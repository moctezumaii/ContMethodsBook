[
  {
    "objectID": "weeks/week_1.html",
    "href": "weeks/week_1.html",
    "title": "Week 01 ‚Äî Introductions",
    "section": "",
    "text": "Short class to introduce ourselves\nGet familiarized with course objectives"
  },
  {
    "objectID": "weeks/week_1.html#session-objectives",
    "href": "weeks/week_1.html#session-objectives",
    "title": "Week 01 ‚Äî Introductions",
    "section": "",
    "text": "Short class to introduce ourselves\nGet familiarized with course objectives"
  },
  {
    "objectID": "weeks/week_1.html#part-1-paper-discussion-60-minutes-of-the-class",
    "href": "weeks/week_1.html#part-1-paper-discussion-60-minutes-of-the-class",
    "title": "Week 01 ‚Äî Introductions",
    "section": "2.1 Part 1: Paper discussion (~60 minutes of the class)",
    "text": "2.1 Part 1: Paper discussion (~60 minutes of the class)\n\n2.1.1 Preparation:\nWe will have a short discussion of two papers. Get in groups of four, each group will then read a paper and present it to the other team.\nGroup a: Tredennick et al. (2021) This is a paper that some of you have read. But I think all of you should read it to be successful in this class.\nGroup b: Zuur, Ieno, and Elphick (2010) if you have already read Tredennick et al. (2021), this is the one you should read.\n\n\n2.1.2 Deliverable:\nYou will give a short lecture ~15 to 20 minutes on the most important aspects of your paper to the other group. YOU ARE THE EXPERTS, so make sure you can answer questions from your ‚Äústudents‚Äù. You can use slides, but you don‚Äôt have to. You will self-govern your group. Each member can present, just two, or have a single person present."
  },
  {
    "objectID": "weeks/week_1.html#part-2-github-and-r",
    "href": "weeks/week_1.html#part-2-github-and-r",
    "title": "Week 01 ‚Äî Introductions",
    "section": "2.2 Part 2: Github and R",
    "text": "2.2 Part 2: Github and R\nMake sure you have downloaded the following:\n\nProgram R\nRStudio\nKnow basics of R and RStudio: https://moctezumaii.github.io/SNR610/installation_instructions.html\nRStudio\nCreate a Github account\nApply for GitHub Education\nJoin the course repository (you will be invited, accept the invite)\nConfirm Codespaces access (we will provide guidance; Codespaces may be enabled by GitHub Education or by the organization)"
  },
  {
    "objectID": "weeks/week04.html",
    "href": "weeks/week04.html",
    "title": "Week 04 - Version Control, Git & Collaboration",
    "section": "",
    "text": "Week 4 # Objectives and background\nTopic: Introduction to Git, GitHub, and Collaborative Reproducible Research"
  },
  {
    "objectID": "weeks/week04.html#learning-objectives",
    "href": "weeks/week04.html#learning-objectives",
    "title": "Week 04 - Version Control, Git & Collaboration",
    "section": "0.1 Learning Objectives",
    "text": "0.1 Learning Objectives\n\nExplain why version control matters for reproducible, transparent research\nConnect version control philosophy to themes from Weeks 1‚Äì3 (data exploration, model selection, the Method-Question-Data triangle)\nUse Git and GitHub for basic version control (init, add, commit, push, pull)\nCollaborate on a shared repository using branches and pull requests\nApply version control to a Quarto-based analytical workflow\n\n\n\n\n\n\n\nThe Semester So Far - Key Takeaways from Weeks 1‚Äì3\n\n\n\n\n\n\n\n\n\n\n\nWeek\nTopic\nKey Takeaway\n\n\n\n\n1\nIntroductions & Papers\nData exploration protects inference (Zuur); exploration vs.¬†inference should be independent (Tredennick); always explore your data before modeling\n\n\n2\nPhilosophy of Data Analysis\n‚ÄúAll models are wrong‚Äù (Box); Bayesian vs.¬†frequentist thinking; uncertainty is everywhere; the goal is to find the useful model, not the true one\n\n\n3\nStatistical Modeling Framework\nThe Method-Question-Data Triangle must align; mismatch ‚Üí wrong conclusions; overcomplication ‚Üí wasted effort; start simple, add complexity only when needed\n\n\n4\nVersion Control & Collaboration\nYour analytical decisions need to be tracked, transparent, and reproducible - Git makes this possible\n\n\n\n\n\nIn Weeks 1‚Äì3, we talked about how to think about data analysis:\n\nWeek 1 emphasized that data exploration and inference are separate activities - but both must be documented. How do you keep track of which analyses were exploratory vs.¬†confirmatory?\nWeek 2 introduced the idea that all models are wrong but some are useful. If you try multiple models, how do you record which ones you tried, why you chose one over another, and what changed?\nWeek 3 showed us the Method-Question-Data Triangle and the dangers of mismatch vs.¬†overcomplication. When you iterate through model choices - trying a lm(), realizing you need a glmer(), adding random effects - how do you track that evolution?\n\nVersion control can help us with this And at WORST‚Ä¶ it is a great tool to have!\n\n\n\n\n\n\nAbout Week 3 Simulations\n\n\n\nMany of you found the simulation exercises in Week 3 challenging - simulating data that matches a scenario description, then fitting both the ‚Äúproposed‚Äù (wrong) and ‚Äúcorrect‚Äù models. That‚Äôs completely normal. Simulating data is a skill that takes practice.\nSession B this week is designed to give you a second pass at those simulations. The first hands-on activity will walk through the Week 3 simulation & analysis exercises together, step by step. Then we‚Äôll layer Git on top, so you‚Äôre learning version control with familiar code rather than starting from scratch."
  },
  {
    "objectID": "weeks/week04.html#background-reading",
    "href": "weeks/week04.html#background-reading",
    "title": "Week 04 - Version Control, Git & Collaboration",
    "section": "0.2 Background Reading",
    "text": "0.2 Background Reading\nBefore Thursday class, review the following:\n\nHappy Git with R - Great guide\nGitHub Quickstart Guide ‚Äì&gt; REad this for an overview of GitHub‚Äôs features ## Before Class\n\nMake sure you have:\n\nA GitHub account (you should already have this from Week 1)\nGit installed on your computer (git --version in terminal)\nRStudio or Positron with Git integration configured\nAccepted the invite to the course repository ‚Äì check your email or GitHub notifications\nConfirmed Codespaces access (if using browser-based workflow) ‚Äì check your email or GitHub notifications\n\nThink about:\n\nHow many versions of your thesis/analysis scripts do you currently have?\nHave you ever lost work, overwritten a file, or been unable to undo a change?\nHave you ever emailed a script to a collaborator and gotten confused about which version is ‚Äúcurrent‚Äù?"
  },
  {
    "objectID": "weeks/week04.html#part-1-retrieval-practice---what-do-you-remember-8-min",
    "href": "weeks/week04.html#part-1-retrieval-practice---what-do-you-remember-8-min",
    "title": "Week 04 - Version Control, Git & Collaboration",
    "section": "1.1 Part 1: Retrieval Practice - What Do You Remember? (8 min)",
    "text": "1.1 Part 1: Retrieval Practice - What Do You Remember? (8 min)\nBefore we introduce anything new, let‚Äôs activate what you already know from Weeks 1‚Äì3. No notes, no phones - this is retrieval practice. Struggling to recall is the point; it strengthens memory.\n\n\n\n\n\n\nQuick-Fire Recall (write on paper, 3 min)\n\n\n\nAnswer as many as you can from memory. One or two sentences each is fine.\n\nWhat did Zuur argue about data exploration? What is the goal of exploring your data before modeling?\nWhat is Box‚Äôs famous quote about models? What does it mean in practice?\nIn Week 3, what were the three scenarios we examined? (Hint: one was a ‚Äúgood match‚Äù)\nIn the examples from Week 3, explain one fo the experiments and what went wrong?\nWhat is the Golden Rule from Week 3?\n\n\n\nDebrief (5 min): Turn to a neighbor and compare answers. Fill in each other‚Äôs gaps. note: ask them what they want here\n\n\n\n\n\n\nWhy Retrieval Practice?\n\n\n\nResearch shows that actively recalling information - even when it‚Äôs difficult - produces stronger long-term retention than re-reading notes (Roediger & Butler, 2011). This is a ‚Äúdesirable difficulty.‚Äù If it felt hard, that‚Äôs good!"
  },
  {
    "objectID": "weeks/week04.html#part-2-predict-observe-explain-12-min",
    "href": "weeks/week04.html#part-2-predict-observe-explain-12-min",
    "title": "Week 04 - Version Control, Git & Collaboration",
    "section": "1.2 Part 2: Predict-Observe-Explain (12 min)",
    "text": "1.2 Part 2: Predict-Observe-Explain (12 min)\nQuick Poll: Raise your hand if you‚Äôve ever:\n\nLost work because you overwrote a file\nCouldn‚Äôt remember why you changed something in your code\nHad a collaborator edit the same file and you had to manually merge changes\nHad a folder full of _v2, _v3, _FINAL files\n\n\n1.2.1 üîÆ PREDICT (3 min - write on paper)\nHere is a scenario. Predict what will go wrong:\n\nYou‚Äôre writing your thesis. You have a file called analysis.R. You make changes over two weeks. Your folder now looks like this:\nanalysis.R\nanalysis_v2.R\nanalysis_FINAL.R\nanalysis_FINAL_v2.R\nanalysis_FINAL_ACTUALLY_FINAL.R\nanalysis_FINAL_ACTUALLY_FINAL_USE_THIS_ONE.R\nYour advisor emails and says: ‚ÄúThe reviewer wants to see the version where you used the Poisson model instead of the linear model. Can you send that?‚Äù\n\nWrite down: What happens next? What specifically goes wrong? How long does it take you to find the right version? Do you even have it?\n\n\n1.2.2 üëÅÔ∏è OBSERVE (2 minute)\nI will show how source control works. And why it is so powerful.\n\n\n1.2.3 üí° EXPLAIN (5 min - whole class)\nAs a class, answer:\n\nWhy does the file-naming approach fail? (Be specific: what information is lost?)\nWhat does Git preserve that file-naming doesn‚Äôt?\nCan you connect this to Box‚Äôs ‚Äúall models are wrong‚Äù idea? (Hint: if you‚Äôre iterating through models, you need a record of which wrong models you tried and why you moved on)"
  },
  {
    "objectID": "weeks/week04.html#part-3-why-version-control---elaborative-interrogation-10-min",
    "href": "weeks/week04.html#part-3-why-version-control---elaborative-interrogation-10-min",
    "title": "Week 04 - Version Control, Git & Collaboration",
    "section": "1.3 Part 3: Why Version Control? - Elaborative Interrogation (10 min)",
    "text": "1.3 Part 3: Why Version Control? - Elaborative Interrogation (10 min)\nElaborative interrogation means asking ‚Äúwhy?‚Äù and ‚Äúhow?‚Äù until you reach a deep understanding.\n\n1.3.1 Round 1: Pair Up - ‚ÄúWhy‚Äù Chain (6 min)\nWith a partner, take turns asking ‚Äúwhy?‚Äù about this statement. Go at least four levels deep:\n\n‚ÄúResearchers should use version control for their analyses.‚Äù\n\n\n\n1.3.2 Round 2: Connect to a Specific Week (5 min)\nEach pair picks two statements.\nAnd you do the why? and how? chain for each one.\n\nData exploration should protect inference, not create it. (Zuur, Week 1)\nAll models are wrong, but some are useful.‚Äù (Box, Week 2)\n‚ÄúStart simple. Add complexity only when needed. Always justify your choices.‚Äù (Golden Rule, Week 3)\n‚ÄúMisalignment between method, question, and data leads to wrong conclusions, wasted effort, rejected papers, and sad grad students.‚Äù (Week 3)\n‚ÄúExploration and inference should come from independent studies. (Tredennick, Week 1)\n\nShare Out (2‚Äì3 min): 3‚Äì4 pairs share their best sentence."
  },
  {
    "objectID": "weeks/week04.html#part-4-lecture---what-is-git-20-min",
    "href": "weeks/week04.html#part-4-lecture---what-is-git-20-min",
    "title": "Week 04 - Version Control, Git & Collaboration",
    "section": "1.4 Part 4: Lecture - What is Git? (‚âà20 min)",
    "text": "1.4 Part 4: Lecture - What is Git? (‚âà20 min)\nDr.¬†Molina will give a traditional lecture covering the following. Take notes - you‚Äôll use this for a concept map right after.\n\n1.4.1 What is version control?\n\nA system that records changes to files over time\nYou can recall any previous version at any time\nThink of it as Track Changes for your entire project - but much more powerful\n\n\n\n1.4.2 Why Git specifically?\n\nCreated by Linus Torvalds (creator of Linux) in 2005\nDistributed - every collaborator has the full project history\nThe industry standard for software, increasingly for science\nIntegrates with RStudio, Positron, and Quarto\n\n\n\n1.4.3 Key Concepts\n\n\n\n\n\n\n\n\nConcept\nWhat It Is\nAnalogy\n\n\n\n\nRepository (repo)\nA project folder tracked by Git\nYour lab notebook for a project\n\n\nCommit\nA snapshot of your files at a point in time\nAn entry in your lab notebook\n\n\nStaging (git add)\nChoosing which changes to include in the next commit\nDeciding which observations to write up\n\n\nBranch\nA parallel version of your project\nAn exploratory side-analysis\n\n\nMerge\nCombining two branches\nIntegrating your exploratory findings into your main analysis\n\n\nPull Request (PR)\nA request to merge your branch + review\nAsking a collaborator to check your work before including it\n\n\nClone\nDownloading a copy of a remote repository\nGetting a copy of a shared lab notebook\n\n\nPush / Pull\nSending/receiving updates to/from GitHub\nSyncing your local lab notebook with the shared one\n\n\n\n\n\n1.4.4 The Git Mental Model\nYour Computer (Local)                    GitHub (Remote)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Working Directory   ‚îÇ   git push    ‚îÇ                  ‚îÇ\n‚îÇ  (your files)        ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫   ‚îÇ   Remote Repo    ‚îÇ\n‚îÇ         ‚îÇ            ‚îÇ               ‚îÇ   (GitHub)       ‚îÇ\n‚îÇ    git add           ‚îÇ   git pull    ‚îÇ                  ‚îÇ\n‚îÇ         ‚ñº            ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ   ‚îÇ                  ‚îÇ\n‚îÇ  Staging Area        ‚îÇ               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n‚îÇ         ‚îÇ            ‚îÇ\n‚îÇ    git commit        ‚îÇ\n‚îÇ         ‚ñº            ‚îÇ\n‚îÇ  Local Repository    ‚îÇ\n‚îÇ  (commit history)    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n1.4.5 Git is Not Just for Code\nGit tracks any text file: .qmd, .R, .csv (small), .bib, .tex, .md\n\n\n\n\n\n\nWhat Git is NOT Good For\n\n\n\n\nLarge binary files (images, PDFs, Word docs, big datasets)\nFiles that change constantly in unpredictable ways\nSensitive data (passwords, API keys, personally identifiable data)\n\nFor large data, look into .gitignore and Git Large File Storage (LFS).\n\n\n\n\n1.4.6 GitHub ‚â† Git\n\n\n\n\n\n\n\nGit\nGitHub\n\n\n\n\nThe version control system\nA website that hosts Git repositories\n\n\nRuns on your computer\nRuns in the cloud\n\n\nTracks history locally\nLets you share, collaborate, and back up\n\n\nFree, open source\nFree for public repos; education accounts get extras"
  },
  {
    "objectID": "weeks/week04.html#part-5-concept-map---your-understanding-of-git-8-min",
    "href": "weeks/week04.html#part-5-concept-map---your-understanding-of-git-8-min",
    "title": "Week 04 - Version Control, Git & Collaboration",
    "section": "1.5 Part 5: Concept Map - Your Understanding of Git (8 min)",
    "text": "1.5 Part 5: Concept Map - Your Understanding of Git (8 min)\nNow that you‚Äôve heard the lecture, build a concept map from memory. This tests whether you actually absorbed it.\n\n1.5.1 Individual (5 min)\nOn a blank piece of paper, create a concept map using these terms. Draw circles for each term and arrows showing how they relate. Label the arrows with verbs (e.g., ‚Äúcreates‚Äù, ‚Äúcontains‚Äù, ‚Äúsends to‚Äù).\nTerms: Repository, Commit, Branch, Merge, Pull Request, Clone, Push, Pull, Staging Area, Working Directory, Remote (GitHub)"
  },
  {
    "objectID": "weeks/week04.html#part-6-hands-on---join-github-create-your-first-repo-first-commits-15-min",
    "href": "weeks/week04.html#part-6-hands-on---join-github-create-your-first-repo-first-commits-15-min",
    "title": "Week 04 - Version Control, Git & Collaboration",
    "section": "1.6 Part 6: Hands-On - Join GitHub, Create Your First Repo, First Commits (‚âà15 min)",
    "text": "1.6 Part 6: Hands-On - Join GitHub, Create Your First Repo, First Commits (‚âà15 min)\n\n\n\n\n\n\nWe‚Äôre doing this NOW, together, in class.\n\n\n\nThe rest of Session A is hands-on.\n\n\n\n1.6.1 Step 1: Make sure you‚Äôre on GitHub (2 min)\n\nGo to github.com\nIf you don‚Äôt have an account, create one now\nIf you haven‚Äôt applied for GitHub Education, do that after class (it gives you free features)\nConfirm you can log in\n\n\n\n1.6.2 Step 2: Create a new RStudio Project with Git (3 min)\n\nOpen RStudio\nGo to File ‚Üí New Project ‚Üí New Directory ‚Üí New Project\nName it: water-growth-sim\n‚úÖ Check ‚ÄúCreate a git repository‚Äù\nClick Create Project\n\nYou now have a local Git repository! Notice the Git tab in your RStudio pane (usually top-right).\n\n\n1.6.3 Step 3: Create a new Quarto file (2 min)\n\nFile ‚Üí New File ‚Üí Quarto Document\nTitle: \"Water and Plant Growth Simulation\"\nSave it as simulation.qmd\n\n\n\n1.6.4 Step 4: Write the simulation - Step 1 only (data simulation) (3 min)\nType this into your simulation.qmd file. This is a simple simulation: water availability (x) affects plant growth (y) through a basic linear relationship.\n\n# =============================================\n# Water & Plant Growth: Simple Linear Simulation\n# =============================================\n# Research question: Does water availability affect plant growth?\n# We KNOW the answer because we're simulating the data!\n\nlibrary(tidyverse)\n\nset.seed(2024)\n\n# Define the truth\nn_plants &lt;- 40             # number of plants\ntrue_intercept &lt;- 5        # baseline growth (cm) with no water\ntrue_slope &lt;- 2.5          # for every 1 unit increase in water, growth increases by 2.5 cm\nnoise_sd &lt;- 3              # how much natural variation there is\n\n# Simulate predictor: water availability (liters per week)\nwater &lt;- runif(n_plants, min = 0, max = 10)\n\n# Simulate response: plant growth (cm)\ngrowth &lt;- true_intercept + true_slope * water + rnorm(n_plants, mean = 0, sd = noise_sd)\n\n# Put it in a data frame\nplant_data &lt;- data.frame(\n  water = water,\n  growth = growth\n)\n\n# Take a look\nhead(plant_data)\nsummary(plant_data)\n\n# Visualize\nggplot(plant_data, aes(x = water, y = growth)) +\n  geom_point(size = 3, alpha = 0.7) +\n  labs(\n    title = \"Simulated: Water Availability vs. Plant Growth\",\n    subtitle = paste(\"True relationship: growth =\", true_intercept, \"+\", true_slope, \"√ó water + noise\"),\n    x = \"Water Availability (L/week)\",\n    y = \"Plant Growth (cm)\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n1.6.5 Step 5: Make your FIRST commit (3 min)\n\nGo to the Git tab in RStudio\nYou‚Äôll see your files listed (.qmd, .Rproj, maybe .gitignore)\nCheck the boxes next to all the files (this is ‚Äústaging‚Äù - git add)\nClick ‚ÄúCommit‚Äù\nIn the commit message box, type: \"Simulated water and plant growth data - true slope is 2.5\"\nClick Commit\n\nüéâ Congratulations - you just made your first Git commit!\nClick ‚ÄúHistory‚Äù in the Git pane to see your commit. There‚Äôs your first lab notebook entry.\n\n\n1.6.6 Step 6: Connect to GitHub and push (3 min)\n\nGo to github.com ‚Üí click ‚Äú+‚Äù (top right) ‚Üí New repository\nName it: water-growth-sim\nLeave it Public (or Private if you prefer)\n‚ö†Ô∏è Do NOT check ‚ÄúAdd a README‚Äù - your local repo already has files\nClick Create repository\nGitHub will show you instructions. Copy the two lines under ‚Äú‚Ä¶or push an existing repository from the command line‚Äù:\nIn RStudio, go to Terminal tab (next to Console) and paste those commands\n\ngit remote add origin https://github.com/YOUR-USERNAME/water-growth-sim.git\ngit branch -M main\ngit push -u origin main\n\nGo back to GitHub in your browser and refresh the page - your files are there! üéâ\n\n\n\n\n\n\n\nCheck GitHub!\n\n\n\nGo to https://github.com/YOUR-USERNAME/water-growth-sim and confirm you can see your simulation.qmd file. Click on it - you can read your code right in the browser. Click ‚ÄúCommits‚Äù to see your commit history (it has one entry so far).\n\n\n\nNow, return to RStudio, and add one line of code to your simulation.qmd. I want you to run the linear model using lm() and run the summary(). After that, commit again, and see if you can push the changes to GitHub.\nCommit message: \"Fit linear model to simulated data\"\nPush to GitHub again.\nRender your Quarto document to see the output. You can also commit and push the rendered HTML if you want (that‚Äôs how I made this website!)."
  },
  {
    "objectID": "weeks/week04.html#muddiest-point-2-min",
    "href": "weeks/week04.html#muddiest-point-2-min",
    "title": "Week 04 - Version Control, Git & Collaboration",
    "section": "1.7 Muddiest Point (2 min)",
    "text": "1.7 Muddiest Point (2 min)\nOn a piece of paper, write down the one thing from today that is most confusing or unclear to you ‚Äì&gt; We will move this to session 2"
  },
  {
    "objectID": "weeks/week04.html#lets-start-the-class-by-taking-a-couple-minutes-and-write-the-things-that-have-been-the-most-complicated-about-this-class",
    "href": "weeks/week04.html#lets-start-the-class-by-taking-a-couple-minutes-and-write-the-things-that-have-been-the-most-complicated-about-this-class",
    "title": "Week 04 - Version Control, Git & Collaboration",
    "section": "2.1 Let‚Äôs start the class by taking a couple minutes and write the things that have been the most complicated about this class",
    "text": "2.1 Let‚Äôs start the class by taking a couple minutes and write the things that have been the most complicated about this class"
  },
  {
    "objectID": "weeks/week04.html#part-1-week-3-simulation-refresher-35-min",
    "href": "weeks/week04.html#part-1-week-3-simulation-refresher-35-min",
    "title": "Week 04 - Version Control, Git & Collaboration",
    "section": "2.2 Part 1: Week 3 Simulation Refresher (‚âà35 min)",
    "text": "2.2 Part 1: Week 3 Simulation Refresher (‚âà35 min)\n\n2.2.1 Why Simulate? (5 min - mini-lecture)\nSimulation is one of the most powerful tools in a statistician‚Äôs toolkit. It lets you:\n\nUnderstand your model by seeing how data generated from that model behaves\nTest your analysis pipeline on data where you know the truth\nDiagnose problems - if your model can‚Äôt recover known parameters from simulated data, something is wrong\n\nIn Week 3, many of you found simulation challenging. That‚Äôs expected! Let‚Äôs break it down together.\n\n\n\n\n\n\nThe Simulation Recipe\n\n\n\nEvery simulation follows the same four steps:\n\nDefine the truth - What are the true parameter values? (e.g., true effect = 3 units)\nGenerate structure - Create the experimental design (e.g., 5 fields √ó 4 plots)\nAdd randomness - Use a distribution to generate data (e.g., rnorm(), rpois(), rbinom())\nFit the model - Analyze the simulated data and see if you recover the truth"
  },
  {
    "objectID": "weeks/week04.html#part-1-setting-up-your-team-repository-10-min",
    "href": "weeks/week04.html#part-1-setting-up-your-team-repository-10-min",
    "title": "Week 04 - Version Control, Git & Collaboration",
    "section": "2.3 Part 1: Setting Up Your Team Repository (‚âà10 min)",
    "text": "2.3 Part 1: Setting Up Your Team Repository (‚âà10 min)\n\n2.3.1 Form Pairs (1 min)\nGet into pairs. You‚Äôll be working on a shared GitHub repository for the rest of this session. Each person will take responsibility for one of the two simulation exercises, so you‚Äôll both contribute a complete analysis to the same repo.\n\n\n\n\n\n\nWhy Shared Repos?\n\n\n\nIn real research, you rarely work alone. Shared repositories force you to practice the pull ‚Üí edit ‚Üí commit ‚Üí push cycle and deal with real collaboration challenges (coordinating who‚Äôs working on what, writing clear commit messages for your partner). This is the whole point of today.\n\n\n\n\n2.3.2 One Person Creates the Repo (3 min)\nOne partner does the following:\n\nGo to github.com ‚Üí ‚Äú+‚Äù ‚Üí New repository\nName it: snr690-sim-team-[your-initials] (e.g., snr690-sim-team-amjk)\n‚úÖ Check ‚ÄúAdd a README file‚Äù\nSet it to Public (so your partner can access it easily)\nClick Create repository\nGo to Settings ‚Üí Collaborators ‚Üí Add people and add your partner by their GitHub username\n\n\n\n2.3.3 Both Partners Clone the Repo (3 min)\nBoth partners (including the creator):\n\nGo to the repository page on GitHub\nClick the green ‚Äú&lt;&gt; Code‚Äù button ‚Üí copy the HTTPS URL\nIn RStudio: File ‚Üí New Project ‚Üí Version Control ‚Üí Git\nPaste the URL, choose a directory, click Create Project\n\n\n\n\n\n\n\nCheckpoint\n\n\n\nBoth partners should now have the same project open in RStudio, connected to the same GitHub repository. You should see the Git tab in your RStudio pane.\n\n\n\n\n2.3.4 Decide Who Does What (1 min)\n\nPartner A will work on Activity 1: The Soil Temperature Experiment\nPartner B will work on Activity 2: The Fertilizer Yield Experiment\n\nEach person creates their own Quarto file:\n\nFile ‚Üí New File ‚Üí Quarto Document\nTitle: \"Salamander - [Your Name]\" or \"Yield - [Your Name]\"\nSave it as sim-soil-temp-[yourname].qmd or sim-fertilizer-[yourname].qmd\nCommit with message: \"Add Quarto file for [activity name]\"\nPush to GitHub\n\n\n\n\n\n\n\nImportant: Pull Before You Push!\n\n\n\nBefore pushing, always pull first (git pull in the Terminal, or the ‚¨áÔ∏è Pull button in the Git tab). Your partner may have pushed changes. Get in the habit now: pull ‚Üí work ‚Üí commit ‚Üí pull ‚Üí push."
  },
  {
    "objectID": "weeks/week04.html#part-2-simulation-exercises-start-simple-no-transformations-45-min",
    "href": "weeks/week04.html#part-2-simulation-exercises-start-simple-no-transformations-45-min",
    "title": "Week 04 - Version Control, Git & Collaboration",
    "section": "2.4 Part 2: Simulation Exercises ‚Äî Start Simple, No Transformations (‚âà45 min)",
    "text": "2.4 Part 2: Simulation Exercises ‚Äî Start Simple, No Transformations (‚âà45 min)\n\n\n\n\n\n\nThe Rule: Start Simple\n\n\n\nWe are deliberately keeping this simple today. I am providing the simulation‚Ä¶ Look at it, and figure out what I did different than you\nThis is what you will be doing here: 1. Simulate data where you know the truth (you have the parameters and I provided the code this time) 2. Comment on the simulation code explain what each step is doing and why‚Ä¶ or at least try to 3. Fit the proposed (wrong) model/method from Week 3. You write the code and explain why it might be problematic 4. Fit the correct model. You propose it, write the code, commit, and push 5. Write it all up in your Quarto document with narrative explaining what you did and why 6. Commit after each step with a meaningful commit message\nThis mirrors the real research process: you try an analysis, realize there‚Äôs a problem, and re-analyze correctly. Git tracks every step of that journey.\n\n\n\n\n2.4.1 Activity 1: Salamander Survival (Partner A) ‚Äî Station 1 from Week 3\nScenario: A researcher wants to know if canopy cover affects salamander survival in forest fragments. They marked 20 salamanders in each of 12 forest fragments and recorded whether each salamander survived (alive/dead) after one year. Canopy cover was measured as a percentage for each fragment.\nThe truth (what we‚Äôre simulating):\n\n12 forest fragments\n20 salamanders per fragment (240 total salamanders)\nCanopy cover ranges from 40% to 90%\nTrue effect of canopy cover on survival probability: for every 10% increase in canopy cover, the log-odds of survival increases by 0.09\nWe‚Äôll use a logistic relationship (since survival is binary), but don‚Äôt worry about the math - just run the code and comment what each line does\n\n\n2.4.1.1 Step 1: Simulate the data and visualize (20 min)\nCopy the code below into your Quarto document. Your job: add a comment above or next to every line explaining what it does. If you don‚Äôt understand a line, ask me.\n\nlibrary(tidyverse)\nlibrary(lme4)  # for mixed models later\n\nset.seed(42)\n\n# Define the experimental structure\nn_fragments &lt;- 12\nn_salamanders_per_fragment &lt;- 20\nn_total &lt;- n_fragments * n_salamanders_per_fragment\n\n# Define the truth\ntrue_intercept &lt;- -3.5          \ntrue_canopy_effect &lt;- 0.09    \n\n# Create fragment-level data\nfragment_data &lt;- data.frame(\n  fragment_id = 1:n_fragments,\n  canopy_cover = runif(n_fragments, min = 40, max = 90)\n)\n\n# Create salamander-level data (each salamander belongs to a fragment)\nsalamander_data &lt;- data.frame(\n  salamander_id = 1:n_total,\n  fragment_id = rep(1:n_fragments, each = n_salamanders_per_fragment)\n)\n\n# Merge to get canopy cover for each salamander\nsalamander_data &lt;- salamander_data %&gt;%\n  left_join(fragment_data, by = \"fragment_id\")\n\n# Simulate survival using logistic regression formula\nsalamander_data &lt;- salamander_data %&gt;%\n  mutate(\n    log_odds = true_intercept + true_canopy_effect * canopy_cover,\n    prob_survival = 1 / (1 + exp(-log_odds)),\n    survived = rbinom(n_total, size = 1, prob = prob_survival)\n  )\n\n# Look at the data\nhead(salamander_data)\nsummary(salamander_data)\n\n# Visualize: proportion surviving in each fragment\nfragment_summary &lt;- salamander_data %&gt;%\n  group_by(fragment_id, canopy_cover) %&gt;%\n  summarise(\n    n_survived = sum(survived),\n    n_total = n(),\n    prop_survived = n_survived / n_total,\n    .groups = \"drop\"\n  )\n\nggplot(fragment_summary, aes(x = canopy_cover, y = prop_survived)) +\n  geom_point(size = 4, alpha = 0.7) +\n  labs(\n    title = \"Simulated: Canopy Cover vs. Salamander Survival\",\n    subtitle = \"Each point = one forest fragment (20 salamanders each)\",\n    x = \"Canopy Cover (%)\",\n    y = \"Proportion Survived\"\n  ) +\n  ylim(0, 1) +\n  theme_minimal(base_size = 14)\n\nüìù In your Quarto doc: Write a paragraph above the code chunk explaining: - What is the research question? - What is the experimental design? (How many fragments? How many salamanders per fragment?) - What is the response variable? What type of variable is it? - Why does this structure matter for the analysis?\nüìù Commit message: \"Simulate salamander survival data - 12 fragments, 20 sal per fragment\"\n\n\n2.4.1.2 Step 2: Fit the proposed (wrong) model from Week 3 (10 min)\nIn Week 3 Station 1, the proposed method was:\n\nLogistic regression: glm(survival ~ canopy_cover, family = binomial) Use the salamander_data data frame, which has one row per salamander, with a binary survived column and a canopy_cover column.\n\nThis treats each salamander as an independent observation. But is that correct?\nYour job:\n\nFit this model using the code below (or write your own):\n\n\nIn your Quarto document, answer these questions:\n\nWhat does this model assume about the salamanders?\nAre salamanders within the same fragment truly independent? Why or why not?\nWhat is the unit of replication in this experiment ‚Äî the salamander or the fragment?\nWhat problem might arise if we ignore the fragment structure?\nKey question: If salamanders in the same fragment are more similar to each other than to salamanders in other fragments (e.g., because of fragment-specific conditions), what happens to our standard errors and p-values?\n\n\nüìù Commit message: \"Fit proposed model (ignores fragment structure) - identify problem\"\nPush to GitHub.\n\n\n2.4.1.3 Step 3: Fit the correct model (15 min)\nThe correct approach needs to account for the fact that salamanders are grouped within fragments. Salamanders in the same fragment are not independent ‚Äî they share the same canopy cover, the same local predators, the same microclimate.\nYour job:\n\nPropose a better model. Hints:\n\nYou need to tell the model that salamanders are nested within fragments\nLook at the lme4 package (already loaded at the top)\nThe function you want is glmer() (generalized linear mixed-effects model)\nThe syntax is similar to glm(), but you add a random effect for fragment: (1 | fragment_id)\nExample structure: glmer(response ~ predictor + (1 | grouping_variable), family = binomial, data = ...)\n\nWrite the code to fit the correct model\nIn your Quarto document, answer:\n\nHow did the estimate of the canopy cover effect change?\nHow did the standard error change? (Bigger? Smaller?)\nDid the p-value change?\nWhy does accounting for fragment structure matter?\nWhich model do you trust more, and why?\n\nReplace the proposed model in your document ‚Äî meaning, re-organize your .qmd so that the correct model comes first, and the wrong model is shown as ‚Äúwhat not to do‚Äù or moved to an appendix section. This simulates the real research process: you realize you made a mistake, so you re-do the analysis correctly.\n\nüìù Commit message: \"Fit correct model with random effect for fragment - replace wrong approach\"\nPush to GitHub.\n\n\n2.4.1.4 Step 4: Write your conclusions\nAdd a final section called ‚ÄúWhat I Learned‚Äù summarizing: - Why the proposed model was problematic (be specific about pseudoreplication) - Why the correct model is better - One sentence connecting this to the Method-Question-Data Triangle from Week 3 (hint: the question is about canopy cover, but the data have a nested structure ‚Äî the method must match both)\nüìù Commit message: \"Add conclusions and connect to Week 3 concepts\"\nPush to GitHub.\n\n\n\n\n2.4.2 Activity 2: Wheat Yield Trials (Partner B) ‚Äî Station 2 from Week 3\nScenario: An agronomist wants to know which of 5 wheat varieties produces the highest yield. They use a randomized complete block design: 4 blocks (fields), with one plot per variety per block (20 plots total). Yield (kg/ha) is recorded once per plot.\nThe truth (what we‚Äôre simulating):\n\n5 wheat varieties\n4 blocks (to account for field variability)\nTrue variety effects: Variety A is the baseline, B is +200 kg/ha better, C is +350 kg/ha better, D is +100 kg/ha better, E is -50 kg/ha worse\nTrue block effects: Block 1 is baseline, Block 2 is +150 kg/ha, Block 3 is -100 kg/ha, Block 4 is +200 kg/ha (because soil quality varies)\nNoise SD = 120 kg/ha\n\n\n2.4.2.1 Step 1: Simulate the data and visualize (20 min)\nCopy the code below into your Quarto document. Your job: add a comment next to lines explaining what it does.\n\nlibrary(tidyverse)\n\nset.seed(123)\n\n# Define experimental structure\nvarieties &lt;- c(\"A\", \"B\", \"C\", \"D\", \"E\")\nblocks &lt;- c(\"Block1\", \"Block2\", \"Block3\", \"Block4\")\n\n# Define the truth\nbaseline_yield &lt;- 3000  # kg/ha for variety A in block 1\n\nvariety_effects &lt;- c(\n  A = 0,\n  B = 200,\n  C = 350,\n  D = 100,\n  E = -50\n)\n\nblock_effects &lt;- c(\n  Block1 = 0,\n  Block2 = 150,\n  Block3 = -100,\n  Block4 = 200\n)\n\nnoise_sd &lt;- 120\n\n# Create all combinations of variety and block (full factorial design)\nwheat_data &lt;- expand.grid(\n  variety = varieties,\n  block = blocks\n)\n\n# Add true yield based on variety and block effects\nwheat_data &lt;- wheat_data %&gt;%\n  mutate(\n    variety_effect = variety_effects[variety],\n    block_effect = block_effects[block],\n    true_yield = baseline_yield + variety_effect + block_effect,\n    yield = true_yield + rnorm(n(), mean = 0, sd = noise_sd)\n  )\n\n# Look at the data\nhead(wheat_data)\nsummary(wheat_data)\n\n# Visualize\nggplot(wheat_data, aes(x = variety, y = yield, color = block)) +\n  geom_point(size = 4, alpha = 0.7, position = position_dodge(width = 0.3)) +\n  stat_summary(fun = mean, geom = \"crossbar\", width = 0.5, \n               color = \"black\", size = 0.3) +\n  labs(\n    title = \"Simulated: Wheat Variety Yields Across Blocks\",\n    subtitle = \"Each point = one plot; crossbar = variety mean across blocks\",\n    x = \"Wheat Variety\",\n    y = \"Yield (kg/ha)\",\n    color = \"Block\"\n  ) +\n  theme_minimal(base_size = 14)\n\nüìù In your Quarto doc: Write a paragraph above the code chunk explaining: - What is the research question? - What is the experimental design? (What is a ‚Äúblock‚Äù? Why use blocks?) - What is the response variable? - Why does the block structure matter?\nüìù Commit message: \"Simulate wheat yield data - 5 varieties x 4 blocks\"\n\n\n2.4.2.2 Step 2: Fit the proposed (wrong) model from Week 3 (10 min)\nIn Week 3 Station 2, the proposed method was:\n\nOne-way ANOVA: aov(yield ~ variety)\n\nThis completely ignores the blocks. But blocks were part of the experimental design!\nYour job:\n\nFit this model: write the code to fit the one-way ANOVA that ignores blocks\n\n\nIn your Quarto narrative, answer these questions:\n\nWhat does this model assume about the blocks?\nIf Block 2 has naturally higher-quality soil (true block effect = +150 kg/ha), and we ignore blocks, what happens to the variety estimates?\nWhat problem arises when we ignore a source of variation that we know exists?\nKey question: The blocks were part of the experimental design. If we don‚Äôt account for them in the analysis, are we throwing away information? What does that do to our standard errors and our ability to detect real variety differences?\n\n\nüìù Commit message: \"Fit proposed model (ignores blocks) - identify problem\"\nPush to GitHub.\n\n\n2.4.2.3 Step 3: Fit the correct model (15 min)\nThe correct approach is to include both variety AND block in the model. This is a two-way ANOVA (or a linear model with two categorical predictors).\nYour job:\n\nPropose a better model. Hints:\nWrite the code to fit the correct model\nIn your Quarto document, answer:\n\nHow did the F-statistic and p-value for variety change?\nHow did the residual error (residual standard error) change? (Hint: look at summary(proposed_model) vs summary(correct_model))\nCompare the means for each variety from both models ‚Äî did they change? If so, why?\n\nReplace the proposed model in your document ‚Äî re-organize your .qmd so the correct analysis comes first, and the wrong model is shown as ‚Äúwhat not to do.‚Äù\n\nüìù Commit message: \"Fit correct model with block effect - replace wrong approach\"\nPush to GitHub.\n\n\n2.4.2.4 Step 4: Write your conclusions\nAdd a final section called ‚ÄúWhat I Learned‚Äù summarizing: - Why the proposed model was problematic (be specific about ignoring the blocking structure) - Why the correct model is better - One sentence connecting this to the Method-Question-Data Triangle from Week 3 (hint: the question is about varieties, but the data were collected using a blocked design ‚Äî the method must account for that)\nüìù Commit message: \"Add conclusions and connect to Week 3 concepts\"\nPush to GitHub.\n\n\n\n\n\n\n\nWhat You Just Did\n\n\n\nYou both just completed the full research cycle that Git is designed to track:\n\nSimulate/collect data ‚Üí commit\nAnalyze using a proposed method ‚Üí commit\nRealize the method is wrong ‚Üí write about the problem, commit\nRe-analyze correctly ‚Üí replace the wrong analysis, commit\nWrite conclusions ‚Üí commit\n\nYour Git history now tells the complete story of your analytical decisions. In real research, this is invaluable: when a reviewer asks ‚Äúdid you try X?‚Äù, you can look at your commit history and say ‚Äúyes, here‚Äôs what happened when we did X, and here‚Äôs why we switched to Y.‚Äù"
  },
  {
    "objectID": "weeks/week04.html#part-3-review-your-partners-work-reflection-10-min",
    "href": "weeks/week04.html#part-3-review-your-partners-work-reflection-10-min",
    "title": "Week 04 - Version Control, Git & Collaboration",
    "section": "2.5 Part 3: Review Your Partner‚Äôs Work + Reflection (‚âà10 min)",
    "text": "2.5 Part 3: Review Your Partner‚Äôs Work + Reflection (‚âà10 min)\n\n2.5.1 Pull and Read (5 min)\n\nPull from GitHub to get your partner‚Äôs file\nOpen their .qmd file and read through it\nPay attention to:\n\nDid they comment every line of the simulation code? Do the comments make sense?\nIs their narrative clear ‚Äî could you understand the analysis without them explaining it to you?\nDo their conclusions connect back to Week 1‚Äì3 concepts?\n\n\n\n\n\n\n\n\nMetacognitive Monitoring\n\n\n\nWriting commit messages forces metacognitive monitoring ‚Äî you have to pause and articulate what you just did and why (Tanner, 2012). This is the same skill that makes for good scientific writing: being explicit about your analytical choices. Over time, the habit of writing commit messages trains you to be a more reflective analyst.\n\n\n\n\n2.5.2 Git Log Review (2 min)\nIn the Terminal, type:\ngit log --oneline\nLook at the commit history. Each line is a snapshot of your analytical journey ‚Äî and your partner‚Äôs. This is what version control gives you: a complete, narrated record of every decision both of you made.\n\n\n2.5.3 Exit Ticket (2 min)\nOn a piece of paper, answer:\n\nOne thing you now feel comfortable doing in Git (be specific ‚Äî e.g., ‚ÄúI can commit and push from RStudio‚Äù)\nOne thing you still want to practice (e.g., ‚ÄúI‚Äôm not sure how branches work‚Äù)\nOne connection between today‚Äôs Git workshop and the statistical concepts from Weeks 1‚Äì3\n\n\n\n\n\n\n\nLooking Ahead\n\n\n\nNow that you have Git fundamentals down, future sessions will build on this. You‚Äôll use version control for every hands-on activity going forward."
  },
  {
    "objectID": "weeks/week02.html",
    "href": "weeks/week02.html",
    "title": "Week 02 ‚Äî [Philosophical concepts in data analysis]",
    "section": "",
    "text": "Week: 2\nUPDATE: Due to inclement weather, there will only be one session this week (Thursday).\nTopic: Foundational philosophical questions"
  },
  {
    "objectID": "weeks/week02.html#background",
    "href": "weeks/week02.html#background",
    "title": "Week 02 ‚Äî [Philosophical concepts in data analysis]",
    "section": "1 Background",
    "text": "1 Background\nThe group that read Tredennick et al. (2021) will be giving their lecture.\nReview the following topics if you don‚Äôt fully understand them:\n\nInference\nProbability\nStatistical models\nSamples and Populations\nBias and Variance\nFrequentist and Bayesian statistics\nUncertainty in data analysis\n\nYou can use AI or a quick search to help you understand these concepts, but make sure you understand them somewhat"
  },
  {
    "objectID": "weeks/week02.html#learning-objectives",
    "href": "weeks/week02.html#learning-objectives",
    "title": "Week 02 ‚Äî [Philosophical concepts in data analysis]",
    "section": "2 Learning Objectives",
    "text": "2 Learning Objectives\nArticulate what statistical models are for and how they function as scientific tools\nExplain how uncertainty enters data analysis and how it is handled in different inferential frameworks\nCompare frequentist and Bayesian perspectives on statistical inference\nCritically evaluate the assumptions underlying quantitative conclusions in published research"
  },
  {
    "objectID": "weeks/week02.html#readings",
    "href": "weeks/week02.html#readings",
    "title": "Week 02 ‚Äî [Philosophical concepts in data analysis]",
    "section": "3 Readings",
    "text": "3 Readings\nPlease read this paper:\nEllison (2004) by Tuesday.\nAgain, a pretty complex topic. If you are not familiar with Bayesian statistics, focus on the philosophical side of things rather than the technical aspects.\nAnd explore this paper by Thursday: Box (1976) (available at: https://www.jstor.org/stable/2286841?seq=1)\nBox (1976) ‚ÄòScience and Statistics‚Äô is VERY dense and had to read, so do not worry about every detail, and you can skim through it. For this class, your goal is to understand three ideas: (1) science as an iteration between theory and data, (2) models as deliberately false but useful, and (3) the need to check and revise models when they clash with data.\n\n3.1 Session A:\n\n3.1.1 Part 1: Lecture by Team B (~ 25 minutes of the class)\nThe team that did not give their lecture today, will be giving a lecture on choosing models.\n\n\n3.1.2 Part 2: Paper discussion (~25 minutes of the class)\nI will open with a short lecture on Ellison (2004) (15 minutes), then we will have a discussion (15 minutes).\nThe discussion will be guided by some questions I will write.\n\n\n\n\n\n\nQuestions To think about while reading\n\n\n\n\nWhat does it mean for a model to be ‚Äúuseful‚Äù rather than ‚Äútrue‚Äù?\nWhat kinds of uncertainty are explicitly modeled, and which are often ignored?\nHow do Bayesian and frequentist approaches differ in how they treat uncertainty?\nHow do these philosophical perspectives influence how we interpret results in applied research?\n\n\n\n\n\n3.1.3 Part 2: Dataset/coding\nWe will start coding here. The objective will be to run a Bayesian example on Thursday\n\n\n3.1.4 Exit ticket\nWhat was the most challenging thing about today?\n\n\n\n3.2 Session B\nMethods workshop ‚Äî hands-on coding Session B has been cancelled"
  },
  {
    "objectID": "weeks/week-template.html",
    "href": "weeks/week-template.html",
    "title": "Week XX ‚Äî [Week Title]",
    "section": "",
    "text": "Week: XX\nSession A: Paper Discussion ‚Äî paper to be assigned by week lead\nSession B: Methods workshop ‚Äî hands-on coding\nObjectives - Short list of objectives for the week.\nReading / Paper - Citation: Title, authors, year. - Key method(s) used in the paper.\nMethod Deep-Dive - Math / equations: short derivation or key formulas. - Assumptions and diagnostics.\nCode / Implementation (R) - R script or R Markdown chunk for implementing the method or a minimal example:\n\n1 Example placeholder\nlibrary(tidyverse) # put example code here"
  },
  {
    "objectID": "slides/slides-Week05.html#the-paper-in-one-sentence",
    "href": "slides/slides-Week05.html#the-paper-in-one-sentence",
    "title": "Lecture on Angelini et al.¬†(2020)",
    "section": "The Paper in One Sentence",
    "text": "The Paper in One Sentence\n\nSeven camelina cultivars √ó two sowing times √ó two years\nWhich combination gives the best site-specific results?\n\n\nWhy it matters statistically: the experimental design is more complex than it looks."
  },
  {
    "objectID": "slides/slides-Week05.html#not-a-simple-rcbd",
    "href": "slides/slides-Week05.html#not-a-simple-rcbd",
    "title": "Lecture on Angelini et al.¬†(2020)",
    "section": "Not a simple RCBD",
    "text": "Not a simple RCBD\n\nAll 14 treatments randomized within each block\nThat‚Äôs impossible: You can‚Äôt sow half a block in October and the other half in March"
  },
  {
    "objectID": "slides/slides-Week05.html#split-plot",
    "href": "slides/slides-Week05.html#split-plot",
    "title": "Lecture on Angelini et al.¬†(2020)",
    "section": "Split plot:",
    "text": "Split plot:\nBLOCK\n‚îú‚îÄ‚îÄ WHOLE PLOT: Autumn\n‚îÇ   ‚îî‚îÄ‚îÄ V1 V2 V3 V4 V5 V6 CELINE\n‚îî‚îÄ‚îÄ WHOLE PLOT: Spring\n    ‚îî‚îÄ‚îÄ V1 V2 V3 V4 V5 V6 CELINE"
  },
  {
    "objectID": "slides/slides-Week05.html#what-are-we-seeing-here",
    "href": "slides/slides-Week05.html#what-are-we-seeing-here",
    "title": "Lecture on Angelini et al.¬†(2020)",
    "section": "What are we seeing here?",
    "text": "What are we seeing here?\n\\[\ny =\n\\mu\n+ \\text{Replicate}\n+ \\text{Year}\n+ \\text{SowingTime}\n+ \\text{WholePlotError}\n+ \\text{Cultivar}\n+ \\text{Interactions}\n+ \\text{SubplotError}\n\\]\n\nConceptual model:\n\\[\ny_{ij} = \\mu + B_i + T_j + \\epsilon_{ij}\n\\]\nWhere:\n\n\\(y_{ij}\\) = observed response in block \\(i\\) receiving treatment \\(j\\)\n\\(\\mu\\) = overall mean response\n\\(B_i\\) = effect of block \\(i\\)\n\nAccounts for background variation we are not primarily interested in\nExamples: lake, field, site, year\nTypically treated as a random effect\n\n\\(T_j\\) = effect of treatment \\(j\\)\n\nThe main effect we want to study\nTreated as a fixed effect\n\n\\(\\epsilon_{ij}\\) = residual error\n\nRandom unexplained variation\nRepresents variability among experimental units within blocks\nAssumed: \\[\n\\epsilon_{ij} \\sim \\text{Normal}(0, \\sigma^2)\n\\]\n\n\nKey idea:\nThere is only ONE level of experimental units and ONE source of experimental error."
  },
  {
    "objectID": "slides/slides-Week05.html#two-error-strata",
    "href": "slides/slides-Week05.html#two-error-strata",
    "title": "Lecture on Angelini et al.¬†(2020)",
    "section": "Two Error Strata",
    "text": "Two Error Strata\n\n\n\nStratum\nTests\nUnit\n\n\n\n\nWhole-plot error\nSowing Time\nWhole plot in block\n\n\nSubplot error\nGenotype, G√óST\nSubplot in whole plot\n\n\n\n\n\n\n\n\n\nImportant\n\n\nUsing a single pooled error gives an anti-conservative test for ST and an over-conservative test for G. This is one of the most common errors in agronomy papers."
  },
  {
    "objectID": "slides/slides-Week05.html#aov-vs.-lmer-for-split-plots",
    "href": "slides/slides-Week05.html#aov-vs.-lmer-for-split-plots",
    "title": "Lecture on Angelini et al.¬†(2020)",
    "section": "aov() vs.¬†lmer() for Split-Plots",
    "text": "aov() vs.¬†lmer() for Split-Plots\nClassical approach ‚Äî explicit error strata:\naov(yield ~ ST * G * Year + Error(Block/ST), data = dat)\nWhat lmerTest does:\nlmer(yield ~ G * ST * Year + (1|Block) + (1|Block:ST), data = dat)\nanova(model)  # Satterthwaite df\n\nBoth are valid. But lmer output labeled as ‚ÄúANOVA‚Äù obscures that this is a linear mixed model with approximated denominator df."
  },
  {
    "objectID": "slides/slides-Week05.html#the-methodquestiondata-triangle",
    "href": "slides/slides-Week05.html#the-methodquestiondata-triangle",
    "title": "Lecture on Angelini et al.¬†(2020)",
    "section": "The Method‚ÄìQuestion‚ÄìData Triangle",
    "text": "The Method‚ÄìQuestion‚ÄìData Triangle\n       QUESTION\n   \"Best genotype √ó \n   sowing time?\"\n        /\\\n       /  \\\n DATA /    \\ METHOD\n-----/------\\-------\nFactorial    Split-plot LMM\nblocked      Two error strata\ncont+count   Poisson for counts\n\nAlignment? Mostly yes - but the gap between what was done (LMM) and what was reported (‚ÄúANOVA‚Äù) is a transparency issue."
  },
  {
    "objectID": "slides/slides-Week05.html#the-6-key-takeaways",
    "href": "slides/slides-Week05.html#the-6-key-takeaways",
    "title": "Lecture on Angelini et al.¬†(2020)",
    "section": "The 6 Key Takeaways",
    "text": "The 6 Key Takeaways\n\n\nSplit-plot because ST cannot be randomized at subplot level ‚Üí two error strata\nlmer + anova() is a linear mixed model, not classical ANOVA\nYear as fixed is pragmatic with n=2 but limits generalizability\nG√óST is disordinal ‚Äî separate recommendations required\nPoisson for counts was correct; response type matters\nData exploration is underreported ‚Äî Zuur would want figures"
  },
  {
    "objectID": "slides/slides-Week05.html#questions",
    "href": "slides/slides-Week05.html#questions",
    "title": "Lecture on Angelini et al.¬†(2020)",
    "section": "Questions",
    "text": "Questions\n\nHow did the authors control for environmental variation when comparing genotypes across different sowing dates?\nThe paper mentions they used ‚Äúvisual inspection of model residuals was also done to check for model assumptions‚Äù"
  },
  {
    "objectID": "slides/slides-Week03.html#the-problem",
    "href": "slides/slides-Week03.html#the-problem",
    "title": "Matching Methods to Research Questions",
    "section": "The Problem",
    "text": "The Problem\n\nWe often learn methods in isolation ‚Äì&gt; during classes\n\n‚ÄúThis is a t-test‚Äù\n‚ÄúThis is ANOVA‚Äù\n‚ÄúThis is regression‚Äù\n‚ÄúThis is Bayesian‚Äù\n\nThen we want to apply those methods in our data.\nThis is particularly true for people that really enjoy analytical methods!\nThis is backwards!\n\n\nThe research question should drive everything!"
  },
  {
    "objectID": "slides/slides-Week03.html#the-triangle-framework",
    "href": "slides/slides-Week03.html#the-triangle-framework",
    "title": "Matching Methods to Research Questions",
    "section": "The Triangle Framework",
    "text": "The Triangle Framework\n         RESEARCH QUESTION\n                /\\\n               /  \\\n              /    \\\n             /      \\\n            /        \\\n           /          \\\n    DATA TYPE -------- METHOD CHOICE\n\nAll three must align\n\n\nMisalignment leads to:\n\nWrong conclusions\nWasted effort\n\nRejected papers\nSad grad students! üò¶"
  },
  {
    "objectID": "slides/slides-Week03.html#research-question-drives-everything",
    "href": "slides/slides-Week03.html#research-question-drives-everything",
    "title": "Matching Methods to Research Questions",
    "section": "Research Question Drives Everything",
    "text": "Research Question Drives Everything\n\n\n\nQuestion Type\nWhat You‚Äôre Looking For\nExample Methods\n\n\n\n\nIs there a difference?\nComparison\nt-test, ANOVA, GLM\n\n\nIs there a relationship?\nAssociation\nRegression, correlation\n\n\nCan I predict?\nPrediction\nML, regression\n\n\nWhat‚Äôs the pattern?\nStructure\nClustering, PCA, ordination\n\n\n\n\nYour question determines what ‚Äúanswer‚Äù looks like!"
  },
  {
    "objectID": "slides/slides-Week03.html#data-type-constrains-your-options",
    "href": "slides/slides-Week03.html#data-type-constrains-your-options",
    "title": "Matching Methods to Research Questions",
    "section": "Data Type Constrains Your Options",
    "text": "Data Type Constrains Your Options\n\n\n\nResponse Variable\nDistribution\nCommon Methods\n\n\n\n\nContinuous, normal\nGaussian\nLM, ANOVA\n\n\nCounts (0, 1, 2, ‚Ä¶)\nPoisson, NegBin\nGLM\n\n\nBinary (yes/no)\nBinomial\nLogistic regression\n\n\nProportions (0-1)\nBinomial, Beta\nGLM, Beta regression\n\n\n\n\nAlso consider:\n\nIndependence vs.¬†grouping\nRepeated measures\nNested/hierarchical structure"
  },
  {
    "objectID": "slides/slides-Week03.html#the-alignment-check",
    "href": "slides/slides-Week03.html#the-alignment-check",
    "title": "Matching Methods to Research Questions",
    "section": "The Alignment Check ‚úÖ",
    "text": "The Alignment Check ‚úÖ\nBefore analyzing, ask yourself:\n\n‚úÖ What exactly is my question?\n‚úÖ What type of response variable do I have?\n‚úÖ What is my data structure (grouping, nesting, time)?\n‚úÖ Does my method handle all of this?\n\n\nIf you can‚Äôt answer these ‚Üí STOP and think!"
  },
  {
    "objectID": "slides/slides-Week03.html#three-common-scenarios",
    "href": "slides/slides-Week03.html#three-common-scenarios",
    "title": "Matching Methods to Research Questions",
    "section": "Three Common Scenarios",
    "text": "Three Common Scenarios\nWe‚Äôll look at three examples:\n\nMismatch - Method ignores key data structure\nGood Match - Method fits question and data\nOvercomplicated - Method is fancier than needed\n\n\nLet‚Äôs see each one‚Ä¶"
  },
  {
    "objectID": "slides/slides-Week03.html#example-1-mismatch",
    "href": "slides/slides-Week03.html#example-1-mismatch",
    "title": "Matching Methods to Research Questions",
    "section": "Example 1: MISMATCH",
    "text": "Example 1: MISMATCH\nScenario:\n\nTesting fertilizer effect on crop yield\n5 fields, 4 plots per field\n2 control plots, 2 fertilized plots per field\n\n\nThe analysis:\nlm(yield ~ fertilizer)\n\nTreats all 20 observations as independent!"
  },
  {
    "objectID": "slides/slides-Week03.html#example-1-the-problem",
    "href": "slides/slides-Week03.html#example-1-the-problem",
    "title": "Matching Methods to Research Questions",
    "section": "Example 1: The Problem",
    "text": "Example 1: The Problem"
  },
  {
    "objectID": "slides/slides-Week03.html#example-1-wrong-vs.-right",
    "href": "slides/slides-Week03.html#example-1-wrong-vs.-right",
    "title": "Matching Methods to Research Questions",
    "section": "Example 1: Wrong vs.¬†Right",
    "text": "Example 1: Wrong vs.¬†Right\n\n\nShow code\n# WRONG: Ignores field structure\nwrong_model &lt;- lm(yield ~ treatment, data = mismatch_data)\n\n# RIGHT: Accounts for field\ncorrect_model &lt;- lmer(yield ~ treatment + (1|field), data = mismatch_data)\n\n\n\n\n\nTRUE EFFECT: 3 units\n\n\nWRONG MODEL (lm):\n\n\n  Estimate: 3.38 \n\n\n  Std Error: 2.57 \n\n\n  p-value: 0.2043 \n\n\nCORRECT MODEL (lmer):\n\n\n  Estimate: 3.38 \n\n\n  Std Error: 0.99 \n\n\n  p-value: 0"
  },
  {
    "objectID": "slides/slides-Week03.html#example-1-the-fix",
    "href": "slides/slides-Week03.html#example-1-the-fix",
    "title": "Matching Methods to Research Questions",
    "section": "Example 1: The Fix",
    "text": "Example 1: The Fix\nIn this design (treatment within fields):\n\nThe wrong model has inflated standard errors because it treats field variance as residual noise\nThe correct model* separates field variance ‚Üí cleaner estimate of treatment effect\nThis means reduced power when you ignore structure\n\n\nIn other designs (treatment between fields):\n\nIgnoring structure would inflate Type I error instead\n\n\n\n# Wrong\nlm(yield ~ treatment)\n\n# Right  \nlmer(yield ~ treatment + (1|field))\n\n\nLesson: Always check your independence assumption!"
  },
  {
    "objectID": "slides/slides-Week03.html#example-2-good-match",
    "href": "slides/slides-Week03.html#example-2-good-match",
    "title": "Matching Methods to Research Questions",
    "section": "Example 2: GOOD MATCH",
    "text": "Example 2: GOOD MATCH\nScenario:\n\nPollinator visits to flowers\n2 treatments: native vs.¬†non-native plants\n30 plants per treatment\nResponse: count of visits (0 to ~45)\n\n\nThe approach:\nglm(visits ~ treatment, family = poisson)"
  },
  {
    "objectID": "slides/slides-Week03.html#example-2-the-data",
    "href": "slides/slides-Week03.html#example-2-the-data",
    "title": "Matching Methods to Research Questions",
    "section": "Example 2: The Data",
    "text": "Example 2: The Data"
  },
  {
    "objectID": "slides/slides-Week03.html#example-2-why-it-works",
    "href": "slides/slides-Week03.html#example-2-why-it-works",
    "title": "Matching Methods to Research Questions",
    "section": "Example 2: Why It Works",
    "text": "Example 2: Why It Works\n\n\nShow code\npoisson_model &lt;- glm(visits ~ treatment, family = poisson, \n                     data = goodmatch_data)\nsummary(poisson_model)$coefficients\n\n\n                 Estimate Std. Error   z value      Pr(&gt;|z|)\n(Intercept)     2.0412203  0.0657951 31.023896 2.567154e-211\ntreatmentnative 0.5761755  0.0822319  7.006715  2.439777e-12\n\n\n\nChecklist:\n\n‚úÖ Count data ‚Üí Poisson distribution\n‚úÖ No upper bound on counts\n‚úÖ Independent observations (different plants)\n‚úÖ Simple comparison question"
  },
  {
    "objectID": "slides/slides-Week03.html#example-2-interpretation",
    "href": "slides/slides-Week03.html#example-2-interpretation",
    "title": "Matching Methods to Research Questions",
    "section": "Example 2: Interpretation",
    "text": "Example 2: Interpretation\n\n\nShow code\nest &lt;- coef(poisson_model)[\"treatmentnative\"]\ncat(\"Coefficient (log scale):\", round(est, 3), \"\\n\")\n\n\nCoefficient (log scale): 0.576 \n\n\nShow code\ncat(\"Multiplicative effect:\", round(exp(est), 2), \"\\n\")\n\n\nMultiplicative effect: 1.78 \n\n\nShow code\ncat(\"Native plants get\", round((exp(est) - 1) * 100, 1), \"% more visits\\n\")\n\n\nNative plants get 77.9 % more visits\n\n\n\nLesson: Match your distribution to your data type!"
  },
  {
    "objectID": "slides/slides-Week03.html#example-3-overcomplicated",
    "href": "slides/slides-Week03.html#example-3-overcomplicated",
    "title": "Matching Methods to Research Questions",
    "section": "Example 3: OVERCOMPLICATED",
    "text": "Example 3: OVERCOMPLICATED\nScenario:\n\nTree height in 2 forest types\n30 trees per forest type\nNormal distribution, no grouping\nSimple question: ‚ÄúIs there a difference?‚Äù\n\n\nThe overkill:\n‚ÄúLet‚Äôs use a Bayesian hierarchical model with spatial autocorrelation, weakly informative priors, and MCMC sampling!‚Äù"
  },
  {
    "objectID": "slides/slides-Week03.html#example-3-the-data",
    "href": "slides/slides-Week03.html#example-3-the-data",
    "title": "Matching Methods to Research Questions",
    "section": "Example 3: The Data",
    "text": "Example 3: The Data"
  },
  {
    "objectID": "slides/slides-Week03.html#example-3-simple-vs.-complex",
    "href": "slides/slides-Week03.html#example-3-simple-vs.-complex",
    "title": "Matching Methods to Research Questions",
    "section": "Example 3: Simple vs.¬†Complex",
    "text": "Example 3: Simple vs.¬†Complex\n\n\nShow code\n# Simple t-test (appropriate!)\nsimple_test &lt;- t.test(height ~ forest_type, data = overcomp_data)\n\ncat(\"Difference:\", round(diff(simple_test$estimate), 2), \"meters\\n\")\n\n\nDifference: -4.51 meters\n\n\nShow code\ncat(\"95% CI: [\", round(simple_test$conf.int[1], 2), \",\", \n    round(simple_test$conf.int[2], 2), \"]\\n\")\n\n\n95% CI: [ 2.2 , 6.81 ]\n\n\nShow code\ncat(\"p-value:\", format(simple_test$p.value, digits = 3), \"\\n\")\n\n\np-value: 0.000239 \n\n\n\nTime to run: ~0.001 seconds\nA Bayesian spatial model: ~5-10 minutes\nSame answer!"
  },
  {
    "objectID": "slides/slides-Week03.html#example-3-the-lesson",
    "href": "slides/slides-Week03.html#example-3-the-lesson",
    "title": "Matching Methods to Research Questions",
    "section": "Example 3: The Lesson",
    "text": "Example 3: The Lesson\n\nProblems with overcomplication:\n\nTakes much longer to fit\nHarder to interpret\nReviewers get confused\nMore things can go wrong\nSame answer as simple approach!\n\n\n\nPrinciple of parsimony:\n\nUse the simplest method that adequately addresses your question\n\n\n\nSave fancy methods for when you need them!\n\n\nI know this is challenging! When I learn about new methods, I want to use them ALL THE TIME. But resist the urge! Focus on the researhc question!\nIf you teach, you get to explore any methods you want in your lessons!"
  },
  {
    "objectID": "slides/slides-Week03.html#summary-three-scenarios",
    "href": "slides/slides-Week03.html#summary-three-scenarios",
    "title": "Matching Methods to Research Questions",
    "section": "Summary: Three Scenarios",
    "text": "Summary: Three Scenarios\n\n\n\n\n\n\n\n\n\nExample\nProblem\nConsequence\nLesson\n\n\n\n\nMismatch\nIgnored grouping structure\nFalse positive risk\nCheck independence\n\n\nGood Match\nNone - appropriate method\nValid inference\nMatch distribution\n\n\nOvercomplicated\nUnnecessary complexity\nWasted effort\nStart simple"
  },
  {
    "objectID": "slides/slides-Week03.html#your-checklist",
    "href": "slides/slides-Week03.html#your-checklist",
    "title": "Matching Methods to Research Questions",
    "section": "Your Checklist",
    "text": "Your Checklist\nBefore you analyze, ask:\n\n1Ô∏è‚É£ What is my question? (difference, relationship, prediction)\n\n\n2Ô∏è‚É£ What is my response variable? (continuous, count, binary, proportion)\n\n\n3Ô∏è‚É£ What is my data structure? (independent, grouped, nested, repeated)\n\n\n4Ô∏è‚É£ Does my method handle all three?"
  },
  {
    "objectID": "slides/slides-Week03.html#the-golden-rule",
    "href": "slides/slides-Week03.html#the-golden-rule",
    "title": "Matching Methods to Research Questions",
    "section": "The Golden Rule",
    "text": "The Golden Rule\n\nStart simple.\n. . .\nAdd complexity only when needed.\n. . .\nAlways justify your choices."
  },
  {
    "objectID": "slides/slides-Week03.html#now-its-your-turn",
    "href": "slides/slides-Week03.html#now-its-your-turn",
    "title": "Matching Methods to Research Questions",
    "section": "Now It‚Äôs Your Turn!",
    "text": "Now It‚Äôs Your Turn!\nThink-Pair-Share (5 min)\n\nLook back at your silent reflection sheet. Based on the three examples:\n\nWhat method might be appropriate for YOUR data?\nWhat‚Äôs one thing about your data structure that makes method choice tricky?\n\n\n\nThink (&lt;1 min) ‚Äî you already did this‚Ä¶ you can use 30 seconds to update your notes\nPair (3 min) ‚Äî discuss with a neighbor, help each other troubleshoot\nShare (1 min) ‚Äî 2‚Äì3 volunteers share their pairing‚Äôs most interesting dilemma\n\n\nGrab your worksheet and let‚Äôs go!"
  },
  {
    "objectID": "slides/slides-Week03.html#now-its-your-turn-1",
    "href": "slides/slides-Week03.html#now-its-your-turn-1",
    "title": "Matching Methods to Research Questions",
    "section": "Now It‚Äôs Your Turn!",
    "text": "Now It‚Äôs Your Turn!\nData Detective Stations\n\n6 scenarios around the room\nDiagnose: Mismatch? Good match? Overcomplicated?\nWork in pairs\n4 minutes per station\n\n\nGrab your worksheet and let‚Äôs go!"
  },
  {
    "objectID": "slides/slides-Week03.html#appendix-full-simulation-code",
    "href": "slides/slides-Week03.html#appendix-full-simulation-code",
    "title": "Matching Methods to Research Questions",
    "section": "Appendix: Full Simulation Code",
    "text": "Appendix: Full Simulation Code\n\n\nShow code\n# ============================================================================\n# EXAMPLE 1: MISMATCH - Ignoring nested structure\n# Demonstrates FALSE POSITIVE from pseudoreplication\n# ============================================================================\n\nlibrary(lme4)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nset.seed(42)\n\nn_fields &lt;- 5\nn_plots_per_field &lt;- 4\n\nmismatch_data &lt;- expand.grid(\n  field = factor(1:n_fields),\n  plot = 1:n_plots_per_field\n) |&gt;\n  mutate(\n    treatment = rep(c(\"control\", \"control\", \"fertilizer\", \"fertilizer\"), n_fields),\n    treatment = factor(treatment, levels = c(\"control\", \"fertilizer\"))\n  )\n\n# Large field-to-field variation\nfield_effects &lt;- data.frame(\n  field = factor(1:n_fields),\n  field_effect = c(-12, -5, 2, 8, 14)\n)\n\ntrue_effect &lt;- 0  # NO TRUE EFFECT!\n\nmismatch_data &lt;- mismatch_data |&gt;\n  left_join(field_effects, by = \"field\") |&gt;\n  mutate(\n    yield = 50 + field_effect + \n            ifelse(treatment == \"fertilizer\", true_effect, 0) +\n            rnorm(n(), mean = 0, sd = 1.5)\n  ) |&gt;\n  # Create confounding between treatment and field quality\n  mutate(\n    yield = yield + ifelse(treatment == \"fertilizer\", field_effect * 0.15, 0)\n  )\n\n# Compare wrong vs correct\nwrong_model &lt;- lm(yield ~ treatment, data = mismatch_data)\ncorrect_model &lt;- lmer(yield ~ treatment + (1|field), data = mismatch_data)\n\n# Wrong model shows \"significant\" effect (p &lt; 0.05)\nsummary(wrong_model)\n\n# Correct model shows non-significant (as it should be - no true effect!)\nsummary(correct_model)"
  },
  {
    "objectID": "slides/slides-Week03.html#appendix-full-simulation-code-continued",
    "href": "slides/slides-Week03.html#appendix-full-simulation-code-continued",
    "title": "Matching Methods to Research Questions",
    "section": "Appendix: Full Simulation Code (continued)",
    "text": "Appendix: Full Simulation Code (continued)\n\n\nShow code\n# ============================================================================\n# EXAMPLE 2: GOOD MATCH - Poisson GLM for counts\n# ============================================================================\n\nset.seed(2024)\nn_per_group &lt;- 30\n\ngoodmatch_data &lt;- data.frame(\n  plant_id = 1:(2 * n_per_group),\n  treatment = factor(rep(c(\"native\", \"non_native\"), each = n_per_group),\n                     levels = c(\"non_native\", \"native\"))\n)\n\nbaseline_visits &lt;- 8\nnative_effect &lt;- 0.5  # Log-scale\n\ngoodmatch_data &lt;- goodmatch_data |&gt;\n  mutate(\n    log_mu = log(baseline_visits) + \n             ifelse(treatment == \"native\", native_effect, 0),\n    visits = rpois(n(), lambda = exp(log_mu))\n  )\n\npoisson_model &lt;- glm(visits ~ treatment, family = poisson, \n                     data = goodmatch_data)\nsummary(poisson_model)\n\n# Interpretation\nexp(coef(poisson_model)[\"treatmentnative\"])  # Multiplicative effect"
  },
  {
    "objectID": "slides/slides-Week03.html#appendix-full-simulation-code-continued-1",
    "href": "slides/slides-Week03.html#appendix-full-simulation-code-continued-1",
    "title": "Matching Methods to Research Questions",
    "section": "Appendix: Full Simulation Code (continued)",
    "text": "Appendix: Full Simulation Code (continued)\n\n\nShow code\n# ============================================================================\n# EXAMPLE 3: OVERCOMPLICATED - Simple question, complex method\n# ============================================================================\n\nset.seed(2024)\nn_trees &lt;- 30\n\novercomp_data &lt;- data.frame(\n  tree_id = 1:(2 * n_trees),\n  forest_type = factor(rep(c(\"deciduous\", \"coniferous\"), each = n_trees))\n)\n\ndeciduous_mean &lt;- 18\nconiferous_mean &lt;- 22\ntree_sd &lt;- 4\n\novercomp_data &lt;- overcomp_data |&gt;\n  mutate(\n    height = ifelse(forest_type == \"deciduous\",\n                    rnorm(n(), deciduous_mean, tree_sd),\n                    rnorm(n(), coniferous_mean, tree_sd))\n  )\n\n# Simple and appropriate!\nt.test(height ~ forest_type, data = overcomp_data)\n\n# Or equivalently\nlm(height ~ forest_type, data = overcomp_data) |&gt; summary()"
  },
  {
    "objectID": "slides/slide-Week01.html#welcome",
    "href": "slides/slide-Week01.html#welcome",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Welcome!",
    "text": "Welcome!\nI am very excited to be teaching this class.\n\nToday we will be talking about the course.\nBefore this introduction, I talked about the website.\nWe will work together on projects, we will use this to create slideshows"
  },
  {
    "objectID": "slides/slide-Week01.html#things-you-need-for-this-course",
    "href": "slides/slide-Week01.html#things-you-need-for-this-course",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Things you need for this course",
    "text": "Things you need for this course\n\nProgram R\nRStudio or Positron (new!)\nGithub\nI recommend you create a Github student account"
  },
  {
    "objectID": "slides/slide-Week01.html#introductions",
    "href": "slides/slide-Week01.html#introductions",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Introductions",
    "text": "Introductions\n\nAbout me:\nI enjoy numbers, statistics, coding, models and teaching\nMy academic history"
  },
  {
    "objectID": "slides/slide-Week01.html#my-academic-history",
    "href": "slides/slide-Week01.html#my-academic-history",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "My academic history",
    "text": "My academic history\n\n\n\n    \n        \n            \n            \n                UNAM\n                Undergraduate degree in Biology and Masters in Ecology. Worked with fish and the evolution of Matrotrophy\n            \n        \n    \n\n    \n        \n            \n            \n                University of Maine\n                PhD working with Atlantic salmon movement and survival\n            \n        \n    \n\n    \n        \n            \n            \n                LSSU\n                Postdoc building a database, analysing data and looking at post-restoration ceommunity composition\n            \n        \n    \n\n    \n        \n            \n            \n                MSU\n                Postdoc working with models"
  },
  {
    "objectID": "slides/slide-Week01.html#currently",
    "href": "slides/slide-Week01.html#currently",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Currently",
    "text": "Currently\nI mostly teach\nDo some research\nServe on committees\nHerbert College representative in the Statistics Minor and Masters"
  },
  {
    "objectID": "slides/slide-Week01.html#your-turn",
    "href": "slides/slide-Week01.html#your-turn",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Your turn",
    "text": "Your turn\n\nName\nDepartment\nInterests both research and something you enjoy to do"
  },
  {
    "objectID": "slides/slide-Week01.html#course-overview",
    "href": "slides/slide-Week01.html#course-overview",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Course overview",
    "text": "Course overview\nPLEASE CHECK THE SYLLABUS ON THE WEBSITE"
  },
  {
    "objectID": "slides/slide-Week01.html#course-overview-1",
    "href": "slides/slide-Week01.html#course-overview-1",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Course overview",
    "text": "Course overview\nLearning Outcomes\n\nCritically evaluate quantitative methods in published research across agricultural and natural resource sciences\nImplement and adapt these methods using equations, models, and R code\nApply appropriate quantitative approaches to their own research data\nCommunicate and defend methodological decisions through peer-led discussions and final presentations"
  },
  {
    "objectID": "slides/slide-Week01.html#course-lectures",
    "href": "slides/slide-Week01.html#course-lectures",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Course lectures",
    "text": "Course lectures\nWe will use some pretty different teaching and learning strategies. This are being used for three reasons:\n\nThere is peer-reviewed evidence that these strategies improve learning outcomes. But I am an empiricist.\nYou will develop some skills, like oral communication and some teaching abilities, that will be very helpful in your future.\nI believe it will make the class engaging."
  },
  {
    "objectID": "slides/slide-Week01.html#this-weeks-assignment",
    "href": "slides/slide-Week01.html#this-weeks-assignment",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "This week‚Äôs assignment",
    "text": "This week‚Äôs assignment\n\nRead Tredennick et al. (2021) or Zuur, Ieno, and Elphick (2010) depending on your group\nGive a lecture (~25 minutes) on the paper and lead a short discussion (~5 minutes)\nBe ready to answer questions from your classmates\nUse slides or not, your choice\nYou will have 10 minutes at the beginning of next class to prepare with your group\nYou are the experts!"
  },
  {
    "objectID": "slides/slide-Week01.html#zuur-et-al.-2010",
    "href": "slides/slide-Week01.html#zuur-et-al.-2010",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Zuur et al.¬†2010",
    "text": "Zuur et al.¬†2010\n\nA protocol for data exploration to avoid common statistical problems\nMethods in Ecology and Evolution 1(1):3‚Äì14. https://doi.org/10.1111/j.2041-210X.2009.00001.x"
  },
  {
    "objectID": "slides/slide-Week01.html#treddennick-et-al.-2021",
    "href": "slides/slide-Week01.html#treddennick-et-al.-2021",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Treddennick et al.¬†2021",
    "text": "Treddennick et al.¬†2021\n\nA practical guide to selecting models for exploration, inference, and prediction in ecology\nEcology 102(5):e03375. https://doi.org/10.1002/ecy.3336\nSome of you have already read this one!"
  },
  {
    "objectID": "slides/slide-Week01.html#make-sure-you-have-everything-ready-for-next-classes",
    "href": "slides/slide-Week01.html#make-sure-you-have-everything-ready-for-next-classes",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Make sure you have everything ready for next classes",
    "text": "Make sure you have everything ready for next classes\n\nR and RStudio or Positron installed\nPositron? What is that?\nPositron is a new IDE by the makers of RStudio. It is still in beta but looks very promising.\nLink: https://posit.co/download/preview/"
  },
  {
    "objectID": "slides/slide-Week01.html#next-week",
    "href": "slides/slide-Week01.html#next-week",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Next Week",
    "text": "Next Week"
  },
  {
    "objectID": "slides/slide-Week01.html#notes-before-the-end-of-the-class",
    "href": "slides/slide-Week01.html#notes-before-the-end-of-the-class",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Notes before the end of the class",
    "text": "Notes before the end of the class\n\nOffice: ANRB 474\nIf you have issues with R or RStudio, please chech the resources section on the website\nIf you are struggling with basic linear models, you can review and work on the materials from SNR 610: https://moctezumaii.github.io/SNR610/ which can be a good resource!\nThis is a collaborative class, we will work together to make it successful for all of us! Feel free to ask anyone for help\nSee you next class!"
  },
  {
    "objectID": "slides/slide-Week01.html#references",
    "href": "slides/slide-Week01.html#references",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "References",
    "text": "References\n\nTredennick, A. T., G. Hooker, and P. B. Adler. (2021). A practical guide to selecting models for exploration, inference, and prediction in ecology. Ecology 102(5):e03375. https://doi.org/10.1002/ecy.3336\nZuur, A. F., E. N. Ieno, and C. S. Elphick. (2010). A protocol for data exploration to avoid common statistical problems. Methods in Ecology and Evolution 1(1):3‚Äì14. https://doi.org/10.1111/j.2041-210X.2009.00001.x\n\n\n\n\n\nTredennick, Andrew T., Giles Hooker, Stephen P. Ellner, and Peter B. Adler. 2021. ‚ÄúA Practical Guide to Selecting Models for Exploration, Inference, and Prediction in Ecology.‚Äù Ecology 102 (6): e03336. https://doi.org/10.1002/ecy.3336.\n\n\nZuur, Alain F., Elena N. Ieno, and Chris S. Elphick. 2010. ‚ÄúA Protocol for Data Exploration to Avoid Common Statistical Problems.‚Äù Methods in Ecology and Evolution 1 (1): 3‚Äì14. https://doi.org/10.1111/j.2041-210X.2009.00001.x."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "References"
  },
  {
    "objectID": "materials/Week3questions.html",
    "href": "materials/Week3questions.html",
    "title": "Week 03 ‚Äî Linear Models and GLM‚Äôs",
    "section": "",
    "text": "div { &.callout { font-size: 2.0rem !important; } }\n\n\n\n\n\n\n\nReflection Prompts\n\n\n\n\nMy research question is (one sentence):\n\n \n\nMy response variable is: (circle one or write your own)\n\nContinuous measurements\nCounts\nBinary (yes/no, presence/absence)\nProportions\nCategories\nOther: ___________\n\n\n\n\nMy data structure includes: (check all that apply)\n\nRepeated measures on the same units\nMultiple sites/plots/locations\nTime series\nNested structure (e.g., plants within plots within sites)\nJust one observation per unit\nOther: ___________\n\n\n\n\nOne worry I have about analyzing my data:"
  },
  {
    "objectID": "materials/answersheet_Version5.html",
    "href": "materials/answersheet_Version5.html",
    "title": "Week 03 Session B ‚Äî Answer Sheet",
    "section": "",
    "text": "This page contains solutions to the Week 03 coding activities.\n\n\nStudents: Please work through the problems yourself before viewing answers!\n\n  Access Answers\n\n\n\nIf you are a student and don‚Äôt have the password,that means you shouldn‚Äôt be here yet! üòä"
  },
  {
    "objectID": "materials/answersheet_Version5.html#option-a2-my-first-model-expected-answers",
    "href": "materials/answersheet_Version5.html#option-a2-my-first-model-expected-answers",
    "title": "Week 03 Session B ‚Äî Answer Sheet",
    "section": "1.1 Option A2: My First Model ‚Äî Expected Answers",
    "text": "1.1 Option A2: My First Model ‚Äî Expected Answers\n\n1.1.1 Question: What does the slope for temperature mean?\nExpected answer: For every 1-degree increase in temperature, yield increases by approximately 1.3 units (the exact value depends on the data). This assumes a linear relationship and that all other factors are held constant.\n\n\n1.1.2 Question: Which model explains more variance?\nExpected answer: Model 2 (with two predictors) will typically have a higher R-squared than Model 1. However, students should note:\n\nR-squared always increases when you add predictors\nAdjusted R-squared accounts for the number of predictors\nA higher R-squared doesn‚Äôt always mean a ‚Äúbetter‚Äù model\n\n\n\n1.1.3 Question: Interpret the coefficient for rainfall while ‚Äúcontrolling for‚Äù temperature\nExpected answer: Holding temperature constant, for every 1-unit increase in rainfall, yield changes by [X] units. This is the partial effect of rainfall ‚Äî the effect of rainfall after accounting for the relationship between temperature and yield.\nDiscussion point: With the provided data, temperature and rainfall are correlated. This can lead to:\n\nCoefficients that differ from simple correlations\nLarger standard errors (multicollinearity)\nDifficulty interpreting ‚Äúindependent‚Äù effects"
  },
  {
    "objectID": "materials/answersheet_Version5.html#station-1-salamander-survival-answer",
    "href": "materials/answersheet_Version5.html#station-1-salamander-survival-answer",
    "title": "Week 03 Session B ‚Äî Answer Sheet",
    "section": "2.1 Station 1: Salamander Survival ‚Äî Answer",
    "text": "2.1 Station 1: Salamander Survival ‚Äî Answer\n\n2.1.1 What‚Äôs wrong with the proposed method?\nThe proposed method glm(survival ~ canopy_cover, family = binomial) treats each salamander as an independent observation. But salamanders within the same forest fragment are not independent - they share the same environment, microclimate, predators, etc.\nThe problem: Pseudoreplication. The true sample size is 12 fragments, not 240 salamanders.\n\n\n2.1.2 The correct approach\nUse a generalized linear mixed model (GLMM) with fragment as a random effect:\n\nlibrary(tidyverse)\nlibrary(lme4)\n\n# -------------------------------------------\n# Simulate the data\n# -------------------------------------------\n\nset.seed(123)\n\nn_fragments &lt;- 12\nn_salamanders_per_fragment &lt;- 20\n\n# Create fragment-level data\nfragments &lt;- data.frame(\n  fragment_id = 1:n_fragments,\n  canopy_cover = runif(n_fragments, 30, 90)\n)\n\n# Add fragment-level random effect\n# This represents unmeasured fragment-level variation\nfragments$fragment_effect &lt;- rnorm(n_fragments, 0, 0.8)\n\n# Create individual salamander data\nsalamander_data &lt;- fragments %&gt;%\n  slice(rep(1:n(), each = n_salamanders_per_fragment)) %&gt;%\n  mutate(\n    salamander_id = 1:n(),\n    # True model: logit(survival) = -2 + 0.04*canopy + fragment_effect\n    log_odds = -2 + 0.04 * canopy_cover + fragment_effect,\n    prob_survival = plogis(log_odds),\n    survival = rbinom(n(), 1, prob_survival)\n  )\n\n# -------------------------------------------\n# WRONG approach (ignoring clustering)\n# -------------------------------------------\n\nwrong_model &lt;- glm(survival ~ canopy_cover, \n                   family = binomial, \n                   data = salamander_data)\nsummary(wrong_model)\n\n# -------------------------------------------\n# CORRECT approach (mixed model)\n# -------------------------------------------\n\ncorrect_model &lt;- glmer(survival ~ canopy_cover + (1 | fragment_id), \n                       family = binomial, \n                       data = salamander_data)\nsummary(correct_model)\n\n# -------------------------------------------\n# Compare results\n# -------------------------------------------\n\n# Extract coefficients and SEs\nwrong_coef &lt;- summary(wrong_model)$coefficients\ncorrect_coef &lt;- summary(correct_model)$coefficients\n\ncat(\"WRONG model SE for canopy_cover:\", wrong_coef[\"canopy_cover\", \"Std. Error\"], \"\\n\")\ncat(\"CORRECT model SE for canopy_cover:\", correct_coef[\"canopy_cover\", \"Std. Error\"], \"\\n\")\n\n\n\n2.1.3 What students should observe\n\n\n\n\n\n\n\n\nComparison\nWrong Model\nCorrect Model\n\n\n\n\nStandard error for canopy_cover\nSmaller (artificially precise)\nLarger (realistic)\n\n\np-value\nOften significant\nMay not be significant\n\n\nConclusion\nMay claim strong effect\nMore honest uncertainty\n\n\n\nKey insight: Ignoring the clustering leads to overconfident conclusions because we‚Äôre pretending we have 240 independent observations when we really only have 12 independent units."
  },
  {
    "objectID": "materials/answersheet_Version5.html#station-4-soil-microbial-diversity-answer",
    "href": "materials/answersheet_Version5.html#station-4-soil-microbial-diversity-answer",
    "title": "Week 03 Session B ‚Äî Answer Sheet",
    "section": "2.2 Station 4: Soil Microbial Diversity ‚Äî Answer",
    "text": "2.2 Station 4: Soil Microbial Diversity ‚Äî Answer\n\n2.2.1 Is Kruskal-Wallis wrong, or just overly cautious?\nKruskal-Wallis is not wrong, but it may be unnecessarily conservative for this scenario.\nWhen Kruskal-Wallis is truly needed:\n\nSeverely non-normal data (heavy skew, outliers)\nOrdinal data\nVery small sample sizes where normality can‚Äôt be assessed\nHeterogeneous variances that can‚Äôt be addressed\n\nWhen ANOVA is fine:\n\nSlight skewness (ANOVA is robust to this)\nModerate sample sizes (n ‚â• 10 per group)\nResiduals approximately normal\nSimilar variances across groups\n\n\n\n2.2.2 The comparison\n\nlibrary(tidyverse)\n\n# -------------------------------------------\n# Simulate the data\n# -------------------------------------------\n\nset.seed(456)\n\nn_per_treatment &lt;- 10\n\nsoil_data &lt;- data.frame(\n  treatment = rep(c(\"no_till\", \"reduced_till\", \"conventional\"), each = n_per_treatment),\n  field_id = 1:30\n)\n\n# Simulate slightly right-skewed Shannon diversity\n# True effect: no-till &gt; reduced &gt; conventional\nsoil_data &lt;- soil_data %&gt;%\n  mutate(\n    true_mean = case_when(\n      treatment == \"no_till\" ~ 3.8,\n      treatment == \"reduced_till\" ~ 3.2,\n      treatment == \"conventional\" ~ 2.6\n    ),\n    # Add slight right skew using gamma-like distribution\n    diversity = true_mean + rnorm(n(), 0, 0.5) + rexp(n(), rate = 5)\n  )\n\n# Visualize\nggplot(soil_data, aes(x = treatment, y = diversity)) +\n  geom_boxplot() +\n  geom_jitter(width = 0.1, alpha = 0.5)\n\n# -------------------------------------------\n# Proposed: Kruskal-Wallis\n# -------------------------------------------\n\nkruskal_result &lt;- kruskal.test(diversity ~ treatment, data = soil_data)\nprint(kruskal_result)\n\n# -------------------------------------------\n# Alternative: ANOVA\n# -------------------------------------------\n\nanova_model &lt;- aov(diversity ~ treatment, data = soil_data)\nsummary(anova_model)\n\n# Check assumptions\npar(mfrow = c(2, 2))\nplot(anova_model)\n\n# Post-hoc (only available with ANOVA, not Kruskal-Wallis easily)\nTukeyHSD(anova_model)\n\n\n\n2.2.3 What students should observe\n\n\n\nAspect\nKruskal-Wallis\nANOVA\n\n\n\n\nTests\nDifferences in ranks\nDifferences in means\n\n\nInterpretation\nLess intuitive\nEffect sizes in original units\n\n\nPost-hoc tests\nDunn‚Äôs test (less common)\nTukey HSD (standard)\n\n\nPower\nSlightly lower\nSlightly higher\n\n\n\nKey insight: For slightly skewed but otherwise well-behaved data, ANOVA is often the better choice because:\n\nIt‚Äôs more powerful\nEffect sizes are interpretable\nPost-hoc comparisons are straightforward\nANOVA is robust to moderate violations of normality"
  },
  {
    "objectID": "materials/answersheet_Version5.html#station-6-seedling-germination-answer",
    "href": "materials/answersheet_Version5.html#station-6-seedling-germination-answer",
    "title": "Week 03 Session B ‚Äî Answer Sheet",
    "section": "2.3 Station 6: Seedling Germination ‚Äî Answer",
    "text": "2.3 Station 6: Seedling Germination ‚Äî Answer\n\n2.3.1 What‚Äôs wrong with lm(proportion ~ stratification_time)?\nThree major problems:\n\nBounded response: Proportions are bounded between 0 and 1. Linear regression can predict values outside this range.\nNon-constant variance: Variance of proportions depends on the mean. Near 0 or 1, variance is smaller. This violates homoscedasticity.\nIgnores sample size: A proportion of 0.5 from 10 seeds has more uncertainty than 0.5 from 100 seeds. Linear regression treats them the same.\n\n\n\n2.3.2 The correct approach\nUse binomial GLM with counts (successes and failures):\n\nlibrary(tidyverse)\n\n# -------------------------------------------\n# Simulate the data\n# -------------------------------------------\n\nset.seed(789)\n\nn_dishes &lt;- 10\nn_seeds &lt;- 50\nstrat_times &lt;- c(0, 30, 60, 90)\n\ngermination_data &lt;- expand.grid(\n  dish_id = 1:n_dishes,\n  stratification_time = strat_times\n) %&gt;%\n  mutate(\n    # True relationship: logit(germination) = -1.5 + 0.025 * time\n    log_odds = -1.5 + 0.025 * stratification_time,\n    true_prob = plogis(log_odds),\n    # Simulate germination (binomial process)\n    n_germinated = rbinom(n(), n_seeds, true_prob),\n    n_failed = n_seeds - n_germinated,\n    proportion = n_germinated / n_seeds\n  )\n\n# Visualize\nggplot(germination_data, aes(x = factor(stratification_time), y = proportion)) +\n  geom_boxplot() +\n  geom_jitter(width = 0.1, alpha = 0.5) +\n  labs(x = \"Stratification Time (days)\", y = \"Proportion Germinated\")\n\n# -------------------------------------------\n# WRONG: Linear model on proportions\n# -------------------------------------------\n\nwrong_model &lt;- lm(proportion ~ stratification_time, data = germination_data)\nsummary(wrong_model)\n\n# Check residuals ‚Äî look for heteroscedasticity\npar(mfrow = c(2, 2))\nplot(wrong_model)\n\n# -------------------------------------------\n# CORRECT: Binomial GLM with counts\n# -------------------------------------------\n\ncorrect_model &lt;- glm(cbind(n_germinated, n_failed) ~ stratification_time, \n                     family = binomial, \n                     data = germination_data)\nsummary(correct_model)\n\n# Check for overdispersion\n# Residual deviance / residual df should be approximately 1\nresid_dev &lt;- summary(correct_model)$deviance\nresid_df &lt;- summary(correct_model)$df.residual\ncat(\"Dispersion ratio:\", resid_dev / resid_df, \"\\n\")\n# If &gt;&gt; 1, use quasibinomial or beta-binomial\n\n# -------------------------------------------\n# Compare predictions\n# -------------------------------------------\n\nnew_data &lt;- data.frame(stratification_time = 0:90)\nnew_data$pred_wrong &lt;- predict(wrong_model, new_data)\nnew_data$pred_correct &lt;- predict(correct_model, new_data, type = \"response\")\n\nggplot() +\n  geom_point(data = germination_data, \n             aes(x = stratification_time, y = proportion), alpha = 0.5) +\n  geom_line(data = new_data, \n            aes(x = stratification_time, y = pred_wrong, color = \"Linear Model\")) +\n  geom_line(data = new_data, \n            aes(x = stratification_time, y = pred_correct, color = \"Binomial GLM\")) +\n  labs(y = \"Proportion Germinated\", color = \"Model\") +\n  ylim(0, 1)\n\n\n\n2.3.3 What students should observe\n\n\n\n\n\n\n\n\nIssue\nLinear Model\nBinomial GLM\n\n\n\n\nPredictions at extremes\nCan go below 0 or above 1\nAlways between 0 and 1\n\n\nResidual variance\nHeteroscedastic (funnel shape)\nProperly modeled\n\n\nInterpretation\nAdditive effect on proportion\nMultiplicative effect on odds\n\n\nAccounts for n_seeds\nNo\nYes\n\n\n\nKey insight: When you have count data out of a known total (successes/trials), use cbind(successes, failures) with family = binomial. This properly models the binomial nature of the data."
  },
  {
    "objectID": "materials/answersheet_Version5.html#station-2-wheat-yield-trials-answer",
    "href": "materials/answersheet_Version5.html#station-2-wheat-yield-trials-answer",
    "title": "Week 03 Session B ‚Äî Answer Sheet",
    "section": "3.1 Station 2: Wheat Yield Trials ‚Äî Answer",
    "text": "3.1 Station 2: Wheat Yield Trials ‚Äî Answer\n\n3.1.1 What‚Äôs wrong with aov(yield ~ variety)?\nThe proposed model ignores the block structure of the RCBD (Randomized Complete Block Design). Blocks account for spatial heterogeneity (some blocks may be more fertile).\nConsequences of ignoring blocks:\n\nBlock variation is lumped into residual error\nResidual variance is inflated\nStandard errors are larger\nF-test has less power\nMay miss real treatment effects\n\n\n\n3.1.2 The correct approach\n\nlibrary(tidyverse)\nlibrary(lme4)\nlibrary(emmeans)\n\n# -------------------------------------------\n# Simulate RCBD data\n# -------------------------------------------\n\nset.seed(2024)\n\nvarieties &lt;- c(\"Var_A\", \"Var_B\", \"Var_C\", \"Var_D\", \"Var_E\")\nblocks &lt;- c(\"Block_1\", \"Block_2\", \"Block_3\", \"Block_4\")\n\nwheat_data &lt;- expand.grid(\n  variety = varieties,\n  block = blocks,\n  stringsAsFactors = FALSE\n) %&gt;%\n  mutate(\n    # True variety effects (differences from grand mean)\n    variety_effect = case_when(\n      variety == \"Var_A\" ~ -200,\n      variety == \"Var_B\" ~ 0,\n      variety == \"Var_C\" ~ 400,  # Best variety\n      variety == \"Var_D\" ~ -100,\n      variety == \"Var_E\" ~ 200\n    ),\n    # Block effects (some blocks more fertile)\n    block_effect = case_when(\n      block == \"Block_1\" ~ -400,\n      block == \"Block_2\" ~ -100,\n      block == \"Block_3\" ~ 200,\n      block == \"Block_4\" ~ 300\n    ),\n    # Grand mean + effects + residual error\n    yield = 5000 + variety_effect + block_effect + rnorm(n(), 0, 120)\n  )\n\n# Visualize\nggplot(wheat_data, aes(x = variety, y = yield, color = block)) +\n  geom_point(size = 3) +\n  theme_minimal() +\n  labs(title = \"Wheat Yield by Variety and Block\")\n\n# -------------------------------------------\n# WRONG: Ignoring blocks\n# -------------------------------------------\n\nwrong_model &lt;- aov(yield ~ variety, data = wheat_data)\nsummary(wrong_model)\n\n# Note: Residual MS includes block variation!\n\n# -------------------------------------------\n# CORRECT Option A: Block as fixed effect\n# -------------------------------------------\n\ncorrect_fixed &lt;- aov(yield ~ block + variety, data = wheat_data)\nsummary(correct_fixed)\n\n# Compare residual variance\ncat(\"Wrong model residual MS:\", summary(wrong_model)[[1]][\"Residuals\", \"Mean Sq\"], \"\\n\")\ncat(\"Correct model residual MS:\", summary(correct_fixed)[[1]][\"Residuals\", \"Mean Sq\"], \"\\n\")\n\n# -------------------------------------------\n# CORRECT Option B: Block as random effect\n# -------------------------------------------\n\ncorrect_random &lt;- lmer(yield ~ variety + (1 | block), data = wheat_data)\nsummary(correct_random)\nanova(correct_random)\n\n# -------------------------------------------\n# Post-hoc comparisons\n# -------------------------------------------\n\nemmeans_result &lt;- emmeans(correct_fixed, pairwise ~ variety)\nemmeans_result$contrasts\n\n# Compact letter display\nlibrary(multcomp)\ncld(emmeans_result$emmeans, Letters = letters)\n\n# -------------------------------------------\n# Extension: Publication figure\n# -------------------------------------------\n\n# Get estimated marginal means\nemm &lt;- as.data.frame(emmeans_result$emmeans)\n\nggplot(emm, aes(x = reorder(variety, emmean), y = emmean)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), width = 0.2) +\n  geom_jitter(data = wheat_data, aes(x = variety, y = yield), \n              width = 0.1, alpha = 0.4, color = \"gray50\") +\n  labs(x = \"Variety\", y = \"Yield (kg/ha)\",\n       title = \"Wheat Variety Comparison\",\n       subtitle = \"Points = raw data, Error bars = 95% CI of estimated means\") +\n  theme_minimal()\n\n\n\n3.1.3 Fixed vs.¬†Random blocks?\n\n\n\n\n\n\n\nUse Fixed Block\nUse Random Block\n\n\n\n\nBlocks are exhaustive (these specific blocks)\nBlocks are a sample from a population\n\n\nInterest in specific block differences\nWant to generalize beyond these blocks\n\n\nBlocks are part of the experimental design\nBlocks are nuisance variation\n\n\nTraditional agronomic trials\nMulti-site, multi-year studies\n\n\n\nFor this scenario: Either is defensible. Fixed is more traditional in agronomy; random is more generalizable."
  },
  {
    "objectID": "materials/answersheet_Version5.html#station-3-bird-abundance-over-time-answer",
    "href": "materials/answersheet_Version5.html#station-3-bird-abundance-over-time-answer",
    "title": "Week 03 Session B ‚Äî Answer Sheet",
    "section": "3.2 Station 3: Bird Abundance Over Time ‚Äî Answer",
    "text": "3.2 Station 3: Bird Abundance Over Time ‚Äî Answer\n\n3.2.1 What are the THREE problems with lm(bird_count ~ year)?\n\nNon-normal response: Counts follow Poisson (or negative binomial), not normal distribution\nNon-independence within parks: Multiple observations from the same park are correlated (need random effect for park)\nTemporal pseudoreplication: Multiple visits within years are not independent\n\n\n\n3.2.2 The correct approach\n\nlibrary(tidyverse)\nlibrary(lme4)\nlibrary(glmmTMB)\n\n# -------------------------------------------\n# Simulate repeated measures count data\n# -------------------------------------------\n\nset.seed(303)\n\nn_parks &lt;- 8\nn_years &lt;- 5\nn_visits &lt;- 6\n\nbird_data &lt;- expand.grid(\n  park_id = 1:n_parks,\n  year = 1:n_years,\n  visit = 1:n_visits\n) %&gt;%\n  mutate(\n    # Park-level random intercepts\n    park_effect = rep(rnorm(n_parks, 0, 0.4), each = n_years * n_visits),\n    # Optional: Park-level random slopes (some parks decline faster)\n    park_slope = rep(rnorm(n_parks, 0, 0.05), each = n_years * n_visits),\n    # True model: log(count) = 3.5 - 0.15*year + park_effect + park_slope*year\n    log_mean = 3.5 - 0.15 * year + park_effect + park_slope * year,\n    # Simulate Poisson counts\n    bird_count = rpois(n(), exp(log_mean))\n  )\n\n# Visualize\nggplot(bird_data, aes(x = year, y = bird_count, color = factor(park_id))) +\n  geom_jitter(width = 0.1, alpha = 0.5) +\n  geom_smooth(method = \"glm\", method.args = list(family = \"poisson\"), se = FALSE) +\n  facet_wrap(~ park_id, ncol = 4) +\n  labs(title = \"Bird Counts by Park Over Time\")\n\n# -------------------------------------------\n# WRONG: Linear model ignoring everything\n# -------------------------------------------\n\nwrong_model &lt;- lm(bird_count ~ year, data = bird_data)\nsummary(wrong_model)\n\n# Problems visible in residuals\npar(mfrow = c(2, 2))\nplot(wrong_model)\n\n# -------------------------------------------\n# BETTER: Poisson GLMM with random intercepts\n# -------------------------------------------\n\nbetter_model &lt;- glmer(bird_count ~ year + (1 | park_id), \n                      family = poisson, \n                      data = bird_data)\nsummary(better_model)\n\n# Check for overdispersion\noverdisp &lt;- sum(residuals(better_model, type = \"pearson\")^2) / df.residual(better_model)\ncat(\"Overdispersion ratio:\", overdisp, \"\\n\")\n# If &gt; 1.5, consider negative binomial\n\n# -------------------------------------------\n# BEST: Random slopes (parks decline at different rates)\n# -------------------------------------------\n\nbest_model &lt;- glmer(bird_count ~ year + (1 + year | park_id), \n                    family = poisson, \n                    data = bird_data)\nsummary(best_model)\n\n# Compare models\nanova(better_model, best_model)\n\n# -------------------------------------------\n# Interpretation\n# -------------------------------------------\n\n# The year coefficient is on the log scale\nyear_coef &lt;- fixef(best_model)[\"year\"]\ncat(\"Year effect (log scale):\", year_coef, \"\\n\")\ncat(\"Multiplicative change per year:\", exp(year_coef), \"\\n\")\ncat(\"Percent change per year:\", (exp(year_coef) - 1) * 100, \"%\\n\")\n\n# -------------------------------------------\n# Extension: Negative binomial for overdispersion\n# -------------------------------------------\n\nnb_model &lt;- glmmTMB(bird_count ~ year + (1 + year | park_id), \n                    family = nbinom2, \n                    data = bird_data)\nsummary(nb_model)\n\n\n\n3.2.3 What students should observe\n\n\n\n\n\n\n\nModel\nIssues Addressed\n\n\n\n\nlm(count ~ year)\nNone\n\n\nglm(..., family = poisson)\nCount distribution\n\n\nglmer(... + (1 \\| park))\nCount + park clustering\n\n\nglmer(... + (1 + year \\| park))\nCount + park clustering + varying trends\n\n\nglmmTMB(..., family = nbinom2)\nAll above + overdispersion"
  },
  {
    "objectID": "materials/answersheet_Version5.html#station-5-pollinator-network-complexity-answer",
    "href": "materials/answersheet_Version5.html#station-5-pollinator-network-complexity-answer",
    "title": "Week 03 Session B ‚Äî Answer Sheet",
    "section": "3.3 Station 5: Pollinator Network Complexity ‚Äî Answer",
    "text": "3.3 Station 5: Pollinator Network Complexity ‚Äî Answer\n\n3.3.1 Why is the Bayesian spatial model overkill?\nThe proposed method (Bayesian multilevel model with spatial Gaussian process) would require: - Spatial coordinates (not provided) - Grouping structure for random effects (not present) - Substantial computation time - Expertise in Bayesian methods - Complex model diagnostics\nFor 25 independent meadows with a simple linear relationship, this is massive overkill.\n\n\n3.3.2 The correct approach: Simple linear regression\n\nlibrary(tidyverse)\n\n# -------------------------------------------\n# Simulate simple, well-behaved data\n# -------------------------------------------\n\nset.seed(555)\n\nn_meadows &lt;- 25\n\npollinator_data &lt;- data.frame(\n  meadow_id = 1:n_meadows,\n  plant_richness = round(runif(n_meadows, 5, 45))\n) %&gt;%\n  mutate(\n    # Simple linear relationship with normal errors\n    network_complexity = 1.0 + 0.15 * plant_richness + rnorm(n_meadows, 0, 0.7)\n  )\n\n# Visualize\nggplot(pollinator_data, aes(x = plant_richness, y = network_complexity)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"blue\") +\n  labs(x = \"Plant Species Richness\", \n       y = \"Network Complexity Score\",\n       title = \"Simple Linear Relationship\")\n\n# -------------------------------------------\n# THE CORRECT APPROACH: Simple lm()\n# -------------------------------------------\n\nsimple_model &lt;- lm(network_complexity ~ plant_richness, data = pollinator_data)\nsummary(simple_model)\n\n# Check assumptions\npar(mfrow = c(2, 2))\nplot(simple_model)\n\n# All assumptions met! We're done.\n\n# -------------------------------------------\n# Discussion: When WOULD complexity be needed?\n# -------------------------------------------\n\n# The complex approach would be appropriate if:\n\n# 1. Meadows were grouped (e.g., multiple meadows per region)\n#    ‚Üí Need random intercepts for region\n\n# 2. Repeated measures over time\n#    ‚Üí Need random intercepts for meadow, possibly temporal autocorrelation\n\n# 3. Spatial autocorrelation (nearby meadows more similar)\n#    ‚Üí Need spatial covariance structure (Gaussian process, CAR, etc.)\n\n# 4. Multiple response variables\n#    ‚Üí Need multivariate model\n\n# 5. Prior information from previous studies\n#    ‚Üí Bayesian framework with informative priors\n\n# -------------------------------------------\n# Costs of over-complication\n# -------------------------------------------\n\n# 1. Computation time (hours vs. seconds)\n# 2. More parameters to estimate with limited data (n=25)\n# 3. Harder to interpret and explain\n# 4. More opportunities for errors\n# 5. Reviewers may not understand or trust the analysis\n# 6. May not converge or give unreliable estimates\n# 7. Requires specialized software and expertise\n\n\n\n3.3.3 Key discussion points\nOccam‚Äôs Razor in Statistics: Start with the simplest model that addresses your research question. Add complexity only when:\n\nThe simple model clearly fails (poor fit, violated assumptions)\nThe research question requires it (e.g., estimating variance components)\nThe data structure demands it (e.g., hierarchical, spatial, temporal)\n\nRed flags for unnecessary complexity:\n\n‚ÄúI used a Bayesian spatial model‚Äù for simple cross-sectional data\nRandom effects with &lt; 5 groups\nMore parameters than you can reliably estimate\nMethods chosen to seem sophisticated rather than answer the question"
  },
  {
    "objectID": "materials/answersheet_Version5.html#why-simulate-data",
    "href": "materials/answersheet_Version5.html#why-simulate-data",
    "title": "Week 03 Session B ‚Äî Answer Sheet",
    "section": "4.1 Why simulate data?",
    "text": "4.1 Why simulate data?\n\nForces you to understand the data-generating process ‚Äî You can‚Äôt simulate what you don‚Äôt understand\nCreates known ‚Äútruth‚Äù to compare methods against ‚Äî You know the true effect size\nReveals how methods fail ‚Äî See the consequences of wrong choices\nBuilds intuition ‚Äî Understand what different parameters do\nUseful for power analysis ‚Äî Before collecting real data"
  },
  {
    "objectID": "materials/answersheet_Version5.html#common-themes-across-stations",
    "href": "materials/answersheet_Version5.html#common-themes-across-stations",
    "title": "Week 03 Session B ‚Äî Answer Sheet",
    "section": "4.2 Common themes across stations",
    "text": "4.2 Common themes across stations\n\n\n\n\n\n\n\n\nStation\nMain Issue\nLesson\n\n\n\n\n1 (Salamander)\nPseudoreplication\nKnow your unit of replication\n\n\n2 (Wheat)\nIgnoring design structure\nUse the structure you designed\n\n\n3 (Birds)\nMultiple violations\nMatch method to data structure\n\n\n4 (Soil)\nOvercautious\nDon‚Äôt be afraid of parametric tests\n\n\n5 (Pollinator)\nOverkill\nSimpler is often better\n\n\n6 (Germination)\nWrong distribution\nMatch distribution to response type"
  },
  {
    "objectID": "materials/answersheet_Version5.html#signs-youve-chosen-the-wrong-method",
    "href": "materials/answersheet_Version5.html#signs-youve-chosen-the-wrong-method",
    "title": "Week 03 Session B ‚Äî Answer Sheet",
    "section": "4.3 Signs you‚Äôve chosen the wrong method",
    "text": "4.3 Signs you‚Äôve chosen the wrong method\n\nResidual plots look terrible\nPredictions outside possible range\nStandard errors that seem too small (pseudoreplication)\nModel won‚Äôt converge\nResults don‚Äôt make biological sense\nYou can‚Äôt explain what the model is doing"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SNR 690 ‚Äî Contemporary Approaches to Quantitative Methods",
    "section": "",
    "text": "Welcome to the course materials for SNR 690.\nInstructor: Dr.¬†Alejandro Molina-Moctezuma\nCredits: 3\nFormat: 2 sessions per week (75 minutes each)\nSemester: Spring 2026\nThis book contains the syllabus, weekly readings, assignments, projects, papers, code notebooks, and everything we do in this class. This website will be a collaborative process.\nWe will be updating this landing page as the course goes on!"
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "SNR 690 ‚Äî Contemporary Approaches to Quantitative Methods",
    "section": "Resources",
    "text": "Resources\nthis section will be updated regularly If you are struggling with R or RStudio, check out these resources:\nWickham Wickham, √áetinkaya-Rundel, and Grolemund (2023) here: https://r4ds.had.co.nz/\nData science in R: A gentle introduction https://bookdown.org/jgscott/DSGI/\nAnd check the materials of my SNR 610 course here: https://moctezumaii.github.io/SNR610/\nWhere you can access info regarding R and models."
  },
  {
    "objectID": "index.html#links-and-inforrmation",
    "href": "index.html#links-and-inforrmation",
    "title": "SNR 690 ‚Äî Contemporary Approaches to Quantitative Methods",
    "section": "Links and inforrmation:",
    "text": "Links and inforrmation:\nSyllabus\nWhat are we doing this week? ‚Äì&gt; Here you will fin what papers to read, and have an idea of what each class is going to look like!\nContact Information and office hours: Find me in my office ANRB 474! üòÉ"
  },
  {
    "objectID": "materials/sixq.html",
    "href": "materials/sixq.html",
    "title": "Week 03 ‚Äî Wall Questions",
    "section": "",
    "text": "Your task: - Move freely around the room - Use markers to write on ANY of the questions (words, phrases, questions, drawings) - Read what others wrote - Add +1, arrows, or comments to build on others‚Äô ideas - No names required\n\n\n\n\n\n\nReflection Prompts\n\n\n\n\nMy research question is (one sentence): ## The Six Questions\n\nWall 1: ‚ÄúWhat‚Äôs the hardest thing about data analysis for you?‚Äù\nWall 2: ‚ÄúWhat‚Äôs the gap between what you learned in stats class and what you actually need/use?‚Äù\nWall 3: ‚ÄúWhat do you wish your advisor/committee understood about statistical analysis?‚Äù\nWall 4: ‚ÄúWhat statistical concept do you pretend to understand but actually don‚Äôt?‚Äù\nWall 5: ‚ÄúWhat do you want to learn in this class?‚Äù\nWall 6: ‚ÄúDo you ever feel like you are doing analyses that you do not understand or that might be wrong, but don‚Äôt know why? If yes, explain‚Äù"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Final Paper Instructions",
    "section": "",
    "text": "This assignment guides you through creating a research project repository and developing your final paper proposal."
  },
  {
    "objectID": "projects/index.html#overview",
    "href": "projects/index.html#overview",
    "title": "Final Paper Instructions",
    "section": "",
    "text": "This assignment guides you through creating a research project repository and developing your final paper proposal."
  },
  {
    "objectID": "projects/index.html#step-1-create-a-private-github-repository",
    "href": "projects/index.html#step-1-create-a-private-github-repository",
    "title": "Final Paper Instructions",
    "section": "2 Step 1: Create a Private GitHub Repository",
    "text": "2 Step 1: Create a Private GitHub Repository\n\nGo to GitHub and log in\nClick the ‚Äú+‚Äù icon in the top-right corner and select ‚ÄúNew repository‚Äù\nName your repository (e.g., SNR690-final-paper-yourname)\nAdd a brief description of your project\nImportant: Select ‚ÄúPrivate‚Äù to keep your work confidential\nCheck ‚ÄúAdd a README file‚Äù\nClick ‚ÄúCreate repository‚Äù"
  },
  {
    "objectID": "projects/index.html#step-2-clone-repository-to-rstudio",
    "href": "projects/index.html#step-2-clone-repository-to-rstudio",
    "title": "Final Paper Instructions",
    "section": "3 Step 2: Clone Repository to RStudio",
    "text": "3 Step 2: Clone Repository to RStudio\n\nIn your new GitHub repository, click the green ‚ÄúCode‚Äù button\nCopy the HTTPS URL\nOpen RStudio\nGo to File &gt; New Project &gt; Version Control &gt; Git\nPaste the repository URL\nChoose a local directory and click ‚ÄúCreate Project‚Äù"
  },
  {
    "objectID": "projects/index.html#step-3-modify-the-readme",
    "href": "projects/index.html#step-3-modify-the-readme",
    "title": "Final Paper Instructions",
    "section": "4 Step 3: Modify the README",
    "text": "4 Step 3: Modify the README\nEdit your README.md file to include the following sections:\n\n4.1 Objective\nWhat do you aim to accomplish with this research?\n\n\n4.2 Research Question\nWhat specific question are you trying to answer?\n\n\n4.3 Variables\nList your response variable(s) and predictor variable(s)\n\n\n4.4 Experimental Design or Data Structure\nDescribe your data collection approach or existing dataset structure\n\n\n4.5 Analysis Method\nWhat statistical method(s) will you use?\n\n\n4.6 Main Result\nWhat do you expect to find or demonstrate?\n\n\n4.7 Logical Alignment\nDo these components align logically? Explain briefly how your methods will answer your research question.\n\n\n4.8 Expected Timeline\nCreate a week-by-week plan from Week 6 through Week 14 outlining your anticipated progress on the final paper. For each week, write a brief description of what you plan to accomplish (e.g., data cleaning, running analyses, drafting the methods section). This timeline should be realistic and account for your other coursework and obligations. You will use this as a self-assessment tool throughout the semester: revisiting and updating it as you progress.\n\n\n4.9 Usefulness for Your Career or Degree\nBriefly describe how this project connects to your thesis or your broader academic or professional goals. How does working through this research question and analysis contribute to your development as a researcher or practitioner in your field? Does it help you with your thesis/dissertation? This section should demonstrate that the project is not just an academic exercise, but an opportunity to apply appropriate quantitative approaches to a problem that is meaningful and relevant to your own research trajectory"
  },
  {
    "objectID": "projects/index.html#example-project-template",
    "href": "projects/index.html#example-project-template",
    "title": "Final Paper Instructions",
    "section": "5 Example Project Template",
    "text": "5 Example Project Template\nObjective: Assess the impact of habitat restoration on native bird species richness in riparian zones\nResearch Question: Does riparian habitat restoration increase native bird species richness compared to unrestored sites?\nVariables: - Response: Bird species richness (count) - Predictors: Restoration status (restored/unrestored), time since restoration (years), habitat area (hectares)\nExperimental Design or Data Structure: Observational study with 20 restored and 20 unrestored riparian sites across Arizona, sampled over 3 breeding seasons\nAnalysis Method: Generalized Linear Mixed Model (Poisson regression) with site as random effect to account for repeated measures\nMain Result: Restored sites are expected to show significantly higher species richness, with effect size increasing with time since restoration\nLogical Alignment: Yes - the GLMM approach handles count data (species richness) and accounts for site-level variation while testing the restoration effect. The temporal component allows assessment of restoration trajectory, directly addressing whether and how restoration increases bird diversity."
  },
  {
    "objectID": "slides/notes-week01.html#zuur-paper-a-protocol-for-data-exploration-to-avoid-common-statistical-problems",
    "href": "slides/notes-week01.html#zuur-paper-a-protocol-for-data-exploration-to-avoid-common-statistical-problems",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Zuur paper: A protocol for data exploration to avoid common statistical problems",
    "text": "Zuur paper: A protocol for data exploration to avoid common statistical problems\n\nZuur et al., 2010. A protocol for data exploration to avoid common statistical problems. Methods in Ecology and Evolution. 1(1):3-14. https://doi.org/10.1111/j.2041-210X.2009.00001.x"
  },
  {
    "objectID": "slides/notes-week01.html#why-is-data-exploration-important",
    "href": "slides/notes-week01.html#why-is-data-exploration-important",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Why is data exploration important?",
    "text": "Why is data exploration important?\nSee if assumptions are met Identify outliers Understand data structure"
  },
  {
    "objectID": "slides/notes-week01.html#discussion",
    "href": "slides/notes-week01.html#discussion",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Discussion",
    "text": "Discussion\nZuur paper makes the point that we should always explore our data before doing inferential analyses. However, Tredennick argues that exploration and inference should come from idnependent studies. How can we reconcile these views?"
  },
  {
    "objectID": "slides/notes-week01.html#equal-variance",
    "href": "slides/notes-week01.html#equal-variance",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Equal variance",
    "text": "Equal variance\nNever happens in real world data"
  },
  {
    "objectID": "slides/notes-week01.html#normal-data",
    "href": "slides/notes-week01.html#normal-data",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Normal data",
    "text": "Normal data\nNever happens in real world data"
  },
  {
    "objectID": "slides/notes-week01.html#covariates",
    "href": "slides/notes-week01.html#covariates",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Covariates",
    "text": "Covariates\nCheck for correlation among covariates"
  },
  {
    "objectID": "slides/notes-week01.html#zero-inflated-data",
    "href": "slides/notes-week01.html#zero-inflated-data",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Zero inflated data",
    "text": "Zero inflated data\nCheck for excess zeros Mix count and logistic data: hurdle models, zero-inflated models Cluster"
  },
  {
    "objectID": "slides/notes-week01.html#vif",
    "href": "slides/notes-week01.html#vif",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "VIF",
    "text": "VIF\nHow much is too much?"
  },
  {
    "objectID": "slides/notes-week01.html#zuur",
    "href": "slides/notes-week01.html#zuur",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Zuur",
    "text": "Zuur\nThe point they make is to use exploration as a tool to protect inference, not create it.\n\nBy exploration, Zuur means checking assumptions, understanding data structure, and identifying potential issues.\nThe goal is to ensure that the data meets the assumptions required for valid inference.\nIt is non-inferential."
  },
  {
    "objectID": "slides/notes-week01.html#tredennick",
    "href": "slides/notes-week01.html#tredennick",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Tredennick",
    "text": "Tredennick\nTredennick argues that exploration and inference should come from independent studies.\n\nBy exploration, Tredennick means generating hypotheses and insights from the data.\nThe goal is to generate hypothesis from observed patterns.\nIf you observe a pattern and then test it in the same data, you risk overfitting and false positives."
  },
  {
    "objectID": "slides/notes-week01.html#discussion-1",
    "href": "slides/notes-week01.html#discussion-1",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Discussion",
    "text": "Discussion\nHow important is subject-matter expertise when exploring data? Can we rely solely on statistical techniques for exploration?\n\nDoes subject matter expertise introduce bias?\nCan other techniques like Bayesian methods help us introduce subject matter with less bias?"
  },
  {
    "objectID": "slides/notes-week01.html#we-never-meet-assumptions",
    "href": "slides/notes-week01.html#we-never-meet-assumptions",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "We never meet assumptions",
    "text": "We never meet assumptions\n\nReal world data won‚Äôt fit assumptions (e.g., there won‚Äôt be a perfectly normal distribution)\nWhen exploring the data, how close is close enough? Do modeling objectives matter when making these decisions?"
  },
  {
    "objectID": "slides/notes-week01.html#who-here-starts-analyzing-data-without-exploring-it-first",
    "href": "slides/notes-week01.html#who-here-starts-analyzing-data-without-exploring-it-first",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Who here starts analyzing data without exploring it first?",
    "text": "Who here starts analyzing data without exploring it first?\n\nBased on hypothesis, and a-priori methods"
  },
  {
    "objectID": "slides/notes-week01.html#in-your-projects-do-you-use-prediction-inference-or-exploration",
    "href": "slides/notes-week01.html#in-your-projects-do-you-use-prediction-inference-or-exploration",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "In your projects, do you use prediction, inference or exploration?",
    "text": "In your projects, do you use prediction, inference or exploration?\n\nWhy?\nExploration ‚Äì&gt; inductive\nInference ‚Äì&gt; deductive"
  },
  {
    "objectID": "slides/notes-week01.html#explorations-vs-inference",
    "href": "slides/notes-week01.html#explorations-vs-inference",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "Explorations vs inference",
    "text": "Explorations vs inference\nIn your view, which is more fundamental for scientific progress: carefully testing well-specified hypotheses, or exploring data and phenomena to see what patterns emerge? Why? Does your answer change depending on the stage of a research program?"
  },
  {
    "objectID": "slides/notes-week01.html#for-your-project",
    "href": "slides/notes-week01.html#for-your-project",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "For your project",
    "text": "For your project\nIn your project, imagine you are doing a purely exploratory study. What would you actually want to look at, play with, or visualize in your system? Be concrete about: what you‚Äôd plot, what relationships you‚Äôd inspect, and what patterns you‚Äôd hope to notice"
  },
  {
    "objectID": "slides/notes-week01.html#for-your-project-1",
    "href": "slides/notes-week01.html#for-your-project-1",
    "title": "Week 01, Session A: Introduction to Class",
    "section": "For your project",
    "text": "For your project\nNow, for the same system, write one clear, testable hypothesis. State exactly what you expect to see, how you‚Äôd measure it, and which model or statistical test you would use to evaluate it"
  },
  {
    "objectID": "slides/slides-Week02.html#objective-for-today",
    "href": "slides/slides-Week02.html#objective-for-today",
    "title": "Week 2: Philosophical concepts in data analysis",
    "section": "Objective for today",
    "text": "Objective for today\nThe objective for the first three weeks is to step back and think and talk about statistics and data analysis from a philosophical and epistemological perspective\n\nChallenges:\nToo technical\nTerminology\nMath-heavy\nKinda boring"
  },
  {
    "objectID": "slides/slides-Week02.html#class-today",
    "href": "slides/slides-Week02.html#class-today",
    "title": "Week 2: Philosophical concepts in data analysis",
    "section": "Class today",
    "text": "Class today\n\nWrap up last lecture/discussion on data exploration\nHave a lecture on Tredennick.\nStart to discuss the Bayesian Inference paper.\nObjective: further your understanding of foundational concepts in data analysis."
  },
  {
    "objectID": "slides/slides-Week02.html#paper-discussions-last-week",
    "href": "slides/slides-Week02.html#paper-discussions-last-week",
    "title": "Week 2: Philosophical concepts in data analysis",
    "section": "Paper discussions (last week)",
    "text": "Paper discussions (last week)\nLast class we had Team 1 talk about ‚Äúdata exploration‚Äù\n\nEssentially, a protocol for ‚Äúpre-modeling‚Äù data analysis\nWhy is it important?"
  },
  {
    "objectID": "slides/slides-Week02.html#questions-from-last-team",
    "href": "slides/slides-Week02.html#questions-from-last-team",
    "title": "Week 2: Philosophical concepts in data analysis",
    "section": "Questions from last team",
    "text": "Questions from last team\n\nWhat kind of data do you have and how have you thought about approaching it?‚Äã\nWhat kinds of datasets (or distributions) that would be an exception to these rules?‚Äã *Rules presented last week\nHow can you tell between an actual outlier and observational error? ‚Äã\nHow might you prevent these errors before they happen?‚Äã"
  },
  {
    "objectID": "slides/slides-Week02.html#question-from-me",
    "href": "slides/slides-Week02.html#question-from-me",
    "title": "Week 2: Philosophical concepts in data analysis",
    "section": "Question from me:",
    "text": "Question from me:\n\nFor Thursday we will read the Box (1976) paper that has the following quote:\n‚ÄúSince all models are wrong, the scientist must be alert to what is importantly wrong. It is inappropriate to be concerned about mice when there are tigers abroad.‚Äù\nHow does this quote relate to last week‚Äôs lecture?"
  },
  {
    "objectID": "slides/slides-Week02.html#goal-of-exploration",
    "href": "slides/slides-Week02.html#goal-of-exploration",
    "title": "Week 2: Philosophical concepts in data analysis",
    "section": "Goal of exploration",
    "text": "Goal of exploration\nThe goal is not to make a perfect model (impossible) but to detect the problems that will meaningfully distort your conclusions\n\n‚ÄúTigers‚Äù are the problems that will meaningfully distort your conclusions\n‚ÄúMice‚Äù are the problems that will not meaningfully distort your conclusions\nThere will always be ‚Äúmice‚Äù in your data!"
  },
  {
    "objectID": "slides/slides-Week02.html#spherical-cow",
    "href": "slides/slides-Week02.html#spherical-cow",
    "title": "Week 2: Philosophical concepts in data analysis",
    "section": "Spherical cow",
    "text": "Spherical cow\n\nThe joke is designed to poke fun at theorists for making unrealistic assumptions in order to simplify a problem to make it easier to solve (or solvable at all).\nWe do this with scientific assumptions all the time. We assume our data is normal, independent, linear and homoscedastic"
  },
  {
    "objectID": "slides/slides-Week02.html#lecture-on-tredennick-et-al.-2021",
    "href": "slides/slides-Week02.html#lecture-on-tredennick-et-al.-2021",
    "title": "Week 2: Philosophical concepts in data analysis",
    "section": "Lecture on Tredennick et al.¬†2021",
    "text": "Lecture on Tredennick et al.¬†2021\nNow we will have Team 2 give a lecture on Tredennick et al.¬†2021 Tredennick et al. (2021)"
  },
  {
    "objectID": "slides/slides-Week02.html#discussion-on-ellison-2004",
    "href": "slides/slides-Week02.html#discussion-on-ellison-2004",
    "title": "Week 2: Philosophical concepts in data analysis",
    "section": "Discussion on Ellison 2004",
    "text": "Discussion on Ellison 2004\n\nRaise your hand if you understand theoretically what Bayesian inference is\nRemember‚Ä¶ it is mostly a philosophical alternative to frequentist inference\nRaise your hand if you have used Bayesian inference in practice (e.g., run a Bayesian model)"
  },
  {
    "objectID": "slides/slides-Week02.html#difference-in-philosophy",
    "href": "slides/slides-Week02.html#difference-in-philosophy",
    "title": "Week 2: Philosophical concepts in data analysis",
    "section": "Difference in philosophy",
    "text": "Difference in philosophy\n\nDifference in how they observe probability\nFrequentist: long-run frequency of repeatable events\nFrequentist: if the null hypothesis is true, and I ran this experiment 100 times, I would get results as extreme as this less than 5% of the time\nBayesian: degree of belief in a hypothesis given the data observed"
  },
  {
    "objectID": "slides/slides-Week02.html#coin-toss-example-7-heads-in-10-tosses",
    "href": "slides/slides-Week02.html#coin-toss-example-7-heads-in-10-tosses",
    "title": "Week 2: Philosophical concepts in data analysis",
    "section": "coin toss example: 7 heads in 10 tosses",
    "text": "coin toss example: 7 heads in 10 tosses\n\nFrequentist: Null hypothesis: coin is fair (p = 0.5)\nFrequentists: Assuming that the null is true, I would observe an event as extreme or more extreme than this (7 or more heads in 10 tosses) about 17% of the time (p = 0.17. )\nBayesian: given the data I have observed, and having no prior information, I believe that chances are that the coin is unfair. There is about an 89% chance that the coin is biased towards heads (p &gt; 0.5)"
  },
  {
    "objectID": "slides/slides-Week02.html#different-questions",
    "href": "slides/slides-Week02.html#different-questions",
    "title": "Week 2: Philosophical concepts in data analysis",
    "section": "Different questions",
    "text": "Different questions\n\nThe frequentist p = 0.17 answers a different question: ‚ÄúIf the coin were exactly fair, how often would I see 7 or more heads in 10 tosses?‚Äù (about 17%). It does not give the probability the coin is biased.\nThe Bayesian answer gives the probability that Œ∏ &gt; 0.5"
  },
  {
    "objectID": "slides/slides-Week02.html#prior-information",
    "href": "slides/slides-Week02.html#prior-information",
    "title": "Week 2: Philosophical concepts in data analysis",
    "section": "Prior information",
    "text": "Prior information\n\nBayesian inference allows you to incorporate prior information\nPrior information can come from previous studies, expert opinion, or logical constraints\nThis is done through the prior distribution\nThe result of the posterior distribution is a combination of the prior and the likelihood of the data"
  },
  {
    "objectID": "slides/slides-Week02.html#example-of-prior-information",
    "href": "slides/slides-Week02.html#example-of-prior-information",
    "title": "Week 2: Philosophical concepts in data analysis",
    "section": "Example of prior information",
    "text": "Example of prior information\nWe use prior information in our daily lives all the time"
  },
  {
    "objectID": "slides/slides-Week02.html#cleveland-browns-and-bayesian-thinking",
    "href": "slides/slides-Week02.html#cleveland-browns-and-bayesian-thinking",
    "title": "Week 2: Philosophical concepts in data analysis",
    "section": "Cleveland Browns and Bayesian Thinking",
    "text": "Cleveland Browns and Bayesian Thinking\n\nYou check the score: the Browns are up 21 to 7 at halftime against the Ravens.\nAt the same time, the Chiefs are up 21 to 7 at halftime against the Jets\nIn frequentist probability, you would think:\n‚ÄúProbability of winning when going 21-7 is about 80%‚Äù\nBut! yous have priors‚Ä¶ if you are a Browns fan:\n\n\\[ \\text{Posterior belief} \\propto \\text{Prior (they find ways to lose)} \\times \\text{New data (they‚Äôre winning now)} \\]\n\nEssentially, you know that they tend to find ways to lose\nYou may be expecting heartbreak, despite the data (21-7)\nA Chiefs fan, at this point, might not be worried at all"
  },
  {
    "objectID": "slides/slides-Week02.html#now-about-the-paper",
    "href": "slides/slides-Week02.html#now-about-the-paper",
    "title": "Week 2: Philosophical concepts in data analysis",
    "section": "Now‚Ä¶ about the paper",
    "text": "Now‚Ä¶ about the paper\n\nShare in pairs one thing you learned reading this paper (or something that it made you think about)\n\n\n\n\n\nTredennick, Andrew T., Giles Hooker, Stephen P. Ellner, and Peter B. Adler. 2021. ‚ÄúA Practical Guide to Selecting Models for Exploration, Inference, and Prediction in Ecology.‚Äù Ecology 102 (6): e03336. https://doi.org/10.1002/ecy.3336."
  },
  {
    "objectID": "slides/slides-Week04.html#welcome-to-week-4",
    "href": "slides/slides-Week04.html#welcome-to-week-4",
    "title": "Version Control, Git & Collaboration",
    "section": "Welcome to Week 4",
    "text": "Welcome to Week 4\nTopic: Version Control, Git & Collaboration\n\nToday we connect how you think about data analysis to how you track your analytical decisions.\n\n\n\n‚ÄúYour analytical decisions need to be tracked, transparent, and reproducible - Git makes this possible.‚Äù This is, at it‚Äôs core, not just useful It follows the scientific iterative process!"
  },
  {
    "objectID": "slides/slides-Week04.html#before-we-start",
    "href": "slides/slides-Week04.html#before-we-start",
    "title": "Version Control, Git & Collaboration",
    "section": "Before we start",
    "text": "Before we start\nLast week was tough. Some things that made it complicated:\n\nSimulations are hard ‚Äì&gt; Generalized Linear Models\nWorking in large groups\nEveryone coding separately, and trying things without a shared system for tracking changes"
  },
  {
    "objectID": "slides/slides-Week04.html#the-semester-so-far",
    "href": "slides/slides-Week04.html#the-semester-so-far",
    "title": "Version Control, Git & Collaboration",
    "section": "The Semester So Far",
    "text": "The Semester So Far\n\n\n\n\n\n\n\n\nWeek\nTopic\nKey Takeaway\n\n\n\n\n1\nIntroductions & Papers\nData exploration protects inference (Zuur); always explore before modeling\n\n\n2\nPhilosophy of Data Analysis\n‚ÄúAll models are wrong‚Äù (Box); find the useful model, not the true one. Also, the best model is based on your obejctives (prediction vs inference vs exploration)\n\n\n3\nStatistical Modeling Framework\nMethod-Question-Data Triangle must align; start simple\n\n\n4\nVersion Control & Collaboration\nTrack, share, and reproduce your analytical journey"
  },
  {
    "objectID": "slides/slides-Week04.html#why-are-we-talking-about-this",
    "href": "slides/slides-Week04.html#why-are-we-talking-about-this",
    "title": "Version Control, Git & Collaboration",
    "section": "Why Are We Talking About This?",
    "text": "Why Are We Talking About This?\nIn Weeks 1‚Äì3, we talked about how to think about data analysis‚Ä¶\n\n\nWeek 1: Data exploration and inference are separate - but both must be documented\n\n\n\n\nWeek 2: All models are wrong but some are useful - how do you record which ones you tried? In case it is an iterative process\n\n\n\n\nWeek 3: The Method-Question-Data Triangle - when you iterate through model choices, how do you track that evolution?\n\n\n\nVersion control answers all of these questions."
  },
  {
    "objectID": "slides/slides-Week04.html#version-control-as-a-tool",
    "href": "slides/slides-Week04.html#version-control-as-a-tool",
    "title": "Version Control, Git & Collaboration",
    "section": "Version Control as a tool",
    "text": "Version Control as a tool\n\nIt can also be a very good tool to have. I have applied at jobs, that specifically asked for this. In the future, as more collaborative projects deal with complex models, version control will be a must-have skill AI is expanding the ability to code and do data analysis, which will increase potential collaboration ‚Äì&gt; source control becomes even more important More importantly‚Ä¶ if you are doing science, it should be reproducible."
  },
  {
    "objectID": "slides/slides-Week04.html#learning-objectives",
    "href": "slides/slides-Week04.html#learning-objectives",
    "title": "Version Control, Git & Collaboration",
    "section": "üéØ Learning Objectives",
    "text": "üéØ Learning Objectives\n\nBy the end of the week, you will be able to:\n\nExplain why version control matters for reproducible research\nConnect version control to themes from Weeks 1‚Äì3\nUse Git and GitHub for basic version control\nCollaborate using branches and pull requests\nApply version control to a Quarto-based workflow"
  },
  {
    "objectID": "slides/slides-Week04.html#useful-for-the-rest-of-the-semester",
    "href": "slides/slides-Week04.html#useful-for-the-rest-of-the-semester",
    "title": "Version Control, Git & Collaboration",
    "section": "Useful for the rest of the semester",
    "text": "Useful for the rest of the semester\nWe will collaborate\nThis will make it easier"
  },
  {
    "objectID": "slides/slides-Week04.html#activity-retrieval-practice-8-min",
    "href": "slides/slides-Week04.html#activity-retrieval-practice-8-min",
    "title": "Version Control, Git & Collaboration",
    "section": "Activity: Retrieval Practice (8 min)",
    "text": "Activity: Retrieval Practice (8 min)\nNo notes, no phones, no laptops\n\nStruggling to recall is the point ‚Äî it strengthens memory!\n\n\nQuick-Fire Recall (write on paper, 3 min)\n\n\nWhat did Zuur argue about data exploration?\nWhat is Box‚Äôs famous quote about models?\nWhat were the three scenarios from Week 3?\nExplain one experiment from Week 3 ‚Äî what went wrong?\nWhat is the Golden Rule from Week 3?\n\n\n\nNotes ‚Äì&gt; start simple, add complexity, justify complexity\n\n. . .\nDebrief (5 min): Turn to a neighbor and compare answers."
  },
  {
    "objectID": "slides/slides-Week04.html#why-retrieval-practice",
    "href": "slides/slides-Week04.html#why-retrieval-practice",
    "title": "Version Control, Git & Collaboration",
    "section": "Why Retrieval Practice?",
    "text": "Why Retrieval Practice?\n\nResearch shows that actively recalling information ‚Äî even when it‚Äôs difficult ‚Äî produces stronger long-term retention than re-reading notes (Roediger & Butler, 2011).\n\n\nThis is a ‚Äúdesirable difficulty.‚Äù If it felt hard, that‚Äôs good!"
  },
  {
    "objectID": "slides/slides-Week04.html#activity-predict-observe-explain-12-min",
    "href": "slides/slides-Week04.html#activity-predict-observe-explain-12-min",
    "title": "Version Control, Git & Collaboration",
    "section": "Activity: Predict-Observe-Explain (12 min)",
    "text": "Activity: Predict-Observe-Explain (12 min)\nQuick Poll: Raise your hand if you‚Äôve ever‚Ä¶\n\n\nLost work because you overwrote a file\nMade a change in your code and wished you had the old version as well\nCouldn‚Äôt remember why you changed something in your code/analysis\nHad a collaborator edit the same file\nHad a folder full of _v2, _v3, _FINAL files"
  },
  {
    "objectID": "slides/slides-Week04.html#predict",
    "href": "slides/slides-Week04.html#predict",
    "title": "Version Control, Git & Collaboration",
    "section": "üîÆ PREDICT",
    "text": "üîÆ PREDICT\nHere is a scenario. Predict what will go wrong:\n\nYour folder looks like this:\nanalysis.R\nanalysis_v2.R\nanalysis_FINAL.R\nanalysis_FINAL_v2.R\nanalysis_FINAL_ACTUALLY_FINAL.R\nanalysis_FINAL_ACTUALLY_FINAL_USE_THIS_ONE.R\nYour advisor emails: ‚ÄúThe reviewer wants to see the version where you used the Poisson model instead of the linear model.‚Äù\n\n\nWrite down: What happens next? Can you even find it?"
  },
  {
    "objectID": "slides/slides-Week04.html#predict-3-min",
    "href": "slides/slides-Week04.html#predict-3-min",
    "title": "Version Control, Git & Collaboration",
    "section": "üîÆ PREDICT (3 min)",
    "text": "üîÆ PREDICT (3 min)\nHere is an alternative scenario. Predict what will go wrong:\n\nYou have a single file: analysis.R Your advisor emails: ‚ÄúThe reviewer wants to see the version where you used the Poisson model instead of the linear model.‚Äù\n\n\nWrite down: What happens next? Can you even find it?"
  },
  {
    "objectID": "slides/slides-Week04.html#observe",
    "href": "slides/slides-Week04.html#observe",
    "title": "Version Control, Git & Collaboration",
    "section": "üëÅÔ∏è OBSERVE",
    "text": "üëÅÔ∏è OBSERVE\nI will now demonstrate how version control solves this problem.\n\nWatch how Git lets us travel through time in our project‚Ä¶"
  },
  {
    "objectID": "slides/slides-Week04.html#explain-5-min-whole-class",
    "href": "slides/slides-Week04.html#explain-5-min-whole-class",
    "title": "Version Control, Git & Collaboration",
    "section": "üí° EXPLAIN (5 min ‚Äî whole class)",
    "text": "üí° EXPLAIN (5 min ‚Äî whole class)\nAs a class, answer:\n\n\nWhy does the file-naming approach fail? (What information is lost?)\n\n\n\n\nWhat does Git preserve that file-naming doesn‚Äôt?\n\n\n\n\nCan you connect this to Box‚Äôs ‚Äúall models are wrong‚Äù idea?\n\n\n\n\nIf you‚Äôre iterating through models, you need a record of which wrong models you tried and why you moved on."
  },
  {
    "objectID": "slides/slides-Week04.html#activity-elaborative-interrogation",
    "href": "slides/slides-Week04.html#activity-elaborative-interrogation",
    "title": "Version Control, Git & Collaboration",
    "section": "Activity: Elaborative Interrogation",
    "text": "Activity: Elaborative Interrogation\nAsking ‚Äúwhy?‚Äù and ‚Äúhow?‚Äù until you reach deep understanding.\n\nRound 1: ‚ÄúWhy‚Äù Chain\nWith a partner, take turns asking ‚Äúwhy?‚Äù about this statement. Go at least four levels deep:\n\n‚ÄúResearchers should use version control for their analyses.‚Äù"
  },
  {
    "objectID": "slides/slides-Week04.html#round-2-connect-to-a-specific-week-5-min",
    "href": "slides/slides-Week04.html#round-2-connect-to-a-specific-week-5-min",
    "title": "Version Control, Git & Collaboration",
    "section": "Round 2: Connect to a Specific Week (5 min)",
    "text": "Round 2: Connect to a Specific Week (5 min)\nEach pair picks two statements.\nAnd you do the why? and how? chain for each one.\n\nData exploration should protect inference, not create it. (Zuur, Week 1)\nAll models are wrong, but some are useful.‚Äù (Box, Week 2)\n‚ÄúStart simple. Add complexity only when needed. Always justify your choices.‚Äù (Golden Rule, Week 3)\n‚ÄúMisalignment between method, question, and data leads to wrong conclusions, wasted effort, rejected papers, and sad grad students.‚Äù (Week 3)\n‚ÄúExploration and inference should come from independent studies. (Tredennick, Week 1)\n\n\nShare Out (2‚Äì3 min): 3‚Äì4 pairs share their best sentence."
  },
  {
    "objectID": "slides/slides-Week04.html#lecture-what-is-version-control",
    "href": "slides/slides-Week04.html#lecture-what-is-version-control",
    "title": "Version Control, Git & Collaboration",
    "section": "Lecture: What is Version Control?",
    "text": "Lecture: What is Version Control?\n\nA system that records changes to files over time\n\n\nYou can recall any previous version at any time\n\n\nThink of it as Track Changes for your entire project ‚Äî but much more powerful"
  },
  {
    "objectID": "slides/slides-Week04.html#why-git-specifically",
    "href": "slides/slides-Week04.html#why-git-specifically",
    "title": "Version Control, Git & Collaboration",
    "section": "Why Git Specifically?",
    "text": "Why Git Specifically?\n\nIt is super easy to learn and use!\n\n\n\nDistributed - every collaborator has the full project history\n\n\n\n\nThe industry standard for software, increasingly for science\n\n\n\n\nIntegrates with RStudio, Positron, and Quarto"
  },
  {
    "objectID": "slides/slides-Week04.html#key-concepts",
    "href": "slides/slides-Week04.html#key-concepts",
    "title": "Version Control, Git & Collaboration",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n\n\n\n\n\n\n\nConcept\nWhat It Is\nAnalogy\n\n\n\n\nRepository (repo)\nA project folder tracked by Git\nYour lab notebook for a project\n\n\nCommit\nA snapshot of your files at a point in time\nAn entry in your lab notebook\n\n\nStaging (git add)\nChoosing which changes to include in the next commit\nDeciding which observations to write up\n\n\nBranch\nA parallel version of your project\nAn exploratory side-analysis"
  },
  {
    "objectID": "slides/slides-Week04.html#key-concepts-continued-.smaller",
    "href": "slides/slides-Week04.html#key-concepts-continued-.smaller",
    "title": "Version Control, Git & Collaboration",
    "section": "Key Concepts (continued) {.smaller} |",
    "text": "Key Concepts (continued) {.smaller} |\n\n\n\n\n\n\n\n\nConcept\nWhat It Is\nAnalogy\n\n\n\n\nMerge\nCombining two branches\nIntegrating exploratory findings into main analysis\n\n\nPull Request (PR)\nA request to merge your branch + review\nAsking a collaborator to check your work\n\n\nClone\nDownloading a copy of a remote repository\nGetting a copy of a shared lab notebook\n\n\nPush / Pull\nSending/receiving updates to/from GitHub\nSyncing your local notebook with the shared one"
  },
  {
    "objectID": "slides/slides-Week04.html#the-git-mental-model",
    "href": "slides/slides-Week04.html#the-git-mental-model",
    "title": "Version Control, Git & Collaboration",
    "section": "The Git Mental Model",
    "text": "The Git Mental Model\nYour Computer (Local)                    GitHub (Remote)\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  Working Directory   ‚îÇ   git push    ‚îÇ                  ‚îÇ\n‚îÇ  (your files)        ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫   ‚îÇ   Remote Repo    ‚îÇ\n‚îÇ         ‚îÇ            ‚îÇ               ‚îÇ   (GitHub)       ‚îÇ\n‚îÇ    git add           ‚îÇ   git pull    ‚îÇ                  ‚îÇ\n‚îÇ         ‚ñº            ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ   ‚îÇ                  ‚îÇ\n‚îÇ  Staging Area        ‚îÇ               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n‚îÇ         ‚îÇ            ‚îÇ\n‚îÇ    git commit        ‚îÇ\n‚îÇ         ‚ñº            ‚îÇ\n‚îÇ  Local Repository    ‚îÇ\n‚îÇ  (commit history)    ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
  },
  {
    "objectID": "slides/slides-Week04.html#the-workflow-in-plain-english",
    "href": "slides/slides-Week04.html#the-workflow-in-plain-english",
    "title": "Version Control, Git & Collaboration",
    "section": "The Workflow in Plain English",
    "text": "The Workflow in Plain English\n\nYou edit files in your Working Directory\n\n\n\nYou stage (git add) the changes you want to record\n\n\n\n\nYou commit - creating a snapshot with a message explaining why\n\n\n\n\nYou push to GitHub so others (and future you!) can see it\n\n\n\n\nYou pull to get changes others have made"
  },
  {
    "objectID": "slides/slides-Week04.html#git-is-not-just-for-code",
    "href": "slides/slides-Week04.html#git-is-not-just-for-code",
    "title": "Version Control, Git & Collaboration",
    "section": "Git is Not Just for Code",
    "text": "Git is Not Just for Code\nGit tracks any text file:\n\n.qmd, .R, .csv (small), .bib, .tex, .md\n\n\nWhat Git is NOT Good For\n\n\nLarge binary files (images, PDFs, Word docs, big datasets)\nFiles that change constantly in unpredictable ways\nSensitive data (passwords, API keys, PII)\n\n\n. . .\nFor large data ‚Üí .gitignore and Git Large File Storage (LFS)"
  },
  {
    "objectID": "slides/slides-Week04.html#github-git",
    "href": "slides/slides-Week04.html#github-git",
    "title": "Version Control, Git & Collaboration",
    "section": "GitHub ‚â† Git",
    "text": "GitHub ‚â† Git\n\n\n\n\n\n\n\nGit\nGitHub\n\n\n\n\nThe version control system\nA website that hosts Git repositories\n\n\nRuns on your computer\nRuns in the cloud\n\n\nTracks history locally\nLets you share, collaborate, and back up\n\n\nFree, open source\nFree for public repos; education accounts get extras\n\n\n\n\nGit is the engine. GitHub is the garage where everyone parks."
  },
  {
    "objectID": "slides/slides-Week04.html#activity-concept-map-8-min",
    "href": "slides/slides-Week04.html#activity-concept-map-8-min",
    "title": "Version Control, Git & Collaboration",
    "section": "Activity: Concept Map (8 min)",
    "text": "Activity: Concept Map (8 min)\nNow that you‚Äôve heard the lecture, build a concept map from memory.\n\nIndividual (5 min)\nOn a blank piece of paper, create a concept map using these terms. Draw circles and arrows. Label arrows with verbs.\n. . .\nTerms: Repository, Commit, Branch, Merge, Pull Request, Clone, Push, Pull, Staging Area, Working Directory, Remote (GitHub)\n\n\n\n\n\n\n## Activity: Hands-On ‚Äî Your First Repo (15 min) {background-color=‚Äú#d4edda‚Äù} Once you are done‚Ä¶ start working on this &gt; Who here did a Github account? &gt; Join an educational account"
  },
  {
    "objectID": "slides/slides-Week04.html#summary",
    "href": "slides/slides-Week04.html#summary",
    "title": "Version Control, Git & Collaboration",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n\n\nWhat We Covered\nKey Takeaway\n\n\n\n\nWhy version control?\nFile-naming fails; Git preserves what, when, and why\n\n\nWhat is Git?\nA system that snapshots your project over time\n\n\nGit ‚â† GitHub\nGit is the engine; GitHub is the cloud platform\n\n\nKey workflow\nedit ‚Üí add ‚Üí commit ‚Üí push\n\n\nConnection to research\nTrack model iterations, exploration vs.¬†inference, analytical decisions"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Course Description - This graduate-level course explores quantitative methods commonly used in agricultural, food, plant, animal, and natural resource sciences. Students will critically evaluate statistical and modeling techniques in current research, develop the ability to apply quantitative approaches to their own projects, and gain practical experience with equations, algorithms, and R code.\nLearning Outcomes\n\nCritically evaluate quantitative methods in published research across agricultural and natural resource sciences.\nImplement and adapt these methods using equations, models, and R code.\nApply appropriate quantitative approaches to their own research data.\nCommunicate and defend methodological decisions through peer-led discussions and final presentations.\n\nCourse Structure - Weeks 1‚Äì3:\n\nSession A (Paper Discussion): Class:\n\nDiscussion of a research article, focusing on research questions, data, and interpretation.\n\nSession B (Method Deep-Dive):\n\nMathematical/statistical foundations of the method used\n\n\n\n\nWeek 4:\n\nGitHub / collaborative work / version control workshop\n\nWeeks 4‚Äì12:\n\nSession A (Student-Led Paper Discussion) and lecture(methods deep-dive)\nSession B (Workshop ‚Äî hands-on coding and project development)\n\nWeeks 13‚Äì14:\n\nProject progress updates and peer feedback\n\nWeek 15:\n\nFinal presentations\n\n\nAssessment:\n\nParticipation & Paper Discussions: 50%\nWorkshops: 25%\nFinal Project (written report + presentation): 25%\n\nSoftware & Tools\n\nR (required)\nShared GitHub repository for code and datasets\nGitHub Codespaces (recommended for reproducible environment)\nCanvas"
  },
  {
    "objectID": "weeks/week01.html",
    "href": "weeks/week01.html",
    "title": "Week 01 ‚Äî Introductions",
    "section": "",
    "text": "Short class to introduce ourselves\nGet familiarized with course objectives"
  },
  {
    "objectID": "weeks/week01.html#session-a-introductions",
    "href": "weeks/week01.html#session-a-introductions",
    "title": "Week 01 ‚Äî Introductions",
    "section": "",
    "text": "Short class to introduce ourselves\nGet familiarized with course objectives"
  },
  {
    "objectID": "weeks/week01.html#session-b-papers-and-introduction-to-code",
    "href": "weeks/week01.html#session-b-papers-and-introduction-to-code",
    "title": "Week 01 ‚Äî Introductions",
    "section": "2 Session B: Papers and introduction to code",
    "text": "2 Session B: Papers and introduction to code\n\n2.1 Part 1: Paper discussion (~60 minutes of the class)\n\n2.1.1 Preparation:\nWe will have a short discussion of two papers. Get in groups of four, each group will then read a paper and present it to the other team.\nGroup a: Tredennick et al. (2021) This is a paper that some of you have read. But I think all of you should read it to be successful in this class.\nGroup b: Zuur, Ieno, and Elphick (2010) if you have already read Tredennick et al. (2021), this is the one you should read.\n\n\n2.1.2 Deliverable:\nYou will give a short lecture ~25 to 30 minutes on the most important aspects of your paper to the other group. YOU ARE THE EXPERTS, so make sure you can answer questions from your ‚Äústudents‚Äù. You can use slides, but you don‚Äôt have to. You will self-govern your group. Each member can present, just two, or have a single person present.\nYou will have ~10 minutes at the beginning of class to ask questions and make a plan\n\n\n\n2.2 Part 2: Github and R\nMake sure you have downloaded the following:\n\nProgram R\nRStudio\nKnow basics of R and RStudio: https://moctezumaii.github.io/SNR610/installation_instructions.html\nRStudio\nCreate a Github account\nApply for GitHub Education\nJoin the course repository (you will be invited, accept the invite)\nConfirm Codespaces access (we will provide guidance; Codespaces may be enabled by GitHub Education or by the organization)\n\n\n\n2.3 Part 3: Look for papers\nPlease send me any and all papers that you find interesting, would be interested in my taking into account for the course!\nYou should start looking for the paper you want to lead the discussion on!\n\n\n\n\n\n\nOther tasks to come\n\n\n\nThese are tasks that will come when we start the ‚Äúcollaborative section of the course‚Äù\n\nJoin the course repository (you will be invited, accept the invite üòÑ\nConfirm Codespaces access (I will provide guidance)"
  },
  {
    "objectID": "weeks/week03.html",
    "href": "weeks/week03.html",
    "title": "Week 03 - Statistical Modeling Framework",
    "section": "",
    "text": "Week: 3\nTopic: Statistical Modeling Framework"
  },
  {
    "objectID": "weeks/week03.html#learning-objectives",
    "href": "weeks/week03.html#learning-objectives",
    "title": "Week 03 - Statistical Modeling Framework",
    "section": "0.1 Learning Objectives",
    "text": "0.1 Learning Objectives\nConnect research questions, data structure and data analysis"
  },
  {
    "objectID": "weeks/week03.html#background",
    "href": "weeks/week03.html#background",
    "title": "Week 03 - Statistical Modeling Framework",
    "section": "0.2 Background",
    "text": "0.2 Background\nNo background this week. After class, review the following topics:\n\nInference\nLinear Models\nDistributions\n\nNormal\nBinomial\nPoisson\nNegative Binomial"
  },
  {
    "objectID": "weeks/week03.html#before-class",
    "href": "weeks/week03.html#before-class",
    "title": "Week 03 - Statistical Modeling Framework",
    "section": "0.3 Before class",
    "text": "0.3 Before class\nThink about:\n\nA dataset you‚Äôre currently working with (or interested in working with)\nThe main research question you want to answer\nWhat is your response variable? What is its distribution?"
  },
  {
    "objectID": "weeks/week03.html#part-1-silent-reflection-10-min",
    "href": "weeks/week03.html#part-1-silent-reflection-10-min",
    "title": "Week 03 - Statistical Modeling Framework",
    "section": "1.1 Part 1: Silent Reflection (10 min)",
    "text": "1.1 Part 1: Silent Reflection (10 min)\nOn the paper I gave you, write the following:\n\n\n\n\n\n\nReflection Prompts\n\n\n\n\nMy research question is (one sentence):\n\n \n\nMy response variable is: (circle one or write your own)\n\nContinuous measurements\nCounts\nBinary (yes/no, presence/absence)\nProportions\nCategories\nOther: ___________\n\n\n\n\nMy data structure includes: (check all that apply)\n\nRepeated measures on the same units\nMultiple sites/plots/locations\nTime series\nNested structure (e.g., plants within plots within sites)\nJust one observation per unit\nOther: ___________\n\n\n\n\nOne worry I have about analyzing my data:"
  },
  {
    "objectID": "weeks/week03.html#part-2-graffitti-discussion-12-minutes",
    "href": "weeks/week03.html#part-2-graffitti-discussion-12-minutes",
    "title": "Week 03 - Statistical Modeling Framework",
    "section": "1.2 Part 2: Graffitti discussion (12 minutes)",
    "text": "1.2 Part 2: Graffitti discussion (12 minutes)\nYour task: - Move freely around the room - Use markers to write on ANY of the questions (words, phrases, questions, drawings) - Read what others wrote - Add +1, arrows, or comments to build on others‚Äô ideas - No names required\n\n\n\n\n\n\nThe Six Questions\n\n\n\nWall 1: ‚ÄúWhat‚Äôs the hardest thing about data analysis for you?‚Äù\nWall 2: ‚ÄúWhat‚Äôs the gap between what you learned in stats class and what you actually need/use?‚Äù\nWall 3: ‚ÄúWhat do you wish your advisor/committee understood about statistical analysis?‚Äù\nWall 4: ‚ÄúWhat statistical concept do you pretend to understand but actually don‚Äôt?‚Äù\nWall 5: ‚ÄúWhat do you want to learn in this class?‚Äù\nWall 6: ‚ÄúDo you ever feel like you are doing analyses that you do not understand or that might be wrong, but don‚Äôt know why? If yes, explain‚Äù"
  },
  {
    "objectID": "weeks/week03.html#post-graffitti-6-min",
    "href": "weeks/week03.html#post-graffitti-6-min",
    "title": "Week 03 - Statistical Modeling Framework",
    "section": "1.3 Post-graffitti (6 min)",
    "text": "1.3 Post-graffitti (6 min)\nBrief discussion of themes and patterns from the walls. This will inform future class topics."
  },
  {
    "objectID": "weeks/week03.html#part-3-main-concept-lecture",
    "href": "weeks/week03.html#part-3-main-concept-lecture",
    "title": "Week 03 - Statistical Modeling Framework",
    "section": "1.4 Part 3: Main concept ‚Äì> Lecture",
    "text": "1.4 Part 3: Main concept ‚Äì&gt; Lecture"
  },
  {
    "objectID": "weeks/week03.html#the-method-question-data-triangle-15-min",
    "href": "weeks/week03.html#the-method-question-data-triangle-15-min",
    "title": "Week 03 - Statistical Modeling Framework",
    "section": "1.5 The Method-Question-Data Triangle (15 min)",
    "text": "1.5 The Method-Question-Data Triangle (15 min)\n     RESEARCH QUESTION\n            /\\\n           /  \\\n          /    \\\n         /      \\\n        /        \\\n       /          \\\nDATA TYPE -------- METHOD CHOICE\nAll needed to be aligned. Dr.¬†Molina will give a lecture showing examples of mismatch, good match and overcomplicated model."
  },
  {
    "objectID": "weeks/week03.html#think-pair-share-5-min",
    "href": "weeks/week03.html#think-pair-share-5-min",
    "title": "Week 03 - Statistical Modeling Framework",
    "section": "1.6 ü§ù Think-Pair-Share (5 min)",
    "text": "1.6 ü§ù Think-Pair-Share (5 min)\nActivity:\n\nLook back at your silent reflection sheet. Based on the three examples:\n\nWhat method might be appropriate for YOUR data?\nWhat‚Äôs one thing about your data structure that makes method choice tricky?\n\n\n\nThink (&lt;1 min) - you already did this‚Ä¶ you can use 30 seconds to update your notes\nPair (3 min) - discuss with a neighbor, help each other troubleshoot\nShare (1 min) - 2‚Äì3 volunteers share their pairing‚Äôs most interesting dilemma"
  },
  {
    "objectID": "weeks/week03.html#data-detective-diagnosis-stations-25-min",
    "href": "weeks/week03.html#data-detective-diagnosis-stations-25-min",
    "title": "Week 03 - Statistical Modeling Framework",
    "section": "1.7 4. Data Detective: Diagnosis Stations (25 min)",
    "text": "1.7 4. Data Detective: Diagnosis Stations (25 min)\n\n1.7.1 Setup\nSix stations around the room, each with a scenario card describing: - A research question - A dataset description - A statistical method that was used (or is being proposed)\nYour job: Diagnose whether the method fits the question and data.\nRotation schedule: - 4 minutes per station - Work in pairs or trios - Record your diagnosis on the station worksheet\n\n\n1.7.1.1 üîç Station 1: Salamander Survival\nResearch Question:\nDoes canopy cover affect salamander survival in forest fragments?\nData:\n\n12 forest fragments\n20 salamanders marked in each fragment (240 total)\nSurvival recorded as binary (alive/dead) after one year\nCanopy cover measured as % for each fragment\n\nProposed Method:\nLogistic regression: glm(survival ~ canopy_cover, family = binomial)\nYour Diagnosis:\n\nGood match - use as is\nNeeds modification - what‚Äôs missing?\nWrong method - what would you use instead?\n\nWhy?\n\n\n\n\n1.7.1.2 üîç Station 2: Wheat Yield Trials\nResearch Question:\nWhich of 5 wheat varieties produces the highest yield?\nData:\n\n5 varieties tested in 4 blocks (randomized complete block design)\nOne plot per variety per block (20 plots total)\nYield (kg/ha) recorded once per plot\nData look approximately normal\n\nProposed Method:\nOne-way ANOVA: aov(yield ~ variety)\nYour Diagnosis:\n\nGood match - use as is\nNeeds modification - what‚Äôs missing?\nWrong method - what would you use instead?\n\nWhy?\n\n\n\n\n1.7.1.3 üîç Station 3: Bird Abundance Over Time\nResearch Question:\nIs bird abundance declining in urban parks?\nData:\n\n8 urban parks surveyed\nEach park visited 6 times per year for 5 years (240 total observations)\nResponse: count of birds per visit (range: 0‚Äì89)\nYear as continuous predictor\n\nProposed Method:\nLinear regression: lm(bird_count ~ year)\nYour Diagnosis:\n\nGood match - use as is\nNeeds modification - what‚Äôs missing?\nWrong method - what would you use instead?\n\nWhy?\n\n\n\n\n1.7.1.4 üîç Station 4: Soil Microbial Diversity\nResearch Question:\nDoes tillage treatment affect soil microbial diversity?\nData:\n\n3 treatments: no-till, reduced till, conventional till\n10 fields per treatment (30 fields total)\nShannon diversity index calculated for each field (continuous, 0‚Äì5)\nData slightly right-skewed but otherwise well-behaved\n\nProposed Method:\nKruskal-Wallis test (non-parametric)\nYour Diagnosis:\n\nGood match - use as is\nNeeds modification - what‚Äôs missing?\nWrong method - what would you use instead?\n\nWhy?\n\n\n\n\n1.7.1.5 üîç Station 5: Pollinator Network Complexity\nResearch Question:\nDo pollinator networks become more complex with plant diversity?\nData:\n\n25 meadows sampled\nPlant diversity (species richness) recorded per meadow\nNetwork complexity score calculated (continuous, 1.2‚Äì8.7)\nData are normal, linear relationship looks reasonable\n\nProposed Method:\nBayesian multilevel model with varying intercepts and slopes, spatial Gaussian process\nYour Diagnosis:\n\nGood match - use as is\nNeeds modification - what‚Äôs missing?\nWrong method - what would you use instead?\n\nWhy?\n\n\n\n\n1.7.1.6 üîç Station 6: Seedling Germination Experiment\nResearch Question:\nDoes stratification time (0, 30, 60, 90 days) affect germination rate?\nData:\n\n4 stratification treatments\n10 petri dishes per treatment (40 dishes)\n50 seeds per dish\nResponse: proportion germinated (0.0‚Äì1.0)\n\nProposed Method:\nLinear regression: lm(proportion ~ stratification_time)\nYour Diagnosis:\n\nGood match - use as is\nNeeds modification - what‚Äôs missing?\nWrong method - what would you use instead?\n\nWhy?"
  },
  {
    "objectID": "weeks/week03.html#discussion-of-diagnosis-stations-10-min",
    "href": "weeks/week03.html#discussion-of-diagnosis-stations-10-min",
    "title": "Week 03 - Statistical Modeling Framework",
    "section": "2.1 Discussion of Diagnosis Stations (10 min)",
    "text": "2.1 Discussion of Diagnosis Stations (10 min)"
  },
  {
    "objectID": "weeks/week03.html#self-assessment-1-minute",
    "href": "weeks/week03.html#self-assessment-1-minute",
    "title": "Week 03 - Statistical Modeling Framework",
    "section": "2.2 Self-Assessment (1 minute)",
    "text": "2.2 Self-Assessment (1 minute)\nBefore we begin, place yourself into a track based on your current comfort level:\n\n\n\n\n\n\n\n\nTrack\nDescription\nYou should choose this if‚Ä¶\n\n\n\n\nüü¢ Track A\nNew to R / Need a refresher\n‚ÄúI‚Äôve never used R‚Äù OR ‚ÄúIt‚Äôs been a while and I need to review some basics‚Äù\n\n\nüü° Track B\nSome experience\n‚ÄúI can run models but need practice choosing the right one‚Äù\n\n\nüî¥ Track C\nExperienced\n‚ÄúI can fit GLMs, troubleshoot code, and want a bit of a challenge‚Äù"
  },
  {
    "objectID": "weeks/week03.html#track-a-beginners-choose-one-option",
    "href": "weeks/week03.html#track-a-beginners-choose-one-option",
    "title": "Week 03 - Statistical Modeling Framework",
    "section": "2.3 üü¢ Track A: Beginners (Choose One Option)",
    "text": "2.3 üü¢ Track A: Beginners (Choose One Option)\n\n2.3.1 Option A1: Introduction to R, Projects, and Quarto\nIf you are completely new to R or need a structured introduction, work through the Intro to R, Projects and Quarto assignment.\nYour goal: Complete the tutorial and have a working .qmd file that renders by the end of class.\n\n\n\n2.3.2 Option A2: My First Model - Guided Template\nIf you have some R basics but haven‚Äôt run statistical models, use this guided template.\nYour goal: Fit two models, interpret the output, and check assumptions.\n\n# ===========================================\n# SNR 690: Your First Model Template\n# ===========================================\n\n# 1. Load packages (install if needed)\nlibrary(tidyverse)\n\n# 2. Load YOUR data (replace with your file path)\n# my_data &lt;- read_csv(\"your_data.csv\")\n\n# For now, let's use example data:\nmy_data &lt;- data.frame(\n  yield = c(12, 15, 14, 18, 20, 22, 19, 25, 17, 21),\n  temperature = c(15, 16, 15, 18, 20, 21, 19, 23, 17, 20),\n  rainfall = c(50, 55, 48, 60, 70, 75, 65, 80, 58, 68),\n  site = c(\"A\", \"A\", \"B\", \"B\", \"C\", \"C\", \"D\", \"D\", \"E\", \"E\")\n)\n\n# 3. Explore your data\nhead(my_data)\nsummary(my_data)\n\n# Visualize relationships\nggplot(my_data, aes(x = temperature, y = yield)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Yield vs Temperature\")\n\n# -------------------------------------------\n# MODEL 1: Single predictor\n# -------------------------------------------\n\n# 4. Fit a simple model with ONE predictor\nmodel1 &lt;- lm(yield ~ temperature, data = my_data)\n\n# 5. Look at the output\nsummary(model1)\n\n# 6. Check assumptions (look at these plots!)\npar(mfrow = c(2, 2))\nplot(model1)\n\n# QUESTION: What does the slope for temperature mean?\n# Write one sentence here:\n# \n\n# -------------------------------------------\n# MODEL 2: Two predictors\n# -------------------------------------------\n\n# 7. Now fit a model with TWO predictors\nmodel2 &lt;- lm(yield ~ temperature + rainfall, data = my_data)\n\n# 8. Look at the output\nsummary(model2)\n\n# 9. Check assumptions\npar(mfrow = c(2, 2))\nplot(model2)\n\n# 10. Compare models\n# Which model explains more variance? (Hint: look at R-squared)\n# \n\n# QUESTION: Interpret the coefficient for rainfall. \n# What does it mean while \"controlling for\" temperature?\n# Write one sentence here:\n# \n\n\n\n\n# -------------------------------------------\n# YOUR TURN: Adapt for your data\n# -------------------------------------------\n\n# First, run the same model with an interactive term, what changed?\n# Replace the example data with your own data. Simulate data if needed. Let's look at your own system.\n# What is your response variable?\n# What are 1-2 predictor variables you want to test?\n# Fit the models and interpret!"
  },
  {
    "objectID": "weeks/week03.html#track-b-intermediate---simulate-analyze-choose-one-station",
    "href": "weeks/week03.html#track-b-intermediate---simulate-analyze-choose-one-station",
    "title": "Week 03 - Statistical Modeling Framework",
    "section": "2.4 üü° Track B: Intermediate - Simulate & Analyze (Choose One Station)",
    "text": "2.4 üü° Track B: Intermediate - Simulate & Analyze (Choose One Station)\nYour task: Take one of the diagnosis stations from Session A (from the ones listed here), simulate data that matches the scenario, then fit the analysis two ways: the ‚Äúproposed‚Äù (potentially wrong) way and the ‚Äúcorrect‚Äù way. Compare the results.\n\n\n\n\n\n\nYour Deliverable\n\n\n\n\nSimulate data that matches the scenario description\nFit the proposed model (as written in the station)\nFit the correct model (what SHOULD be used)\nCompare the outputs - what‚Äôs different? Why does it matter?\nWrite 2-3 sentences explaining what you learned\n\n\n\n\n\n2.4.1 Station 1: Salamander Survival\nResearch Question: Does canopy cover affect salamander survival in forest fragments?\nData Structure:\n\n12 forest fragments\n20 salamanders marked in each fragment (240 total)\nSurvival recorded as binary (alive/dead) after one year\nCanopy cover measured as % for each fragment\n\nProposed Method: glm(survival ~ canopy_cover, family = binomial)\nYour Diagnosis from Session A: Needs modification - what‚Äôs missing?\nHints:\n\nWhat is the unit of observation? What is the unit of replication?\nAre salamanders within the same fragment independent?\nWhat package might you need for the correct approach?\n\n\n\n\n2.4.2 Station 4: Soil Microbial Diversity\nResearch Question: Does tillage treatment affect soil microbial diversity?\nData Structure:\n\n3 treatments: no-till, reduced till, conventional till\n10 fields per treatment (30 fields total)\nShannon diversity index calculated for each field (continuous, 0‚Äì5)\nData slightly right-skewed but otherwise well-behaved\n\nProposed Method: Kruskal-Wallis test (non-parametric)\nYour Diagnosis from Session A: Is this wrong, or just overly cautious?\nHints:\n\nWhen is a non-parametric test truly necessary?\nWhat assumptions does ANOVA actually require?\nHow robust is ANOVA to slight skewness?\n\n\n\n\n2.4.3 Station 6: Seedling Germination\nResearch Question: Does stratification time (0, 30, 60, 90 days) affect germination rate?\nData Structure:\n\n4 stratification treatments\n10 petri dishes per treatment (40 dishes)\n50 seeds per dish\nResponse: proportion germinated (0.0‚Äì1.0)\n\nProposed Method: lm(proportion ~ stratification_time)\nYour Diagnosis from Session A: Wrong method - what would you use instead?\nHints:\n\nWhat‚Äôs the difference between a proportion and a count?\nWhy can‚Äôt you just use lm() on proportions?\nLook up cbind() with glm(..., family = binomial)"
  },
  {
    "objectID": "weeks/week03.html#track-c-advanced---simulate-fix-extend-choose-one-station",
    "href": "weeks/week03.html#track-c-advanced---simulate-fix-extend-choose-one-station",
    "title": "Week 03 - Statistical Modeling Framework",
    "section": "2.5 üî¥ Track C: Advanced - Simulate, Fix & Extend (Choose One Station)",
    "text": "2.5 üî¥ Track C: Advanced - Simulate, Fix & Extend (Choose One Station)\nYour task: Take one of the diagnosis stations, simulate realistic data (including appropriate complexity), then fit the analysis two ways: the ‚Äúproposed‚Äù (wrong) way and the ‚Äúcorrect‚Äù way. Then extend: add a visualization, check for additional issues, or adapt the code structure for your own research project.\n\n\n\n\n\n\nYour Deliverable\n\n\n\n\nSimulate data that realistically reflects the scenario (think about variance structure!)\nFit the proposed model\nFit the correct model\nExtend in one of these ways:\n\nCreate a publication-ready visualization\nCheck for additional issues (overdispersion, influential points, etc.)\nAdapt the analysis structure for YOUR research data\n\nBe prepared to explain your approach to the class\n\n\n\n\n\n2.5.1 Station 2: Wheat Yield Trials\nResearch Question: Which of 5 wheat varieties produces the highest yield?\nData Structure:\n\n5 varieties tested in 4 blocks (randomized complete block design)\nOne plot per variety per block (20 plots total)\nYield (kg/ha) recorded once per plot\nData look approximately normal\n\nProposed Method: aov(yield ~ variety) (one-way ANOVA)\nYour Diagnosis from Session A: Needs modification - what‚Äôs missing?\nChallenges:\n\nSimulate data with BOTH variety effects AND block effects\nWhat happens to your standard errors and p-values when you ignore blocks?\nShould block be fixed or random? When does it matter?\nExtension: Add post-hoc comparisons with emmeans\n\n\n\n\n2.5.2 Station 3: Bird Abundance Over Time\nResearch Question: Is bird abundance declining in urban parks?\nData Structure:\n\n8 urban parks surveyed\nEach park visited 6 times per year for 5 years (240 total observations)\nResponse: count of birds per visit (range: 0‚Äì89)\nYear as continuous predictor\n\nProposed Method: lm(bird_count ~ year)\nYour Diagnosis from Session A: Wrong method - multiple issues!\nChallenges:\n\nThis data has at least THREE problems with the proposed method. What are they?\nSimulate data with park-level random effects and temporal structure\nWhat distribution should counts follow?\nExtension: Try adding random slopes - do parks decline at different rates?\n\n\n\n\n2.5.3 Station 5: Pollinator Network Complexity\nResearch Question: Do pollinator networks become more complex with plant diversity?\nData Structure:\n\n25 meadows sampled\nPlant diversity (species richness) recorded per meadow\nNetwork complexity score calculated (continuous, 1.2‚Äì8.7)\nData are normal, linear relationship looks reasonable\n\nProposed Method: Bayesian multilevel model with varying intercepts and slopes, spatial Gaussian process\nYour Diagnosis from Session A: This is OVERKILL!\nChallenges:\n\nSimulate simple, well-behaved data that matches this scenario\nShow that a simple lm() is sufficient\nDiscussion: When WOULD the complex approach be justified? What would the data need to look like?\nExtension: What are the costs of over-complicating your analysis? Write a brief argument for simplicity."
  },
  {
    "objectID": "weeks/week03.html#end-of-session-wrap-up",
    "href": "weeks/week03.html#end-of-session-wrap-up",
    "title": "Week 03 - Statistical Modeling Framework",
    "section": "2.6 End of Session Wrap-Up",
    "text": "2.6 End of Session Wrap-Up\nDeliverables (choose based on your track):\n\n\n\n\n\n\n\nTrack\nWhat to submit/share\n\n\n\n\nüü¢ Track A\nIntro to R ‚Äì&gt; follow the instructions. Or your working .qmd file with at least one model output\n\n\nüü° Track B\nYour simulation + comparison of wrong vs.¬†correct model, with 2-3 sentences explaining what you learned.\n\n\nüî¥ Track C\nYour extended analysis + one visualization + notes on how this applies to your research\n\n\n\n\n2.6.0.1 Exit Ticket (5 min)\nIs thinking about how methods align to your objectives useful?"
  },
  {
    "objectID": "weeks/week05.html",
    "href": "weeks/week05.html",
    "title": "Week 05 ‚Äî Performance and Potentiality of Camelina (Camelina sativa L. Crantz) Genotypes in Response to Sowing Date under Mediterranean Environment",
    "section": "",
    "text": "Session\nContent\n\n\n\n\nSession A Part 1\nStudent-led paper discussion (~35 min)\n\n\nSession A Part 2\nMethod deep-dive (this document, ~35 min)\n\n\nSession B\nHands-on coding workshop\n\n\n\n\n\n\n\n\n\nLearning Objectives\n\n\n\n\nUnderstand why split-plot designs exist and how they differ from RCBD\nRecognize that lmer + anova() is a linear mixed model, not classical ANOVA\nIdentify whole-plot vs subplot error strata and why they change the F-ratio\nInterpret G √ó ST interactions biologically and agronomically\nApply the Zuur data exploration checklist critically to a published paper\n\n\n\n\n\nPaper:\nAngelini, L. G., Chehade, L. A., Foschi, L., & Tavarini, S. (2020). Performance and Potentiality of Camelina (Camelina sativa L. Crantz) Genotypes in Response to Sowing Date under Mediterranean Environment. Agronomy, 10(12), 1929. https://doi.org/10.3390/agronomy10121929\n\n\n\n\n\n\nQuestions to Consider\n\n\n\nWhile reading, always think about:\n\nWhat is the research question**? What factors are being tested?\nWhat is the experimental design**? (How many factors? How are treatments arranged? What is the blocking factor?)\nWhat are the response variables**? What type of data are they? (continuous, counts, proportions?)\nWhat statistical methods are used? Are they appropriate given the design?\nDoes the Method-Question-Data Triangle align in this paper?\nWhat would Zuur (Week 1) say about their data exploration? Do you see evidence of it?\n\n\n\n\n\n\n\n\n\nVariable\nType\n\n\n\n\nSeed yield (Mg/ha)\nContinuous\n\n\nOil content (% DW)\nContinuous\n\n\n1000-seed weight (g)\nContinuous\n\n\nPlant height (cm)\nContinuous\n\n\nSiliques per plant\nCount\n\n\nPlant density (No./m¬≤)\nCount\n\n\nHarvest index\nIndex\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nCounts were analyzed with Poisson GLMs: potentially the right call (if they checked for zero-inflation). We return to this below."
  },
  {
    "objectID": "weeks/week05.html#background-readings",
    "href": "weeks/week05.html#background-readings",
    "title": "Week 05 ‚Äî Performance and Potentiality of Camelina (Camelina sativa L. Crantz) Genotypes in Response to Sowing Date under Mediterranean Environment",
    "section": "",
    "text": "Paper:\nAngelini, L. G., Chehade, L. A., Foschi, L., & Tavarini, S. (2020). Performance and Potentiality of Camelina (Camelina sativa L. Crantz) Genotypes in Response to Sowing Date under Mediterranean Environment. Agronomy, 10(12), 1929. https://doi.org/10.3390/agronomy10121929\n\n\n\n\n\n\nQuestions to Consider\n\n\n\nWhile reading, always think about:\n\nWhat is the research question**? What factors are being tested?\nWhat is the experimental design**? (How many factors? How are treatments arranged? What is the blocking factor?)\nWhat are the response variables**? What type of data are they? (continuous, counts, proportions?)\nWhat statistical methods are used? Are they appropriate given the design?\nDoes the Method-Question-Data Triangle align in this paper?\nWhat would Zuur (Week 1) say about their data exploration? Do you see evidence of it?"
  },
  {
    "objectID": "weeks/week05.html#response-variables",
    "href": "weeks/week05.html#response-variables",
    "title": "Week 05 ‚Äî Performance and Potentiality of Camelina (Camelina sativa L. Crantz) Genotypes in Response to Sowing Date under Mediterranean Environment",
    "section": "",
    "text": "Variable\nType\n\n\n\n\nSeed yield (Mg/ha)\nContinuous\n\n\nOil content (% DW)\nContinuous\n\n\n1000-seed weight (g)\nContinuous\n\n\nPlant height (cm)\nContinuous\n\n\nSiliques per plant\nCount\n\n\nPlant density (No./m¬≤)\nCount\n\n\nHarvest index\nIndex\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nCounts were analyzed with Poisson GLMs: potentially the right call (if they checked for zero-inflation). We return to this below."
  },
  {
    "objectID": "weeks/week05.html#why-it-is-a-split-plot",
    "href": "weeks/week05.html#why-it-is-a-split-plot",
    "title": "Week 05 ‚Äî Performance and Potentiality of Camelina (Camelina sativa L. Crantz) Genotypes in Response to Sowing Date under Mediterranean Environment",
    "section": "2.1 Why It Is a Split-Plot",
    "text": "2.1 Why It Is a Split-Plot\nYou cannot randomize Autumn vs.¬†Spring sowing within the same small plot ‚Äî the whole field area for a given replicate must be sown in the same season. Sowing time requires a large experimental unit. This is the defining reason split-plot designs exist.\nBLOCK (replicate, n = 4)\n‚îú‚îÄ‚îÄ WHOLE PLOT: Autumn sowing\n‚îÇ   ‚îú‚îÄ‚îÄ subplot: V1, V2, V3, V4, V5, V6, CELINE (randomized)\n‚îî‚îÄ‚îÄ WHOLE PLOT: Spring sowing\n    ‚îî‚îÄ‚îÄ subplot: V1, V2, V3, V4, V5, V6, CELINE (randomized)"
  },
  {
    "objectID": "weeks/week05.html#two-error-strata",
    "href": "weeks/week05.html#two-error-strata",
    "title": "Week 05 ‚Äî Performance and Potentiality of Camelina (Camelina sativa L. Crantz) Genotypes in Response to Sowing Date under Mediterranean Environment",
    "section": "2.2 Two Error Strata",
    "text": "2.2 Two Error Strata\n\n\n\nStratum\nTests\nExperimental unit\n\n\n\n\nWhole-plot error\nSowing Time (ST)\nWhole plot within block\n\n\nSubplot error\nGenotype (G), G√óST\nSubplot within whole plot\n\n\n\nUsing a single pooled error (naive ANOVA) gives an anti-conservative test for ST (false positives) and an over-conservative test for G (false negatives)."
  },
  {
    "objectID": "weeks/week05.html#how-to-run-as-an-anova-not-what-they-did-even-though-they-claim-that",
    "href": "weeks/week05.html#how-to-run-as-an-anova-not-what-they-did-even-though-they-claim-that",
    "title": "Week 05 ‚Äî Performance and Potentiality of Camelina (Camelina sativa L. Crantz) Genotypes in Response to Sowing Date under Mediterranean Environment",
    "section": "2.3 How to run as an ANOVA (not what they did, even though they claim that)",
    "text": "2.3 How to run as an ANOVA (not what they did, even though they claim that)\n\naov(yield ~ ST * Genotype * Year + Error(Block/ST), data = dat)"
  },
  {
    "objectID": "weeks/week05.html#what-they-likely-ran",
    "href": "weeks/week05.html#what-they-likely-ran",
    "title": "Week 05 ‚Äî Performance and Potentiality of Camelina (Camelina sativa L. Crantz) Genotypes in Response to Sowing Date under Mediterranean Environment",
    "section": "2.4 What They Likely Ran",
    "text": "2.4 What They Likely Ran\n\nmodel &lt;- lmer(yield ~ Genotype * ST * Year + (1|Block) + (1|Block:ST),\n              data = dat)\nanova(model)  # Satterthwaite F-tests\n\n\n\n\n\n\n\nlmer + anova() ‚â† Classical ANOVA\n\n\n\nThis is a linear mixed model. The anova() call uses Satterthwaite approximated denominator df - which may be non-integer. Reporting this as ‚ÄúANOVA‚Äù obscures what was done."
  },
  {
    "objectID": "weeks/week05.html#what-a-significant-g-st-interaction-means",
    "href": "weeks/week05.html#what-a-significant-g-st-interaction-means",
    "title": "Week 05 ‚Äî Performance and Potentiality of Camelina (Camelina sativa L. Crantz) Genotypes in Response to Sowing Date under Mediterranean Environment",
    "section": "2.5 What a Significant G √ó ST Interaction Means",
    "text": "2.5 What a Significant G √ó ST Interaction Means\n\nThe ranking of genotypes depends on sowing time. You cannot make one variety recommendation."
  },
  {
    "objectID": "weeks/week05.html#ordinal-vs.-disordinal",
    "href": "weeks/week05.html#ordinal-vs.-disordinal",
    "title": "Week 05 ‚Äî Performance and Potentiality of Camelina (Camelina sativa L. Crantz) Genotypes in Response to Sowing Date under Mediterranean Environment",
    "section": "2.6 Ordinal vs.¬†Disordinal",
    "text": "2.6 Ordinal vs.¬†Disordinal\n\n\n\n\n\n\n\n\nType\nDefinition\nImplication\n\n\n\n\nOrdinal\nRankings preserved, magnitudes differ\nMain effects broadly valid\n\n\nDisordinal\nRankings cross over\nSeparate recommendations essential"
  },
  {
    "objectID": "weeks/week05.html#tukey-vs.-lsd",
    "href": "weeks/week05.html#tukey-vs.-lsd",
    "title": "Week 05 ‚Äî Performance and Potentiality of Camelina (Camelina sativa L. Crantz) Genotypes in Response to Sowing Date under Mediterranean Environment",
    "section": "2.7 Tukey vs.¬†LSD",
    "text": "2.7 Tukey vs.¬†LSD\n\n\n\n\nLSD\nTukey HSD\n\n\n\n\nControls\nPer-comparison alpha\nFamilywise error rate\n\n\nResult\nMore liberal\nMore conservative\n\n\nUsed in paper\n\n‚úÖ\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nCompact letter displays (‚Äúa‚Äù, ‚Äúab‚Äù, ‚Äúb‚Äù) can mask near-significant differences. Always look at the actual means and CIs."
  },
  {
    "objectID": "weeks/week05.html#the-methodquestiondata-triangle",
    "href": "weeks/week05.html#the-methodquestiondata-triangle",
    "title": "Week 05 ‚Äî Performance and Potentiality of Camelina (Camelina sativa L. Crantz) Genotypes in Response to Sowing Date under Mediterranean Environment",
    "section": "2.8 The Method‚ÄìQuestion‚ÄìData Triangle",
    "text": "2.8 The Method‚ÄìQuestion‚ÄìData Triangle\n       QUESTION\n   \"Best genotype √ó \n   sowing time?\"\n        /\\\n       /  \\\n DATA /    \\ METHOD\n-----/------\\-------\nFactorial    Split-plot LMM\nblocked      Two error strata\ncont+count   Poisson for counts\n\nAlignment? Mostly yes ‚Äî but the gap between what was done (LMM) and what was reported (‚ÄúANOVA‚Äù) is a transparency issue."
  },
  {
    "objectID": "weeks/week05.html#the-6-key-takeaways",
    "href": "weeks/week05.html#the-6-key-takeaways",
    "title": "Week 05 ‚Äî Performance and Potentiality of Camelina (Camelina sativa L. Crantz) Genotypes in Response to Sowing Date under Mediterranean Environment",
    "section": "2.9 The 6 Key Takeaways",
    "text": "2.9 The 6 Key Takeaways\n\n\nSplit-plot because ST cannot be randomized at subplot level ‚Üí two error strata\nlmer + anova() is a linear mixed model, not classical ANOVA, this is a reporting issue\nYear as fixed is pragmatic with n=2 but limits generalizability\nG√óST is disordinal separate recommendations required\nPoisson for counts was correct if they checked for zero-inflation (not reported)\nData exploration is underreported it usually is"
  },
  {
    "objectID": "weeks/week05.html#data-analysis",
    "href": "weeks/week05.html#data-analysis",
    "title": "Week 05 ‚Äî Performance and Potentiality of Camelina (Camelina sativa L. Crantz) Genotypes in Response to Sowing Date under Mediterranean Environment",
    "section": "2.10 Data analysis",
    "text": "2.10 Data analysis\nYou can generate the data using this, and then analyze it using either the aov() or lmer() approach. Check for differences\n\n# I will simulate the data. 4 repliacation (Block), 2 sowing times (ST), 7 Genotypes (G), 2 years (Year)\nset.seed(42)\ndat&lt;-expand.grid(Block = factor(1:4),\n                 ST = factor(c(\"Autumn\", \"Spring\")),\n                 Genotype = factor(paste0(\"V\", 1:6)),\n                 Year = factor(2018:2019))\ndat$yield &lt;- 1.8 +\n   0.30 * (dat$ST == \"Autumn\") +\n   c(0.10, -0.10, 0.40, -0.20, 0.05, 0.10, 0.20)[as.integer(dat$G)] +\n   0.40 * (dat$ST == \"Autumn\" & dat$G == \"V3\") + \n   -0.05 * (dat$ST == \"Spring\" & dat$G == \"V5\") + \n   0.20 * (dat$Year == \"2019\") +\n   rnorm(nrow(dat), 0, 0.15)  # add some noise"
  }
]