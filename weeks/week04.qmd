---
title: "Week 04 - Version Control, Git & Collaboration"
format: html
---

# Objectives and background

Topic: Introduction to Git, GitHub, and Collaborative Reproducible Research

## Learning Objectives

- Explain *why* version control matters for reproducible, transparent research
- Connect version control philosophy to themes from Weeks 1â€“3 (data exploration, model selection, the Method-Question-Data triangle)
- Use Git and GitHub for basic version control (init, add, commit, push, pull)
- Collaborate on a shared repository using branches and pull requests
- Apply version control to a Quarto-based analytical workflow

::: {.callout-note}
## The Semester So Far - Key Takeaways from Weeks 1â€“3

| Week | Topic | Key Takeaway |
|------|-------|-------------|
| 1 | Introductions & Papers | Data exploration protects inference (Zuur); exploration vs. inference should be independent (Tredennick); always explore your data before modeling |
| 2 | Philosophy of Data Analysis | "All models are wrong" (Box); Bayesian vs. frequentist thinking; uncertainty is everywhere; the goal is to find the useful model, not the true one |
| 3 | Statistical Modeling Framework | The Method-Question-Data Triangle must align; mismatch â†’ wrong conclusions; overcomplication â†’ wasted effort; start simple, add complexity only when needed |
| **4** | **Version Control & Collaboration** | **Your analytical decisions need to be tracked, transparent, and reproducible - Git makes this possible** |
:::

In Weeks 1â€“3, we talked about *how to think* about data analysis:

- **Week 1** emphasized that data exploration and inference are separate activities - but both must be documented. How do you keep track of which analyses were exploratory vs. confirmatory?
- **Week 2** introduced the idea that all models are wrong but some are useful. If you try multiple models, how do you record *which* ones you tried, *why* you chose one over another, and *what changed*?
- **Week 3** showed us the Method-Question-Data Triangle and the dangers of mismatch vs. overcomplication. When you iterate through model choices - trying a `lm()`, realizing you need a `glmer()`, adding random effects - how do you track that evolution?

**Version control can help us with this** And at WORST... it is a great tool to have!

::: {.callout-important}
## About Week 3 Simulations
Many of you found the simulation exercises in Week 3 challenging - simulating data that matches a scenario description, then fitting both the "proposed" (wrong) and "correct" models. **That's completely normal.** Simulating data is a skill that takes practice.

Session B this week is designed to give you a **second pass** at those simulations. The first hands-on activity will walk through the Week 3 simulation & analysis exercises together, step by step. *Then* we'll layer Git on top, so you're learning version control with familiar code rather than starting from scratch.
:::

## Background Reading

Before Thursday class, review the following:

- [Happy Git with R](https://happygitwithr.com/) - Great guide
- [GitHub Quickstart Guide](https://docs.github.com/en/get-started/quickstart) --> REad this for an overview of GitHub's features
## Before Class

Make sure you have:

- [ ] A [GitHub account](https://github.com) (you should already have this from Week 1)
- [ ] Git installed on your computer (`git --version` in terminal)
- [ ] RStudio or Positron with Git integration configured
- [ ] Accepted the invite to the course repository -- check your email or GitHub notifications
- [ ] Confirmed Codespaces access (if using browser-based workflow) -- check your email or GitHub notifications

Think about:

- How many versions of your thesis/analysis scripts do you currently have?
- Have you ever lost work, overwritten a file, or been unable to undo a change?
- Have you ever emailed a script to a collaborator and gotten confused about which version is "current"?

---

# Session A: Why Version Control? (Lecture + Discussion, 75 min)

## Part 1: Retrieval Practice - What Do You Remember? (8 min)

Before we introduce anything new, let's activate what you already know from Weeks 1â€“3. **No notes, no phones** - this is retrieval practice. Struggling to recall is the point; it strengthens memory.

::: {.callout-warning}
## Quick-Fire Recall (write on paper, 3 min)

Answer as many as you can from memory. One or two sentences each is fine.

1. What did Zuur argue about data exploration? What is the goal of exploring your data before modeling?
2. What is Box's famous quote about models? What does it mean in practice?
3. In Week 3, what were the **three scenarios** we examined? (Hint: one was a "good match")
4. In the examples from Week 3, explain one fo the experiments and what went wrong?
5. What is the **Golden Rule** from Week 3?
:::

**Debrief (5 min):** Turn to a neighbor and compare answers. Fill in each other's gaps. 
note: ask them what they want here

::: {.callout-tip}
## Why Retrieval Practice?
Research shows that actively recalling information - even when it's difficult - produces stronger long-term retention than re-reading notes (Roediger & Butler, 2011). This is a "desirable difficulty." If it felt hard, that's good!
:::



## Part 2: Predict-Observe-Explain (12 min)


**Quick Poll:** Raise your hand if you've ever:

1. Lost work because you overwrote a file
2. Couldn't remember why you changed something in your code
3. Had a collaborator edit the same file and you had to manually merge changes
4. Had a folder full of `_v2`, `_v3`, `_FINAL` files


### ğŸ”® PREDICT (3 min - write on paper)

Here is a scenario. **Predict what will go wrong:**

> You're writing your thesis. You have a file called `analysis.R`. You make changes over two weeks. Your folder now looks like this:
>
> ```
> analysis.R
> analysis_v2.R
> analysis_FINAL.R
> analysis_FINAL_v2.R
> analysis_FINAL_ACTUALLY_FINAL.R
> analysis_FINAL_ACTUALLY_FINAL_USE_THIS_ONE.R
> ```
>
> Your advisor emails and says: *"The reviewer wants to see the version where you used the Poisson model instead of the linear model. Can you send that?"*

**Write down:** What happens next? What specifically goes wrong? How long does it take you to find the right version? Do you even *have* it?

### ğŸ‘ï¸ OBSERVE (2 minute)
I will show how source control works. And why it is so powerful.

### ğŸ’¡ EXPLAIN (5 min - whole class)

As a class, answer:

1. Why does the file-naming approach fail? (Be specific: what information is lost?)
2. What does Git preserve that file-naming doesn't?
3. Can you connect this to Box's "all models are wrong" idea? (Hint: if you're iterating through models, you need a record of *which* wrong models you tried and why you moved on)

## Part 3: Why Version Control? - Elaborative Interrogation (10 min)

Elaborative interrogation means asking "**why?**" and "**how?**" until you reach a deep understanding.

### Round 1: Pair Up - "Why" Chain (6 min)

With a partner, take turns asking "why?" about this statement. Go at least four levels deep:

> **"Researchers should use version control for their analyses."**

### Round 2: Connect to a Specific Week (5 min)

Each pair picks **two** statements. 

And you do the *why?* and *how?* chain for each one.

1. Data exploration should protect inference, not create it. (Zuur, Week 1)

2. All models are wrong, but some are useful." (Box, Week 2)

3. "Start simple. Add complexity only when needed. Always justify your choices." (Golden Rule, Week 3)

4. "Misalignment between method, question, and data leads to wrong conclusions, wasted effort, rejected papers, and sad grad students." (Week 3)

5. "Exploration and inference should come from independent studies. (Tredennick, Week 1)

**Share Out (2â€“3 min):** 3â€“4 pairs share their best sentence.

## Part 4: Lecture - What is Git? (â‰ˆ20 min)

Dr. Molina will give a traditional lecture covering the following. Take notes - you'll use this for a concept map right after.

### What is version control?

- A system that records changes to files over time
- You can recall any previous version at any time
- Think of it as **Track Changes** for your entire project - but much more powerful

### Why Git specifically?

- Created by Linus Torvalds (creator of Linux) in 2005
- Distributed - every collaborator has the full project history
- The industry standard for software, increasingly for science
- Integrates with RStudio, Positron, and Quarto

### Key Concepts

| Concept | What It Is | Analogy |
|---------|-----------|---------|
| **Repository (repo)** | A project folder tracked by Git | Your lab notebook for a project |
| **Commit** | A snapshot of your files at a point in time | An entry in your lab notebook |
| **Staging (git add)** | Choosing which changes to include in the next commit | Deciding which observations to write up |
| **Branch** | A parallel version of your project | An exploratory side-analysis |
| **Merge** | Combining two branches | Integrating your exploratory findings into your main analysis |
| **Pull Request (PR)** | A request to merge your branch + review | Asking a collaborator to check your work before including it |
| **Clone** | Downloading a copy of a remote repository | Getting a copy of a shared lab notebook |
| **Push / Pull** | Sending/receiving updates to/from GitHub | Syncing your local lab notebook with the shared one |

### The Git Mental Model

```
Your Computer (Local)                    GitHub (Remote)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Working Directory   â”‚   git push    â”‚                  â”‚
â”‚  (your files)        â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º   â”‚   Remote Repo    â”‚
â”‚         â”‚            â”‚               â”‚   (GitHub)       â”‚
â”‚    git add           â”‚   git pull    â”‚                  â”‚
â”‚         â–¼            â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚                  â”‚
â”‚  Staging Area        â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚         â”‚            â”‚
â”‚    git commit        â”‚
â”‚         â–¼            â”‚
â”‚  Local Repository    â”‚
â”‚  (commit history)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Git is *Not* Just for Code

Git tracks **any text file**: `.qmd`, `.R`, `.csv` (small), `.bib`, `.tex`, `.md`

::: {.callout-important}
## What Git is NOT Good For

- Large binary files (images, PDFs, Word docs, big datasets)
- Files that change constantly in unpredictable ways
- Sensitive data (passwords, API keys, personally identifiable data)

For large data, look into `.gitignore` and Git Large File Storage (LFS).
:::

### GitHub â‰  Git

| Git | GitHub |
|-----|--------|
| The version control system | A website that hosts Git repositories |
| Runs on your computer | Runs in the cloud |
| Tracks history locally | Lets you share, collaborate, and back up |
| Free, open source | Free for public repos; education accounts get extras |

## Part 5: Concept Map - Your Understanding of Git (8 min)

Now that you've heard the lecture, **build a concept map** from memory. This tests whether you actually absorbed it.

### Individual (5 min)

On a blank piece of paper, create a **concept map** using these terms. Draw circles for each term and arrows showing how they relate. Label the arrows with verbs (e.g., "creates", "contains", "sends to").

**Terms:** Repository, Commit, Branch, Merge, Pull Request, Clone, Push, Pull, Staging Area, Working Directory, Remote (GitHub)

## Part 6: Hands-On - Join GitHub, Create Your First Repo, First Commits (â‰ˆ15 min)

::: {.callout-important}
## We're doing this NOW, together, in class.
The rest of Session A is hands-on. 
:::

### Step 1: Make sure you're on GitHub (2 min)

1. Go to [github.com](https://github.com)
2. If you don't have an account, **create one now**
3. If you haven't applied for [GitHub Education](https://education.github.com/), do that after class (it gives you free features)
4. Confirm you can log in

### Step 2: Create a new RStudio Project with Git (3 min)

1. Open **RStudio**
2. Go to **File â†’ New Project â†’ New Directory â†’ New Project**
3. Name it: `water-growth-sim`
4. âœ… Check **"Create a git repository"**
5. Click **Create Project**

You now have a local Git repository! Notice the **Git tab** in your RStudio pane (usually top-right).

### Step 3: Create a new Quarto file (2 min)

1. **File â†’ New File â†’ Quarto Document**
2. Title: `"Water and Plant Growth Simulation"`
3. Save it as `simulation.qmd`

### Step 4: Write the simulation - Step 1 only (data simulation) (3 min)

Type this into your `simulation.qmd` file. This is a simple simulation: water availability (x) affects plant growth (y) through a basic linear relationship.

```{r}
#| label: simulate-data
#| eval: false

# =============================================
# Water & Plant Growth: Simple Linear Simulation
# =============================================
# Research question: Does water availability affect plant growth?
# We KNOW the answer because we're simulating the data!

library(tidyverse)

set.seed(2024)

# Define the truth
n_plants <- 40             # number of plants
true_intercept <- 5        # baseline growth (cm) with no water
true_slope <- 2.5          # for every 1 unit increase in water, growth increases by 2.5 cm
noise_sd <- 3              # how much natural variation there is

# Simulate predictor: water availability (liters per week)
water <- runif(n_plants, min = 0, max = 10)

# Simulate response: plant growth (cm)
growth <- true_intercept + true_slope * water + rnorm(n_plants, mean = 0, sd = noise_sd)

# Put it in a data frame
plant_data <- data.frame(
  water = water,
  growth = growth
)

# Take a look
head(plant_data)
summary(plant_data)

# Visualize
ggplot(plant_data, aes(x = water, y = growth)) +
  geom_point(size = 3, alpha = 0.7) +
  labs(
    title = "Simulated: Water Availability vs. Plant Growth",
    subtitle = paste("True relationship: growth =", true_intercept, "+", true_slope, "Ã— water + noise"),
    x = "Water Availability (L/week)",
    y = "Plant Growth (cm)"
  ) +
  theme_minimal(base_size = 14)
```

### Step 5: Make your FIRST commit (3 min)

1. Go to the **Git tab** in RStudio
2. You'll see your files listed (`.qmd`, `.Rproj`, maybe `.gitignore`)
3. **Check the boxes** next to all the files (this is "staging" - `git add`)
4. Click **"Commit"**
5. In the commit message box, type: `"Simulated water and plant growth data - true slope is 2.5"`
6. Click **Commit**

ğŸ‰ **Congratulations - you just made your first Git commit!**

Click **"History"** in the Git pane to see your commit. There's your first lab notebook entry.

### Step 6: Connect to GitHub and push (3 min)

1. Go to [github.com](https://github.com) â†’ click **"+"** (top right) â†’ **New repository**
2. Name it: `water-growth-sim`
3. Leave it **Public** (or Private if you prefer)
4. âš ï¸ **Do NOT** check "Add a README" - your local repo already has files
5. Click **Create repository**
6. GitHub will show you instructions. Copy the two lines under **"â€¦or push an existing repository from the command line"**:
7. In RStudio, go to **Terminal** tab (next to Console) and paste those commands

```bash
git remote add origin https://github.com/YOUR-USERNAME/water-growth-sim.git
git branch -M main
git push -u origin main
```

8. Go back to GitHub in your browser and **refresh the page** - your files are there! ğŸ‰

::: {.callout-tip}
## Check GitHub!
Go to `https://github.com/YOUR-USERNAME/water-growth-sim` and confirm you can see your `simulation.qmd` file. Click on it - you can read your code right in the browser. Click "Commits" to see your commit history (it has one entry so far).
:::

9. Now, return to RStudio, and add one line of code to your `simulation.qmd`. I want you to run the linear model using `lm()` and run the `summary()`. After that, commit again, and see if you can push the changes to GitHub.
10. **Commit message:** `"Fit linear model to simulated data"`
11. Push to GitHub again.
12. Render your Quarto document to see the output. You can also commit and push the rendered HTML if you want (that's how I made this website!).

## Muddiest Point (2 min)

On a piece of paper, write down the **one thing** from today that is most confusing or unclear to you. Be specific! Dr. Molina will read these before Session B.


# Session B: Hands-On - Simulations Revisited + Git Workshop (75 min)

::: {.callout-important}
## Session B Game Plan

This session has **two parts**:

This entire session is **hands-on**. You will be working on your computers the whole time. The goals are:

1. **Practice GitHub** â€” cloning, committing, pushing, pulling, and collaborating on a shared repository. This is your first real deep dive after the intro in Session A.
2. **Revisit Week 3 simulations** â€” specifically the "simulate â†’ analyze correctly â†’ analyze incorrectly" workflow, but this time we **start simple** (no transformations like log or logit) and work inside a **Quarto document** with proper source control.
3. **Work collaboratively** â€” you'll be working in small teams on a shared GitHub repository, experiencing what real collaborative version control feels like.

**The rule for today: start simple.** Simple linear models. Normal distributions. No transformations. Get comfortable with the simulation â†’ correct analysis â†’ wrong analysis pipeline *and* with Git before we add complexity.
:::

### Muddiest Points (2 min)

Let's start the class by taking a couple minutes and write the things that have been the most complicated about this class
---

## Part 1: Week 3 Simulation Refresher (â‰ˆ35 min)

### Why Simulate? (5 min - mini-lecture)

Simulation is one of the most powerful tools in a statistician's toolkit. It lets you:

- **Understand your model** by seeing how data generated *from* that model behaves
- **Test your analysis pipeline** on data where you *know* the truth
- **Diagnose problems** - if your model can't recover known parameters from simulated data, something is wrong

In Week 3, many of you found simulation challenging. That's expected! Let's break it down together.

::: {.callout-tip}
## The Simulation Recipe

Every simulation follows the same four steps:

1. **Define the truth** - What are the true parameter values? (e.g., true effect = 3 units)
2. **Generate structure** - Create the experimental design (e.g., 5 fields Ã— 4 plots)
3. **Add randomness** - Use a distribution to generate data (e.g., `rnorm()`, `rpois()`, `rbinom()`)
4. **Fit the model** - Analyze the simulated data and see if you recover the truth
:::

---

## Part 1: Setting Up Your Team Repository (â‰ˆ10 min)

### Form Pairs (1 min)

Get into pairs. You'll be working on a **shared GitHub repository** for the rest of this session. Each person will take responsibility for **one** of the two simulation exercises, so you'll both contribute a complete analysis to the same repo.

::: {.callout-note}
## Why Shared Repos?
In real research, you rarely work alone. Shared repositories force you to practice the pull â†’ edit â†’ commit â†’ push cycle and deal with real collaboration challenges (coordinating who's working on what, writing clear commit messages for your partner). This is the whole point of today.
:::

### One Person Creates the Repo (3 min)

**One partner** does the following:

1. Go to [github.com](https://github.com) â†’ **"+"** â†’ **New repository**
2. Name it: `snr690-sim-team-[your-initials]` (e.g., `snr690-sim-team-amjk`)
3. âœ… Check **"Add a README file"**
4. Set it to **Public** (so your partner can access it easily)
5. Click **Create repository**
6. Go to **Settings â†’ Collaborators â†’ Add people** and add your partner by their GitHub username

### Both Partners Clone the Repo (3 min)

**Both partners** (including the creator):

1. Go to the repository page on GitHub
2. Click the green **"<> Code"** button â†’ copy the HTTPS URL
3. In RStudio: **File â†’ New Project â†’ Version Control â†’ Git**
4. Paste the URL, choose a directory, click **Create Project**

::: {.callout-tip}
## Checkpoint
Both partners should now have the same project open in RStudio, connected to the same GitHub repository. You should see the **Git tab** in your RStudio pane.
:::

### Decide Who Does What (1 min)

- **Partner A** will work on **Activity 1: The Soil Temperature Experiment**
- **Partner B** will work on **Activity 2: The Fertilizer Yield Experiment**

Each person creates their own Quarto file:

1. **File â†’ New File â†’ Quarto Document**
2. Title: `"Soil Temperature Simulation - [Your Name]"` or `"Fertilizer Yield Simulation - [Your Name]"`
3. Save it as `sim-soil-temp-[yourname].qmd` or `sim-fertilizer-[yourname].qmd`
4. **Commit** with message: `"Add Quarto file for [activity name]"`
5. **Push** to GitHub

::: {.callout-warning}
## Important: Pull Before You Push!
Before pushing, always **pull first** (`git pull` in the Terminal, or the â¬‡ï¸ Pull button in the Git tab). Your partner may have pushed changes. Get in the habit now: **pull â†’ work â†’ commit â†’ pull â†’ push**.
:::

---

## Part 2: Simulation Exercises â€” Start Simple, No Transformations (â‰ˆ45 min)

::: {.callout-important}
## The Rule: Start Simple
We are deliberately keeping this simple today. **No log transformations. No logit links. No random effects.** Just linear models with normal distributions. The goal is to get the *workflow* right:

1. Simulate data where you **know the truth**
2. **Comment every line** â€” explain what each step is doing and why
3. Fit the **correct** model â€” does it recover the truth?
4. Fit a **wrong** model â€” what goes wrong?
5. Write it all up in your Quarto document with narrative explaining what you did and why
6. Commit after each step with a meaningful commit message

Once you're comfortable with this pipeline, adding complexity (GLMs, transformations, random effects) in future weeks will be much easier.
:::

---

### Activity 1: The Soil Temperature Experiment (Partner A)

**Scenario:** A researcher wants to know if soil temperature affects the rate of decomposition (mass loss in grams) of leaf litter. They set up 30 plots across a gradient of soil temperatures (5Â°C to 25Â°C) and measure mass loss after 6 months.

**The truth (what we're simulating):**

- True intercept = 2 (baseline decomposition at 0Â°C)
- True slope = 0.8 (for every 1Â°C increase in soil temp, mass loss increases by 0.8 g)
- Noise SD = 2.5

#### Step 1: Simulate the data and visualize

Copy the code below into your Quarto document. **Your job: add a comment above or next to every line explaining what it does and *why*.** If you don't understand a line, ask Dr. Molina â€” that's the point.

```{r}
#| label: sim-soil-temp
#| eval: false

library(tidyverse)

set.seed(42)

n_plots <- 30
true_intercept <- 2
true_slope <- 0.8
noise_sd <- 2.5

soil_temp <- runif(n_plots, min = 5, max = 25)
mass_loss <- true_intercept + true_slope * soil_temp + rnorm(n_plots, 0, noise_sd)

decomp_data <- data.frame(
  soil_temp = soil_temp,
  mass_loss = mass_loss
)

ggplot(decomp_data, aes(x = soil_temp, y = mass_loss)) +
  geom_point(size = 3, alpha = 0.7) +
  geom_smooth(method = "lm", se = TRUE, color = "steelblue") +
  labs(
    title = "Simulated: Soil Temperature vs. Leaf Litter Decomposition",
    subtitle = paste("Truth: mass_loss =", true_intercept, "+", true_slope, "x soil_temp + noise"),
    x = "Soil Temperature (Â°C)",
    y = "Mass Loss (g)"
  ) +
  theme_minimal(base_size = 14)
```

**ğŸ“ In your Quarto doc:** Write a paragraph *above* the code chunk explaining the scenario, the research question, and what the true relationship is. Write another paragraph *below* the plot describing what you see.

**ğŸ“ Commit message:** `"Simulate soil temp decomposition data - true slope 0.8"`

#### Step 2: Fit the correct model

The correct approach here is a **simple linear regression** â€” `lm(mass_loss ~ soil_temp)`. The data are continuous, the relationship is linear, and the errors are normally distributed. This is a textbook match.

**Your job:** Write the code to fit this model, look at the summary, and answer these questions in your Quarto narrative:

- What slope did the model estimate? How close is it to the true value of 0.8?
- What intercept did the model estimate? How close is it to the true value of 2?
- Is the slope statistically significant? Should it be, given that we *know* the true effect exists?
- Why might the estimates not be *exactly* 0.8 and 2?

**ğŸ“ Commit message:** `"Fit correct linear model - check parameter recovery"`

#### Step 3: Fit the wrong model

The wrong approach: **categorize the continuous soil temperature into "Cold" (< 15Â°C) and "Warm" (â‰¥ 15Â°C) and run a t-test** comparing mass loss between the two groups.

**Your job:** Write the code to do this, and then answer these questions in your Quarto narrative:

- What information do you lose when you turn a continuous variable into two categories?
- Does the t-test tell you *how much* mass loss changes per degree? Or just that the groups differ?
- Compare the p-value and effect size from the t-test to the slope and p-value from the linear regression. Which gives you more useful information?
- Connect this to the **Golden Rule from Week 3**: "Start simple. Add complexity only when needed. Always justify your choices." Here the wrong model isn't more complex â€” it's *less informative*. Sometimes the mistake isn't overcomplicating; it's throwing away information.

**ğŸ“ Commit message:** `"Fit wrong model (categorized t-test) - compare to correct approach"`

#### Step 4: Write your conclusions

In your Quarto document, add a final section called **"What I Learned"** summarizing:

- Why the correct model is correct for this scenario
- What specifically went wrong with the incorrect approach
- One sentence connecting this to a concept from Weeks 1â€“3

**ğŸ“ Commit message:** `"Add conclusions and reflections"`

**Push to GitHub.**

---

### Activity 2: The Fertilizer Yield Experiment (Partner B)

**Scenario:** An agronomist tests whether nitrogen application rate (kg/ha) affects wheat yield (tons/ha). They have 40 plots, each receiving a different nitrogen rate (0â€“200 kg/ha). The relationship is linear and the data are well-behaved.

**The truth (what we're simulating):**

- True intercept = 1.5 (yield with no fertilizer)
- True slope = 0.015 (for every 1 kg/ha of nitrogen, yield increases by 0.015 tons/ha)
- Noise SD = 0.4

#### Step 1: Simulate the data and visualize

Copy the code below into your Quarto document. **Your job: add a comment above or next to every line explaining what it does and *why*.** If you don't understand a line, ask Dr. Molina â€” that's the point.

```{r}
#| label: sim-fertilizer
#| eval: false

library(tidyverse)

set.seed(123)

n_plots <- 40
true_intercept <- 1.5
true_slope <- 0.015
noise_sd <- 0.4

nitrogen <- runif(n_plots, min = 0, max = 200)
yield <- true_intercept + true_slope * nitrogen + rnorm(n_plots, 0, noise_sd)

fert_data <- data.frame(
  nitrogen = nitrogen,
  yield = yield
)

ggplot(fert_data, aes(x = nitrogen, y = yield)) +
  geom_point(size = 3, alpha = 0.7) +
  geom_smooth(method = "lm", se = TRUE, color = "darkgreen") +
  labs(
    title = "Simulated: Nitrogen Application vs. Wheat Yield",
    subtitle = paste("Truth: yield =", true_intercept, "+", true_slope, "x nitrogen + noise"),
    x = "Nitrogen Application (kg/ha)",
    y = "Wheat Yield (tons/ha)"
  ) +
  theme_minimal(base_size = 14)
```

**ğŸ“ In your Quarto doc:** Write a paragraph *above* the code chunk explaining the scenario, the research question, and what the true relationship is. Write another paragraph *below* the plot describing what you see.

**ğŸ“ Commit message:** `"Simulate fertilizer yield data - true slope 0.015"`

#### Step 2: Fit the correct model

The correct approach here is a **simple linear regression** â€” `lm(yield ~ nitrogen)`. Same logic as Activity 1: continuous response, continuous predictor, linear relationship, normal errors.

**Your job:** Write the code to fit this model, look at the summary, and answer these questions in your Quarto narrative:

- What slope did the model estimate? How close is it to the true value of 0.015?
- What intercept did the model estimate? How close is it to the true value of 1.5?
- Is the slope statistically significant?
- What is the RÂ² value? What does it tell you about how much variation in yield is explained by nitrogen?

**ğŸ“ Commit message:** `"Fit correct linear model - check parameter recovery"`

#### Step 3: Fit the wrong model

The wrong approach: **add a quadratic term that isn't needed** â€” `lm(yield ~ nitrogen + I(nitrogen^2))`. This is the *overcomplication* scenario from Week 3.

**Your job:** Write the code to fit this overcomplicated model, and then answer these questions in your Quarto narrative:

- Is the quadratic term (`I(nitrogen^2)`) statistically significant? Should it be?
- Compare the slope estimate for `nitrogen` in the quadratic model to the simple model. Did it change? Why might it change even though the quadratic term isn't real?
- Compare the RÂ² of both models. Did the overcomplicated model explain *meaningfully* more variance, or just a tiny bit more?
- What is the danger of adding terms "just in case"? What does this do to interpretability?
- Connect this to **Box's quote from Week 2**: "All models are wrong, but some are useful." The quadratic model is *more wrong* (it implies a curvature that doesn't exist) and *less useful* (harder to interpret). More parameters â‰  better model.

**ğŸ“ Commit message:** `"Fit wrong model (unnecessary quadratic) - compare to correct approach"`

#### Step 4: Write your conclusions

In your Quarto document, add a final section called **"What I Learned"** summarizing:

- Why the correct model is correct for this scenario
- What specifically went wrong with the incorrect approach
- One sentence connecting this to a concept from Weeks 1â€“3

**ğŸ“ Commit message:** `"Add conclusions and reflections"`

**Push to GitHub.**

---

## Part 3: Review Your Partner's Work + Reflection (â‰ˆ10 min)

### Pull and Read (5 min)

1. **Pull** from GitHub to get your partner's file
2. **Open their `.qmd` file** and read through it
3. Pay attention to:
   - Did they comment every line of the simulation code? Do the comments make sense?
   - Is their narrative clear â€” could you understand the analysis without them explaining it to you?
   - Do their conclusions connect back to Week 1â€“3 concepts?

::: {.callout-tip}
## SoTL Connection: Peer Review as Learning
Research on peer instruction (Mazur, 1997) shows that explaining your reasoning to others â€” and reading others' explanations â€” deepens understanding more than working alone. Reading your partner's Quarto document isn't just a Git exercise; comparing how they narrated their analysis to how you narrated yours is a powerful form of peer learning.
:::

4. **Optional:** If you want to leave feedback, you can add a comment directly in their `.qmd` file (use `<!-- Your comment here -->` so it doesn't render), commit with message `"Add peer review comments to [partner]'s file"`, and push.

### Think-Pair-Share Reflection (5 min)

**Think (1 min):** On paper, answer:

1. What was the most surprising or useful thing about using Git today?
2. What did you learn from reading your partner's analysis that you wouldn't have learned working alone?

**Pair (2 min):** Discuss with your partner.

**Share (2 min):** 2â€“3 pairs share with the class.

::: {.callout-tip}
## SoTL Connection: Metacognitive Monitoring
Writing commit messages forces **metacognitive monitoring** â€” you have to pause and articulate *what* you just did and *why* (Tanner, 2012). This is the same skill that makes for good scientific writing: being explicit about your analytical choices. Over time, the habit of writing commit messages trains you to be a more reflective analyst.
:::

### Git Log Review (2 min)

In the Terminal, type:

```bash
git log --oneline
```

Look at the commit history. Each line is a snapshot of your analytical journey â€” and your partner's. **This is what version control gives you**: a complete, narrated record of every decision both of you made.

### Exit Ticket (2 min)

On a piece of paper, answer:

1. **One thing you now feel comfortable doing in Git** (be specific â€” e.g., "I can commit and push from RStudio")
2. **One thing you still want to practice** (e.g., "I'm not sure how branches work")
3. **One connection** between today's Git workshop and the statistical concepts from Weeks 1â€“3

::: {.callout-note}
## Looking Ahead
Now that you have Git fundamentals down, future sessions will build on this. You'll use version control for every hands-on activity going forward. 
:::

---